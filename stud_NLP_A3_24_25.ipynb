{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cihj8t1AM00f"
      },
      "source": [
        "# Lab 3: Three NLP tasks\n",
        "\n",
        "The assignment covers three NLP tasks related to the language structure and meaning.  \n",
        "Part 1 is about probabilistic context-free grammar parsing, a task of recovering the underlying syntactic structure of a sentence using a probabilistic grammar.  \n",
        "Part 2 deals with word meaning as it tackles the task of identifying the correct sense of a word in the context.  \n",
        "Part 3 concerns reasoning with math question-answering problems and examines it from the generalization and explainability perspectives.\n",
        "\n",
        "Shall we begin?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTkFjaarrc1F"
      },
      "source": [
        "# Rules\n",
        "\n",
        "You are greatly encouraged to add comments to your code describing what particular lines of code do (in general, a great habit to have in your coding life).\n",
        "Additionally, please follow these rules when submitting the notebook:\n",
        "\n",
        "* Put all code in the cell with the `# YOUR CODE HERE` comment.\n",
        "* For theoretical questions, put your solution in the `YOUR ANSWER HERE` or `ANSWER UNDER THIS LINE` cells (and keep the header if any).\n",
        "* Don't change or delete any initially provided cells, either text or code, unless explicitly instructed to do so.\n",
        "* Don't delete the comment lines `# TEST...` or edit their code cells. The test cells are for sanity checking. Passing them doesn't necessarily mean that your code is fine.\n",
        "* Don't change the names of provided functions and variables or arguments of the functions.\n",
        "* Don't clear the output of your code cells.\n",
        "* Don't output unnecessary info (e.g., printing variables for debugging purposes). This clutters the notebook and slows down the grading. You can have print() in the code, but comment them out before submitting the notebook.\n",
        "* Delete those cells that you inserted for your own debugging/testing purposes.\n",
        "* Don't forget to fill in the **contribution information**.\n",
        "* Don't forget to fill in the **work description section** per exercise.\n",
        "* Test your code and **make sure we can run your notebook** in the colab environment.\n",
        "* A single notebook file (without archiving) per group should be submitted via BB.\n",
        "\n",
        "<font color=\"red\">Following these rules helps us to grade the submissions relatively efficiently. If these rules are violated, a submission will be subject to penalty points.</font>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWqs-t7Grc1L"
      },
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "YOUR ANSWER HERE [30-50 words]\n",
        "\n",
        "**Names:**\n",
        "\n",
        "- Alexia Ntantouri\n",
        "- Juan David Liut Aymar\n",
        "\n",
        "**Contributions:**\n",
        "\n",
        "**Part 1:** Code by David, review by Alexia<br>\n",
        "\n",
        "**Part 2:** Code and review by Alexia and David<br>\n",
        "\n",
        "**Part 3:** Code by Alexia, review by David<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUCfBV-9l7-"
      },
      "source": [
        "# General instructions\n",
        "\n",
        "Before diving into the exercises, keep in mind that the variables defined previously can be reused in the subsequent cells. So there is no need to redefine the same variable in multiple sections, e.g., it is sufficient to read the file in a variable once and later reuse the value of the variable, instead of re-reading the file.   \n",
        "\n",
        "If your code is too long and uses several code cells instead of a single code cell, rethink how to organize data in variables so that you can easily access the required info. Reading about [list comprehension](https://realpython.com/list-comprehension-python/#leverage-list-comprehensions) can be useful.\n",
        "\n",
        "Your code will often be evaluated based on its behaviour. So, during the grading some code cells are executed. If code runtime is too long than expected, this will hinder grading.\n",
        "\n",
        "<font color=\"red\">**The cases similar to the above-mentioned ones will be subject to penalty points.**</font>\n",
        "\n",
        "<font color=\"red\">**Pay attention to test units**</font> that are either provided as assert cases or as comments. Test units help you by giving you a hint about the correct answer. Note that **passing test units doesn't guarantee the full points** for an exercise because test units are incomplete, and the code might fail on other test units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_codXTgCGLZ"
      },
      "source": [
        "# Part 1: Constituency parsing with CKY\n",
        "\n",
        "The grammatical structure of a sentence can be represented with a Context Free Grammar (CFG). When we additionally assign probabilities to the rules of the CFG we get a PCFG: a _Probabilistic_ CFG.\n",
        "\n",
        "Given a sufficiently expressive PCFG (one that holds enough rules) we can parse new sentences using the Cocke–Kasami–Younger (CKY) algorithm. You can use this algorithm in three ways: to find the set of all the possible parses $p$ of a sentence $s$ under a PCFG $G$; to find the probability of the sentence by summing up the probabilities of these parses; or to find the parse $p^{*}$ of the highest probability.\n",
        "\n",
        "\n",
        "### Tasks\n",
        "1. In this notebook you will learn how to represent a PCFG in an object-oriented manner as a collection of python classes. These classes are already defined for you. Read them through thoroughly and make sure that you understand them well. You have to use them when implementing the CKY algorithm.\n",
        "\n",
        "2. Implement the CKY algorithm to find the most probable parse $p^{*}$ for a sentence. Your implementation will follow the psuedo-code that is given in both the lecture slides, and Jurafsky and Martin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J__sR-Swbg_1"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2rFTz2rCGLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "# nltk will be used to draw constituency parses\n",
        "import nltk\n",
        "from nltk.tree import Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5N77nlCWcvs",
        "outputId": "c9caa95e-b986-4dea-dd0a-aa8cc588c155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-08 09:09:07 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt [337/337] -> \"groucho-grammar-1.txt\" [1]\n",
            "2025-06-08 09:09:07 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt [337/337] -> \"groucho-grammar-2.txt\" [1]\n",
            "2025-06-08 09:09:08 URL:https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt [381/381] -> \"telescope-grammar.txt\" [1]\n"
          ]
        }
      ],
      "source": [
        "# downloading grammar files\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7SNulWbMf5"
      },
      "source": [
        "## PCFG\n",
        "\n",
        "In this lab we will show you a way to represent a **PCFG** using python objects. We will introduce the following classes:\n",
        "\n",
        "* Symbol\n",
        "    * Terminal\n",
        "    * Nonterminal\n",
        "* Rule\n",
        "\n",
        "At first glance, this might seem like a lot of work. But, hopefully, by the time you get to implementing CKY you will be convinced in the benefits of these constructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X2Nk5i3CGLg"
      },
      "source": [
        "### Symbol\n",
        "\n",
        "Recall that:\n",
        "* **Terminal** symbols are the words of the sentence: _I, ate, salad, the_ etc.\n",
        "* **Nonterminal** symbols are the syntactic categories of the various constituents: _S, NP, VP, Det_ etc.\n",
        "\n",
        "In our representation, `Symbol` is going to be a container class. The classes `Terminal` and `Nonterminal` will *inherit* from the `Symbol` class and will hence both become a type of symbol. The classes themselves are effectively a container for the underlying python strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlsXWvTjCGLh"
      },
      "outputs": [],
      "source": [
        "class Symbol:\n",
        "    \"\"\"\n",
        "    A symbol in a grammar.\n",
        "    This class will be used as parent class for Terminal, Nonterminal.\n",
        "    This way both will be a type of Symbol.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Terminal(Symbol):\n",
        "    \"\"\"\n",
        "    Terminal symbols are words in a vocabulary\n",
        "\n",
        "    E.g. 'I', 'ate', 'salad', 'the'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Terminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return True\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return False\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"'{self._symbol}'\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Terminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol\n",
        "\n",
        "\n",
        "class Nonterminal(Symbol):\n",
        "    \"\"\"\n",
        "    Nonterminal symbols are the grammatical classes in a grammar.\n",
        "\n",
        "    E.g. S, NP, VP, N, Det, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Nonterminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return False\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return True\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"[{self._symbol}]\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Nonterminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ0WmVOZCGLj"
      },
      "source": [
        "Let's try out the classes by initializing some terminal and nonterminal symbols:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv2qVwloCGLk"
      },
      "outputs": [],
      "source": [
        "dog = Terminal('dog')\n",
        "the = Terminal('the')\n",
        "walks = Terminal('walks')\n",
        "\n",
        "S = Nonterminal('S')\n",
        "NP = Nonterminal('NP')\n",
        "NP_prime = Nonterminal('NP')\n",
        "VP = Nonterminal('VP')\n",
        "V = Nonterminal('V')\n",
        "N = Nonterminal('N')\n",
        "Det = Nonterminal('Det')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZHKNAUCGLl"
      },
      "source": [
        "The methods `__eq__` and `__ne__` make it possible to compare our objects using standard Python syntax. But more importantly: compare in the way that we are interested in, namely whether the underlying representation is the same.\n",
        "\n",
        "To see the difference, try commenting out the method `__eq__` in the class above, and notice the different result of the equality test `NP==NP_prime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWBrXghCGLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed97b29-b5ee-4b96-c7b2-e396a15ff9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dog'\n",
            "[NP]\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(dog)\n",
        "print(NP)\n",
        "print(NP==Det)\n",
        "print(NP!=Det)\n",
        "print(NP==NP)\n",
        "print(NP==NP_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qScfOAVvCGLm"
      },
      "source": [
        "Note the difference between calling `print(NP)` and simply calling `NP`. The first is taken care of by the method `__str__` and the second by the method `__repr__`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTS_97wYCGLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4330ef09-5b8e-4fd8-a561-8f06c4ab1c8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Terminal('dog')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXMlXaFkCGLo"
      },
      "source": [
        "We can also easily check if our symbol is a terminal or not:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMuoMVHQCGLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569453bc-45b5-4e54-920e-3355bec98421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dog.is_terminal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtnXm0IUCGLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d12c4dc-092a-405d-808f-b8af4d8b8923"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "NP.is_terminal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvtkwhBhCGLq"
      },
      "source": [
        "Finally the method `__hash__` makes our object *hashable*, and hence usable in a datastructure like a dictionary.\n",
        "\n",
        "Try commenting out this method above in the class and then retry constructing the dictionary: notice the error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nniQ14QyCGLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b7ccf8-eff2-4ee2-c48f-6b165d285a25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Nonterminal('NP'): 1, Nonterminal('S'): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "d = {NP: 1, S: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpC5JyBcCGLs"
      },
      "source": [
        "### Rules\n",
        "\n",
        "In a PCFG a **rule** looks something like this\n",
        "\n",
        "$$NP \\to Det\\;N$$\n",
        "\n",
        "with a corresponding probability, for example $1.0$ if we lived in a world where all noun phrases had this grammatical structure.\n",
        "\n",
        "In our representation, `Rule` will be an object made of a left-hand side (`lhs`) symbol, a sequence of right-hand side symbols (`rhs`) and a probability `prob`.\n",
        "\n",
        "If we use the above defined symbols, we can call\n",
        "\n",
        "    rule = Rule(NP, [Det, N], 1.0)\n",
        "   \n",
        "This will construct an instance called `rule` which represent the rule above\n",
        "\n",
        "    [NP] -> [Det] [N] (1.0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXN4G4t-CGLs"
      },
      "outputs": [],
      "source": [
        "class Rule:\n",
        "\n",
        "    def __init__(self, lhs, rhs, prob):\n",
        "        \"\"\"\n",
        "        Constructs a Rule.\n",
        "        A Rule takes a LHS symbol and a list/tuple of RHS symbols.\n",
        "\n",
        "        :param lhs: the LHS nonterminal\n",
        "        :param rhs: a sequence of RHS symbols (terminal or nonterminal)\n",
        "        :param prob: probability of the rule\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(lhs, Symbol), 'LHS must be an instance of Symbol (actually even a non-terminal but later we will expan LHS)'\n",
        "        assert len(rhs) > 0, 'If you want an empty RHS, use an epsilon Terminal EPS'\n",
        "        assert all(isinstance(s, Symbol) for s in rhs), 'RHS must be a sequence of Symbol objects'\n",
        "        if prob is not None:\n",
        "            assert 0 <= prob <= 1, 'The probability must be between 0 and 1'\n",
        "        self._lhs = lhs\n",
        "        self._rhs = tuple(rhs)\n",
        "        self._prob = prob\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self._lhs == other._lhs and self._rhs == other._rhs and self._prob == other._prob\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._lhs, self._rhs, self._prob))\n",
        "\n",
        "    def __repr__(self):\n",
        "        rhs = ' '.join(str(sym) for sym in self._rhs)\n",
        "        return f\"{self._lhs} -> {rhs} ({self.prob})\"\n",
        "\n",
        "    def is_binary(self):\n",
        "        \"\"\"True if Rule is binary: A -> B C\"\"\"\n",
        "        return len(self._rhs) == 2\n",
        "\n",
        "    def is_unary(self):\n",
        "        \"\"\"True if Rule is unary: A -> w\"\"\"\n",
        "        return len(self._rhs) == 1\n",
        "\n",
        "    @property\n",
        "    def lhs(self):\n",
        "        \"\"\"Returns the lhs of the rule\"\"\"\n",
        "        return self._lhs\n",
        "\n",
        "    @property\n",
        "    def rhs(self):\n",
        "        \"\"\"Returns the rhs of the rule\"\"\"\n",
        "        return self._rhs\n",
        "\n",
        "    @property\n",
        "    def prob(self):\n",
        "        \"\"\"Returns the probability of the rule\"\"\"\n",
        "        return self._prob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4U1gI2rCGLt"
      },
      "source": [
        "Just as with `Terminal` and `Nonterminal` you can print an instance of `Rule`, you can access its attributes, and you can hash rules with containers such as dict and set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld0VMQWWCGLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d40140d-7481-48a3-a561-84335c03fd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n"
          ]
        }
      ],
      "source": [
        "r1 = Rule(S, [NP, VP], 1.0)\n",
        "r2 = Rule(NP, [Det, N], 1.0)\n",
        "r3 = Rule(N, [dog], 1.0)\n",
        "r4 = Rule(Det, [the], 1.0)\n",
        "r5 = Rule(VP, [walks], 1.0)\n",
        "\n",
        "print(r1)\n",
        "print(r2)\n",
        "print(r3)\n",
        "print(r4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y62yZ8I8CGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c9f737-294d-495c-aefc-ac65a0704fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(r1.prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhEJETHgCGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fe41a1-af49-4bd7-ac96-3e7980abdfb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "r1 in set([r1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTAJ2CmBCGLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60278433-ce34-4951-a92f-c09965f43d13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{[S] -> [NP] [VP] (1.0): 1, [NP] -> [Det] [N] (1.0): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "d = {r1: 1, r2: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrHaNQzKCGLw"
      },
      "source": [
        "### Grammar\n",
        "\n",
        "A `PCFG` class is a container for `Rules`. The `Rules` are stored in the `PCFG` in such a way that they can be accesed easily in different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm6tzk7TCGLw"
      },
      "outputs": [],
      "source": [
        "class PCFG(object):\n",
        "    \"\"\"\n",
        "    Constructs a PCFG.\n",
        "    A PCFG stores a list of rules that can be accessed in various ways.\n",
        "\n",
        "    :param rules: an optional list of rules to initialize the grammar with\n",
        "    \"\"\"\n",
        "    def __init__(self, rules=[]):\n",
        "        self._rules = []\n",
        "        self._rules_by_lhs = defaultdict(list)\n",
        "        self._terminals = set()\n",
        "        self._nonterminals = set()\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    def add(self, rule):\n",
        "        \"\"\"Adds a rule to the grammar\"\"\"\n",
        "        if not rule in self._rules:\n",
        "            self._rules.append(rule)\n",
        "            self._rules_by_lhs[rule.lhs].append(rule)\n",
        "            self._nonterminals.add(rule.lhs)\n",
        "            for s in rule.rhs:\n",
        "                if s.is_terminal():\n",
        "                    self._terminals.add(s)\n",
        "                else:\n",
        "                    self._nonterminals.add(s)\n",
        "\n",
        "    def update(self, rules):\n",
        "        \"\"\"Add a list of rules to the grammar\"\"\"\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    @property\n",
        "    def nonterminals(self):\n",
        "        \"\"\"The list of nonterminal symbols in the grammar\"\"\"\n",
        "        return self._nonterminals\n",
        "\n",
        "    @property\n",
        "    def terminals(self):\n",
        "        \"\"\"The list of terminal symbols in the grammar\"\"\"\n",
        "        return self._terminals\n",
        "\n",
        "    @property\n",
        "    def rules(self):\n",
        "        \"\"\"The list of rules in the grammar\"\"\"\n",
        "        return self._rules\n",
        "\n",
        "    @property\n",
        "    def binary_rules(self):\n",
        "        \"\"\"The list of binary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_binary()]\n",
        "\n",
        "    @property\n",
        "    def unary_rules(self):\n",
        "        \"\"\"The list of unary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_unary()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._rules)\n",
        "\n",
        "    def get(self, lhs):\n",
        "        \"\"\"The list of rules whose LHS is the given symbol lhs\"\"\"\n",
        "        return self._rules_by_lhs.get(lhs, [])\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Iterator over rules (in arbitrary order)\"\"\"\n",
        "        return iter(self._rules)\n",
        "\n",
        "    def iteritems(self):\n",
        "        \"\"\"Iterator over pairs of the kind (LHS, rules rewriting LHS)\"\"\"\n",
        "        return self._rules_by_lhs.items()\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints the grammar line by line\"\"\"\n",
        "        lines = []\n",
        "        for lhs, rules in self.iteritems():\n",
        "            for rule in rules:\n",
        "                lines.append(str(rule))\n",
        "        return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGZAbUSCGLx"
      },
      "source": [
        "Initialize a grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIVuStsyCGLy"
      },
      "outputs": [],
      "source": [
        "G = PCFG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVkm-al_CGLy"
      },
      "source": [
        "We can add rules individually with `add`, or as a list with `update`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-d55FW6CGLy"
      },
      "outputs": [],
      "source": [
        "G.add(r1)\n",
        "G.update([r2,r3,r4,r5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f-3Mf4JPCGLy"
      },
      "source": [
        "We can print the grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZNR4GxqCGLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8149fbba-c4aa-4e0f-8d5f-aa2b29648ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n",
            "[VP] -> 'walks' (1.0)\n"
          ]
        }
      ],
      "source": [
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpEzw7CSCGLz"
      },
      "source": [
        "We can get the set of rewrite rules for a certain LHS symbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvJI3GIPCGLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a59ee7-7b1f-4297-f0f4-96e8b28575ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "G.get(S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3cghJx6CGL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4028730d-1928-4c2d-bae8-69cf638c9b9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[NP] -> [Det] [N] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "G.get(NP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNh0XOhuCGL0"
      },
      "source": [
        "We can also iterate through rules in the grammar.\n",
        "\n",
        "Note that the following is basically counting how many rules we have in the grammar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXVqzI9lCGL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c065162d-f55f-4002-c9d9-2d7fe7de36cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sum(1 for r in G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jjU3krCCGL1"
      },
      "source": [
        "which can also be done in a more concise way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vi814lRCGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7a806e-b004-455c-f2b8-3d33c1913c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7BmtlyCGL2"
      },
      "source": [
        "We can access the set of terminals and nonterminals of the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9--IbP75CGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc3ab8d-e8a3-4848-a556-1c64c9e0346f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Nonterminal('NP'), Nonterminal('VP'), Nonterminal('Det'), Nonterminal('N'), Nonterminal('S')}\n"
          ]
        }
      ],
      "source": [
        "print(G.nonterminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MvItFKtCGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205a7e9b-0226-44d3-a371-58ed9b64fcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Terminal('the'), Terminal('walks'), Terminal('dog')}\n"
          ]
        }
      ],
      "source": [
        "print(G.terminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q29uTBaXCGL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a47ba4c-4492-43d8-a819-a0f00f10eb30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "S in G.nonterminals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsVg9Wf2CGL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55284b46-5ec7-48b3-ec3b-9dbd70e6da92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "dog in G.terminals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ojHdLHUCGL4"
      },
      "source": [
        "Finally we can easily access all the binary rules and all the unary rules in the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv6pcFS1CGL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9271824b-dca1-48cd-8cc8-a1fe7e6403cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[N] -> 'dog' (1.0), [Det] -> 'the' (1.0), [VP] -> 'walks' (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "G.unary_rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYpJIx4mCGL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5195e6ae-8036-4546-ec9f-fd44120abc88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0), [NP] -> [Det] [N] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "G.binary_rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZdbicfrCGL5"
      },
      "source": [
        "## Visualizing a tree\n",
        "\n",
        "For the sake of legacy let's reiterate an age-old NLP schtick, the well-known example of structural ambiguity from the Groucho Marx movie, [Animal Crackers](https://youtu.be/FZUfhfHbjE4?t=1m33s) (1930):\n",
        "\n",
        "> One morning I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\n",
        "\n",
        "Let's take a closer look at the ambiguity in the phrase: _I shot an elephant in my pajamas_. The ambiguity is caused by the fact that the sentence has two competing parses represented in:\n",
        "\n",
        "    (S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\n",
        "\n",
        "and\n",
        "\n",
        "    (S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\n",
        "\n",
        "\n",
        "We can write these parses down as strings and then let NLTK turn them into trees using the NLTK `Tree` class. (See http://www.nltk.org/api/nltk.html#nltk.tree.Tree as reference for this class, if you want to know more.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDFH2wyqCGL5"
      },
      "outputs": [],
      "source": [
        "parse1 = \"(S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\"\n",
        "parse2 = \"(S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\"\n",
        "\n",
        "pajamas1 = Tree.fromstring(parse1)\n",
        "pajamas2 = Tree.fromstring(parse2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQ_EvhHCGL5"
      },
      "source": [
        "We can then *pretty-print* these trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSsl34LCCGL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dad2684-2c49-413b-dd2d-ddfb34051869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     S                                       \n",
            "  ___|______________                          \n",
            " |                  VP                       \n",
            " |         _________|__________               \n",
            " |        VP                   PP            \n",
            " |    ____|___              ___|___           \n",
            " |   |        NP           |       NP        \n",
            " |   |     ___|_____       |    ___|_____     \n",
            " NP  V   Det        N      P  Det        N   \n",
            " |   |    |         |      |   |         |    \n",
            " I  shot  an     elephant  in  my     pajamas\n",
            "\n",
            "     S                                       \n",
            "  ___|__________                              \n",
            " |              VP                           \n",
            " |    __________|______                       \n",
            " |   |                 NP                    \n",
            " |   |     ____________|___                   \n",
            " |   |    |                NP                \n",
            " |   |    |      __________|___               \n",
            " |   |    |     |              PP            \n",
            " |   |    |     |       _______|___           \n",
            " |   |    |     |      |           NP        \n",
            " |   |    |     |      |        ___|_____     \n",
            " NP  V   Det    N      P      Det        N   \n",
            " |   |    |     |      |       |         |    \n",
            " I  shot  an elephant  in      my     pajamas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pajamas1.pretty_print()\n",
        "pajamas2.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjAkmuXCGL7"
      },
      "source": [
        "## Parsing with CKY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8pVcXseCGL8"
      },
      "source": [
        "Let's stick with this sentence for the rest of this lab. We will use CKY to find the 'best' parse for this sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWkI8S1kCGL8"
      },
      "outputs": [],
      "source": [
        "# Turn the sentence into a list\n",
        "sentence = \"I shot an elephant in my pajamas\".split()\n",
        "# The length of the sentence\n",
        "num_words = len(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtehwdb1CGL8"
      },
      "source": [
        "A PCFG for this sentence can be found in the file `groucho-grammar-1.txt`. We read this in with the function `read_grammar_rules`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVASx2r0CGL9"
      },
      "outputs": [],
      "source": [
        "def read_grammar_rules(istream):\n",
        "    \"\"\"Reads grammar rules formatted as 'LHS ||| RHS ||| PROB'.\"\"\"\n",
        "    for line in istream:\n",
        "        line = line.strip()\n",
        "        if not line: continue\n",
        "        fields = line.split('|||')\n",
        "        if len(fields) != 3:\n",
        "            raise ValueError(f\"Three fields were expected: {fields}\")\n",
        "        lhs = fields[0].strip()\n",
        "\n",
        "        if lhs.startswith('[') and lhs.endswith(']'):\n",
        "            lhs = Nonterminal(lhs[1:-1])\n",
        "        else:\n",
        "            raise ValueError(f\"LHS must be a non-terminal: {fields}\")\n",
        "        rhs = fields[1].strip().split()\n",
        "        new_rhs = []\n",
        "        for r in rhs:\n",
        "            if r.startswith('[') and r.endswith(']'):\n",
        "                r = Nonterminal(r[1:-1])\n",
        "            else:\n",
        "                r = Terminal(r)\n",
        "            new_rhs.append(r)\n",
        "\n",
        "        prob = float(fields[2].strip())\n",
        "        yield Rule(lhs, new_rhs, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UP_-I5XCGL9",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1245a4-9e09-4ac1-bb02-408fcda0a594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[PP] -> [P] [NP] (1.0)\n",
            "[NP] -> [Det] [N] (0.2)\n",
            "[NP] -> [Det] [NP] (0.3)\n",
            "[NP] -> [N] [PP] (0.3)\n",
            "[NP] -> 'I' (0.2)\n",
            "[VP] -> [V] [NP] (0.4)\n",
            "[VP] -> [VP] [PP] (0.6)\n",
            "[Det] -> 'an' (0.6)\n",
            "[Det] -> 'my' (0.4)\n",
            "[N] -> 'elephant' (0.5)\n",
            "[N] -> 'pajamas' (0.5)\n",
            "[V] -> 'shot' (1.0)\n",
            "[P] -> 'in' (1.0)\n"
          ]
        }
      ],
      "source": [
        "# Read in the grammar\n",
        "with open('groucho-grammar-1.txt') as F:\n",
        "    grammar = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRecCE1RCGL-"
      },
      "source": [
        "We will also need the following two dictionaries: `n2i` mapping from nonterminals to integers (indices); and its inverse, an `i2n` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjPcYJQuCGL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c8a8f2-8fa7-40e5-e42f-3a05ed0c3f25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Nonterminal('Det'): 0,\n",
              " Nonterminal('N'): 1,\n",
              " Nonterminal('NP'): 2,\n",
              " Nonterminal('P'): 3,\n",
              " Nonterminal('PP'): 4,\n",
              " Nonterminal('S'): 5,\n",
              " Nonterminal('V'): 6,\n",
              " Nonterminal('VP'): 7}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "n2i = defaultdict(lambda: len(n2i))\n",
        "i2n = dict()\n",
        "\n",
        "# sort nonterminals to make the mapping deterministic\n",
        "for nt in sorted(grammar.nonterminals):\n",
        "    i2n[n2i[nt]] = nt\n",
        "\n",
        "# Stop defaultdict behavior of n2i\n",
        "n2i = dict(n2i)\n",
        "\n",
        "n2i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x_4Mb1xCGL-"
      },
      "source": [
        "### The charts\n",
        "\n",
        "Now we are ready to introduce the chart datastructures. We need a chart to store the **scores** and a chart to store the **backpointers**.\n",
        "\n",
        "Both of these will be 3-dimensional numpy arrays: one named `score` holding the probabilities of intermediate results; one named `back` to store the backpointers in. We will use the following indexing convention for these charts:\n",
        "\n",
        "* Format of the chart holding the **scores** `score[A][begin][end] = probability`.\n",
        "This is interpreted as the probability of the constituent between `begin:end` being parsed with `A` as its root.      \n",
        "         \n",
        "* Format of the chart holding the **backpointers** `back[A][begin][end] = (split, B, C)`.\n",
        "This is interpreted as the constituent `begin:end` can be combined with a rule `A -> B C` where `begin:split` is `B` and `split:end` is `C`.\n",
        "\n",
        "This indexing convention is convenient for printing. See what happens when we print `back` below: we get `num_nonterminal` slices, each a numpy array of shape `[n_words+1, n_words+1]`. This is easier to read than the format `back[i][j][A]`.\n",
        "\n",
        "**[Note]** Here we pretended `A` is both the nonterminal as well as the index. In our implementation `A` will be the nonterminal and the index for `A` will be `n2i[A]`.  \n",
        "\n",
        "Let's show you what we mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqNdJjfrCGL-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# A numpy array zeros\n",
        "score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "# A numpy array that can store arbitrary data (we set dtype to object)\n",
        "back = np.zeros((num_nonterminals,\n",
        "                 num_words + 1,\n",
        "                 num_words + 1), dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0YJ227uCGL-"
      },
      "source": [
        "The following illustrates the way you will use the `back` chart. In this example, your parser recognized that the entire sequence is S while the words between 0 and 2 form NP, and the words between 2 and the end of the sentence form VP (and nothing else yet):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7KOKnTuCGL_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c963d8c9-0ff0-4d4e-a3b4-3464df1311be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, (2, Nonterminal('NP'), Nonterminal('VP'))],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Illustration of the backpointer array\n",
        "back[n2i[S]][0][-1] = (2,NP,VP)\n",
        "back"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUx3Mc5CGL_"
      },
      "source": [
        "## Ex1.1 [10pt] CKY parsing\n",
        "\n",
        "Implement the **CKY** algorithm. Follow the pseudo-code given in the lecture-slides (or alternatively in J&M). The code must comply to the following:\n",
        "\n",
        "* The function `cky` takes a sentence (list of words), a grammar (an instance of PCFG), and a n2i non-terminals-to-index dictionary.\n",
        "* The function `cky` returns the filled-in score-chart and backpointer-chart, following the format established above.\n",
        "* No global variables should be accessed from the body of the function (except for the predefined classes).\n",
        "\n",
        "**[Hint]** This is the moment to make good use of the methods of the classes `PCFG`, `Rule`, `Nonterminal`, and `Terminal`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kq23wsvCGL_"
      },
      "outputs": [],
      "source": [
        "# @title cky function\n",
        "def cky(sentence, grammar, n2i):\n",
        "    \"\"\"\n",
        "    The CKY algorithm.\n",
        "\n",
        "    :param sentence: a list of words\n",
        "    :param grammar: an instance of the class PCFG\n",
        "    :param n2i: a dictionary mapping from Nonterminals to indices\n",
        "    :return score: the filled in scores chart\n",
        "    :return back: the filled in backpointers chart\n",
        "    \"\"\"\n",
        "    num_words = len(sentence)\n",
        "    num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "    # A numpy array to store the scores of intermediate parses\n",
        "    score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "    # A numpy array to store the backpointers\n",
        "    back = np.zeros((num_nonterminals,\n",
        "                     num_words + 1,\n",
        "                     num_words + 1), dtype=object)\n",
        "\n",
        "    ## YOUR CODE HERE ##\n",
        "    # 1. Initialize with lexical rules (A -> w)\n",
        "    for i in range(num_words):\n",
        "        word = sentence[i] # get the i-th word and treat it as a terminal\n",
        "        terminal = Terminal(word)\n",
        "        for rule in grammar.rules:\n",
        "            if rule.is_unary() and rule.rhs[0] == terminal: # check for unary rules with terminal on the right\n",
        "                A = rule.lhs\n",
        "                A = rule.lhs\n",
        "                A_idx = n2i[A]\n",
        "                score[A_idx][i][i+1] = rule.prob # the substring from word i to i+1 can be generated using rule A\n",
        "                back[A_idx][i][i+1] = None  # unary rules don't have backpointers\n",
        "\n",
        "    # 2. Handle spans of increasing length\n",
        "    for span in range(2, num_words + 1):  # length of the span\n",
        "        for begin in range(num_words + 1 - span):\n",
        "            end = begin + span\n",
        "            for split in range(begin + 1, end):\n",
        "                for rule in grammar.rules:\n",
        "                    if rule.is_binary():\n",
        "                        B, C = rule.rhs\n",
        "                        A = rule.lhs\n",
        "                        A_idx = n2i[A]\n",
        "                        B_idx = n2i[B]\n",
        "                        C_idx = n2i[C]\n",
        "                        prob = rule.prob * score[B_idx][begin][split] * score[C_idx][split][end]\n",
        "                        if prob > score[A_idx][begin][end]:\n",
        "                            score[A_idx][begin][end] = prob\n",
        "                            back[A_idx][begin][end] = (split, B, C)\n",
        "\n",
        "    return score, back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdyvogQICGMA"
      },
      "outputs": [],
      "source": [
        "# Run CKY\n",
        "score, back = cky(sentence, grammar, n2i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-RR3hKxCGMA"
      },
      "source": [
        "### Check your CKY\n",
        "\n",
        "Use the code in the following two cell to check your `cky` implementation.\n",
        "\n",
        "Take the Nonterminal `S` to inspect your filled in score and backpointer charts. **Leave the code in this cell unchanged.** We will use this to evaluate the corectness of your cky function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBvi4nElCGMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acd57c5-f193-45b1-c9df-fc9b823f35a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The whole slice for nonterminal S:\n",
            "[[0.        0.        0.        0.        0.0048    0.        0.\n",
            "  0.0001152]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]] \n",
            "\n",
            "The score in cell (S, 0, num_words), which is the probability of the best parse:\n",
            "0.00011520000000000004 \n",
            "\n",
            "The backpointer in cell (S, 0, num_words):\n",
            "(1, Nonterminal('NP'), Nonterminal('VP')) \n",
            "\n",
            "[[0 0 0 0 (1, Nonterminal('NP'), Nonterminal('VP')) 0 0\n",
            "  (1, Nonterminal('NP'), Nonterminal('VP'))]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# TEST EX1.1\n",
        "### Don't change the code in this cell ###\n",
        "\n",
        "S = Nonterminal('S')\n",
        "\n",
        "print('The whole slice for nonterminal S:')\n",
        "print(score[n2i[S]], \"\\n\")\n",
        "\n",
        "print('The score in cell (S, 0, num_words), which is the probability of the best parse:')\n",
        "print(score[n2i[S]][0][num_words], \"\\n\")\n",
        "\n",
        "print('The backpointer in cell (S, 0, num_words):')\n",
        "print(back[n2i[S]][0][num_words], \"\\n\")\n",
        "\n",
        "print(back[n2i[S]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFo5ehEACGMC"
      },
      "source": [
        "## Ex1.2 [5pt] Recovering a tree\n",
        "\n",
        "Write the function `build_tree` that reconstructs the parse from the backpointer table. This is the function that is called in the return statement of the [pseudo-code](https://web.stanford.edu/~jurafsky/slp3/C.pdf#page=6) in Jurafsky and Martin.\n",
        "\n",
        "**[Note]** We have no pseudocode for you here: you must come up with your own implementation. However we do provide you with the expected output so that you can at least partially test your code.\n",
        "\n",
        "Here is some additional advice:\n",
        "\n",
        "* Use recursion - that is write your function in a recursive way.  \n",
        "What is the base case? Hint: $A \\to w$.  \n",
        "What is the recursive case? Hint: $A \\to B\\; C$.\n",
        "    \n",
        "    \n",
        "* Use the additional class `Span` that we introduce below for the symbols in your recovered rules. Read the documentation in the `Span` class for its usage.\n",
        "    \n",
        "    \n",
        "* In order to use the function `make_nltk_tree` (which we provide and that turns a `derivation` into an NLTK tree so that you can draw it), your function must return the <font color=\"red\">**list of rules in derivation ordered [depth-first](https://en.wikipedia.org/wiki/Depth-first_search)**</font>. If you write your function recursively such order can be achieved easily.\n",
        "\n",
        "The following class will be very useful in your solution for the function `build_tree`.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty0jbFeuCGMD"
      },
      "outputs": [],
      "source": [
        "class Span(Symbol):\n",
        "    \"\"\"\n",
        "    A Span indicates that symbol was recognized between begin and end.\n",
        "\n",
        "    Example:\n",
        "        Span(Terminal('the'), 0, 1)\n",
        "            This means: we found 'the' in the sentence between 0 and 1\n",
        "        Span(Nonterminal('NP'), 4, 8) represents NP:4-8\n",
        "            This means: we found an NP that covers the part of the sentence between 4 and 8\n",
        "\n",
        "    Thus, Span holds a Terminal or a Nonterminal and wraps it between two integers.\n",
        "    This makes it possible to distinguish between two instances of the same rule in the derivation.\n",
        "    Example:\n",
        "        We can find that the rule NP -> Det N is used twice in the parse derivation. But that in the first\n",
        "        case it spans \"an elephant\" and in the second case it spans \"my pajamas\". We want to distinguis these.\n",
        "        So: \"an elephant\" is covered by [NP]:2-4 -> [Det]:2-3 [N]:3-4\n",
        "            \"my pajamas\" is covered by [NP]:5-7 -> [Det]:5-6 [N]:6-7\n",
        "\n",
        "    Internally, we represent spans with tuples of the kind (symbol, start, end).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol, start, end):\n",
        "        assert isinstance(symbol, Symbol), f\"A span takes an instance of Symbol, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "        self._start = start\n",
        "        self._end = end\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # a span delegates this to an underlying symbol\n",
        "        return self._symbol.is_terminal()\n",
        "\n",
        "    def obj(self):\n",
        "        \"\"\"The underlying python tuple (Symbol, start, end)\"\"\"\n",
        "        return (self._symbol, self._start, self._end)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints Symbol surrounded with begin and end (purely aesthetics)\"\"\"\n",
        "        return f\"{self._start}:{self._symbol}:{self._end}\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Span({self._symbol!r}, {self._start!r}, {self._end!r})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._symbol, self._start, self._end))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol and self._start == other._start and self._end == other._end\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW5SsW6sCGMD"
      },
      "source": [
        "Example usage of `Span`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwn43NFYCGME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e9e07e-d5b2-4423-b409-bd5fa60d1418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:[S]:10\n",
            "4:'dog':5\n",
            "2:[NP]:4 -> 2:[Det]:3 3:[NP]:4 (None)\n"
          ]
        }
      ],
      "source": [
        "span_S = Span(S, 0, 10)\n",
        "print(span_S)\n",
        "span_S = Span(dog, 4, 5)\n",
        "print(span_S)\n",
        "\n",
        "spanned_rule = Rule(Span(NP, 2, 4), [Span(Det, 2, 3), Span(NP, 3, 4)], prob=None)\n",
        "print(spanned_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4CFhArSpLL"
      },
      "source": [
        "Your final derivation should look like this:\n",
        "\n",
        "```\n",
        "[0:[S]:7 -> 0:[NP]:1 1:[VP]:7 (None),\n",
        " 0:[NP]:1 -> 0:'I':1 (None),\n",
        " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (None),\n",
        " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (None),\n",
        " 1:[V]:2 -> 1:'shot':2 (None),\n",
        " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (None),\n",
        " 2:[Det]:3 -> 2:'an':3 (None),\n",
        " 3:[N]:4 -> 3:'elephant':4 (None),\n",
        " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (None),\n",
        " 4:[P]:5 -> 4:'in':5 (None),\n",
        " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (None),\n",
        " 5:[Det]:6 -> 5:'my':6 (None),\n",
        " 6:[N]:7 -> 6:'pajamas':7 (None)]\n",
        " ```\n",
        "\n",
        "(Note that the rule probabilities are set to `None`. These are not saved in the backpointer chart so cannot be retrieved at the recovering stage. They also don't matter at this point, so you can set them to `None`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5iPPQ9kCGMF"
      },
      "outputs": [],
      "source": [
        "# @title build_tree function\n",
        "def build_tree(back, sentence, root, n2i, begin=0, end=None):\n",
        "    \"\"\"\n",
        "    Reconstruct the viterbi parse from a filled-in backpointer chart.\n",
        "    The function takes detailed arguments to be easily used in a recursive way.\n",
        "\n",
        "    It returns a list called derivation which holds the rules over Spans.\n",
        "    In order to use the function make_nltk_tree for the output,\n",
        "    you must make sure that the order in derivation follows the depth-first order (!!!).\n",
        "\n",
        "    :param back: a backpointer chart of shape [num_nonterminals, num_words+1, num_words+1]\n",
        "    :param sentence: a list of words\n",
        "    :param root: the root symbol of the tree: usually Nonterminal('S')\n",
        "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
        "    :param begin: index that marks the start of the target segment of the sentence\n",
        "    :param end: index that marks the end of the target segment of the sentence\n",
        "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
        "    :return derivation: a derivation: a list of Rules with Span symbols that generate the Viterbi tree.\n",
        "                        The list should be ordered depth first!\n",
        "    \"\"\"\n",
        "    if end is None: end = len(sentence)\n",
        "    assert isinstance(end, int), \"when end argument is specified, it needs to be an integer\"\n",
        "    derivation = []\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    root_index = n2i[root]\n",
        "    pointer = back[root_index][begin][end]\n",
        "\n",
        "    lhs = Span(root, begin, end)\n",
        "\n",
        "    if pointer == 0 or pointer is None:\n",
        "        word = sentence[begin]\n",
        "        rhs = [Span(Terminal(word), begin, end)]\n",
        "\n",
        "        # Find the probability for the unary lexical rule\n",
        "        prob = None\n",
        "        for rule in grammar.rules:\n",
        "            if rule.lhs == root and len(rule.rhs) == 1 and rule.rhs[0] == Terminal(word):\n",
        "                prob = rule.prob\n",
        "                break\n",
        "\n",
        "        derivation.append(Rule(lhs, rhs, prob))\n",
        "        return derivation\n",
        "\n",
        "    split, B, C = pointer\n",
        "    rhs = [Span(B, begin, split), Span(C, split, end)]\n",
        "\n",
        "    # Add the parent rule first\n",
        "    prob = None\n",
        "\n",
        "    for rule in grammar.rules:\n",
        "        if rule.lhs == root and list(rule.rhs) == [B, C]: # Convert rule.rhs into list before comparing because it was a tuple\n",
        "            prob = rule.prob\n",
        "            break\n",
        "    derivation.append(Rule(lhs, rhs, prob))\n",
        "\n",
        "    # Then recursively add the children\n",
        "    derivation += build_tree(back, sentence, B, n2i, begin, split)\n",
        "    derivation += build_tree(back, sentence, C, n2i, split, end)\n",
        "\n",
        "    return derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C-x98b5CGMG"
      },
      "source": [
        "Get your derivation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZCWB9n8CGMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b09a8ea-ce9b-4ece-bbb4-dcf3d7e844d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0:[S]:7 -> 0:[NP]:1 1:[VP]:7 (1.0),\n",
              " 0:[NP]:1 -> 0:'I':1 (0.2),\n",
              " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (0.6),\n",
              " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (0.4),\n",
              " 1:[V]:2 -> 1:'shot':2 (1.0),\n",
              " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (0.2),\n",
              " 2:[Det]:3 -> 2:'an':3 (0.6),\n",
              " 3:[N]:4 -> 3:'elephant':4 (0.5),\n",
              " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (1.0),\n",
              " 4:[P]:5 -> 4:'in':5 (1.0),\n",
              " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (0.2),\n",
              " 5:[Det]:6 -> 5:'my':6 (0.4),\n",
              " 6:[N]:7 -> 6:'pajamas':7 (0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "derivation = build_tree(back, sentence, S, n2i)\n",
        "derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7hKnXenUcyk"
      },
      "source": [
        "### Draw the tree\n",
        "\n",
        "Turn the derivation into an NLTK tree:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKPgJ9q5CGMG"
      },
      "outputs": [],
      "source": [
        "def make_nltk_tree(derivation):\n",
        "    \"\"\"\n",
        "    Return a NLTK Tree object based on the derivation\n",
        "    (list or tuple of Rules)\n",
        "    \"\"\"\n",
        "    d = defaultdict(None, ((r.lhs, r.rhs) for r in derivation))\n",
        "\n",
        "    def make_tree(lhs):\n",
        "        return Tree(str(lhs), (str(child) if child not in d else make_tree(child) for child in d[lhs]))\n",
        "\n",
        "    return make_tree(derivation[0].lhs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhh7YJLMUoIa"
      },
      "source": [
        "If you give the derivation to the function `make_nltk_tree` and let NLTK draw it, then you get this tree:\n",
        "\n",
        "```\n",
        "          0:[S]:7                                                                              \n",
        "    _________|_______________________________                                                   \n",
        "   |                                      1:[VP]:7                                             \n",
        "   |                     ____________________|_____________________                             \n",
        "   |                 1:[VP]:4                                   4:[PP]:7                       \n",
        "   |          __________|________                         _________|________                    \n",
        "   |         |                2:[NP]:4                   |               5:[NP]:7              \n",
        "   |         |           ________|___________            |          ________|___________        \n",
        "0:[NP]:1  1:[V]:2   2:[Det]:3             3:[N]:4     4:[P]:5  5:[Det]:6             6:[N]:7   \n",
        "   |         |          |                    |           |         |                    |       \n",
        "0:'I':1  1:'shot':2  2:'an':3          3:'elephant':4 4:'in':5  5:'my':6          6:'pajamas':7\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8KwEzfKNHsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bcdb3c-f218-43fb-e09b-929ba10049c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0:[S]:7                                                                              \n",
            "    _________|_______________________________                                                   \n",
            "   |                                      1:[VP]:7                                             \n",
            "   |                     ____________________|_____________________                             \n",
            "   |                 1:[VP]:4                                   4:[PP]:7                       \n",
            "   |          __________|________                         _________|________                    \n",
            "   |         |                2:[NP]:4                   |               5:[NP]:7              \n",
            "   |         |           ________|___________            |          ________|___________        \n",
            "0:[NP]:1  1:[V]:2   2:[Det]:3             3:[N]:4     4:[P]:5  5:[Det]:6             6:[N]:7   \n",
            "   |         |          |                    |           |         |                    |       \n",
            "0:'I':1  1:'shot':2  2:'an':3          3:'elephant':4 4:'in':5  5:'my':6          6:'pajamas':7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TEST EX1.2\n",
        "tree = make_nltk_tree(derivation)\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KpnoxfjCGMH"
      },
      "source": [
        "## That's it!\n",
        "\n",
        "Congratulations, you have made it to the end of the lab.\n",
        "\n",
        "**Make sure all your cells are executed so that all your answers are there. Then, continue if you're interested!**\n",
        "\n",
        "----\n",
        "\n",
        "## Optional\n",
        "\n",
        "If you managed to get your entire CKY-parser working and have an appetite for more, it might be fun to try it on some more sentences and grammars. Give the grammars below a try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQXFftl-CGMH"
      },
      "source": [
        "### Alternative Groucho-grammar\n",
        "\n",
        "If you change the probabilities in the grammar, you'll get a different parse as the most likely one. Compare `groucho-grammar-1.txt` with `groucho-grammar-2.txt` and spot the difference in probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmKzOKOrCGMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c040f1-0142-4a70-9ac5-705bd3c5fc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[PP] -> [P] [NP] (1.0)\n",
            "[NP] -> [Det] [N] (0.2)\n",
            "[NP] -> [Det] [NP] (0.3)\n",
            "[NP] -> [N] [PP] (0.3)\n",
            "[NP] -> 'I' (0.2)\n",
            "[VP] -> [V] [NP] (0.6)\n",
            "[VP] -> [VP] [PP] (0.4)\n",
            "[Det] -> 'an' (0.6)\n",
            "[Det] -> 'my' (0.4)\n",
            "[N] -> 'elephant' (0.5)\n",
            "[N] -> 'pajamas' (0.5)\n",
            "[V] -> 'shot' (1.0)\n",
            "[P] -> 'in' (1.0)\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "# Read in the grammar\n",
        "with open('groucho-grammar-2.txt') as F:\n",
        "    grammar = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQvNMXcpCGMI"
      },
      "source": [
        "### The man with the telescope\n",
        "\n",
        "Another ambiguous sentence:\n",
        "\n",
        "> I saw the man on the hill with the telescope.\n",
        "\n",
        "A grammar for this sentence is specified in the file `telescope-grammar.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saH1dFIkCGMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5839eb2e-6692-4874-acde-d4f89655ebce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[VP] -> [V] [NP] (0.6)\n",
            "[VP] -> [VP] [PP] (0.4)\n",
            "[NP] -> [NP] [PP] (0.3)\n",
            "[NP] -> [Det] [N] (0.3)\n",
            "[NP] -> [Det] [NP] (0.2)\n",
            "[NP] -> 'I' (0.2)\n",
            "[PP] -> [P] [NP] (0.8)\n",
            "[PP] -> [PP] [PP] (0.2)\n",
            "[V] -> 'saw' (1.0)\n",
            "[Det] -> 'the' (1.0)\n",
            "[N] -> 'man' (0.4)\n",
            "[N] -> 'hill' (0.3)\n",
            "[N] -> 'telescope' (0.3)\n",
            "[P] -> 'on' (0.5)\n",
            "[P] -> 'with' (0.5)\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "# Read in the grammar\n",
        "with open('telescope-grammar.txt') as F:\n",
        "    grammar = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4moydQnHy6"
      },
      "source": [
        "## Work description for Part 1\n",
        "\n",
        "YOUR ANSWER HERE [100-200 words]\n",
        "\n",
        "To solve ex1.1, we hard-coded the CKY algorithm, defining the lexical unary rules and assigning them a probability. Then we handled spans of increasing length, computing the probability of each rule and updating the score and backpointer charts accordingly.\n",
        "\n",
        "For ex 1.2, we used the backpointer chart - filled in the previous exercise - to code the \"build_tree\". Starting from the root $<S>$, this function performs spanning recurrently, based on the probabilities on the backpointer chart.\n",
        "\n",
        "Overall, the concepts were easy-to-understand and manageable Nevertheless, GenAI has been employed to treat arrays and matrices correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgQy4lRYf29y"
      },
      "source": [
        "# Part 2: Word sense disambiguation\n",
        "\n",
        "In this part we will use the BERT transformer model's contextualized word embeddings to tackle the word sense disambiguation (WSD) task. The approach consists of the following:\n",
        "\n",
        "1. Get the contextualized BERT embeddings for all tokens in a sense-annotated corpus;\n",
        "2. For each sense $s$, calculate a mean vector of all the vectors of the words that are tagged with the sense $s$ in the training part of the corpus;\n",
        "3. For each sense-annotated token $t$ in the test part of the corpus, assign $s$ sense to $t$ such that the vector of $s$ is the closest to the vector of $t$.\n",
        "4. As a backup strategy for tokens in the test part for which no sense vector was obtained from the training part (i.e., tokens with unseen senses), use the 1st sense of the token by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aVl7w4T7hm8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZG-F8YbYq5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513edde1-6db9-4131-d001-9edd48ea26f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assigntools'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 267 (delta 27), reused 6 (delta 3), pack-reused 200 (from 1)\u001b[K\n",
            "Receiving objects: 100% (267/267), 66.36 KiB | 557.00 KiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ],
      "source": [
        "# Course-specific package\n",
        "! rm -rf assigntools\n",
        "! git clone https://github.com/kovvalsky/assigntools.git\n",
        "from assigntools.NLP.deep_learning import transformer_word2convec\n",
        "from assigntools.M4LP.A1 import read_pickle, write_pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g5Rnh1FZaOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10b520d-6367-400b-ec6b-bd7f216a326d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import random, torch\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict, Counter\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "import nltk\n",
        "from more_itertools import chunked\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import semcor\n",
        "from nltk.corpus.reader.wordnet import Lemma\n",
        "nltk.download('semcor')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# append any imports if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10rIyb-EaTE5"
      },
      "source": [
        "## SemCor\n",
        "\n",
        "As a sense annotated corpus, we will use SemCor, conveniently available within NLTK. <code>semcor.sents()</code> iterates over all sentences represented as lists of tokens, while <code>semcor.tagged_sents()</code> iterates over the same sentences with additional annotation including WordNet Lemma identifiers (Lemma in WordNet stands for a particular sense of a word as opposed to a synset that is a set of Lemmas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjzGDH1Ef29y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7125897d-0c21-435e-fc6d-cf1d7f96946d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
            "[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), Tree(Lemma('state.v.01.say'), ['said']), Tree(Lemma('friday.n.01.Friday'), ['Friday']), ['an'], Tree(Lemma('probe.n.01.investigation'), ['investigation']), ['of'], Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']), [\"'s\"], Tree(Lemma('late.s.03.recent'), ['recent']), Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']), Tree(Lemma('produce.v.04.produce'), ['produced']), ['``'], ['no'], Tree(Lemma('evidence.n.01.evidence'), ['evidence']), [\"''\"], ['that'], ['any'], Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']), Tree(Lemma('happen.v.01.take_place'), ['took', 'place']), ['.']]\n",
            "['His', 'petition', 'charged', 'mental', 'cruelty', '.']\n",
            "[['His'], Tree(Lemma('request.n.01.petition'), ['petition']), Tree(Lemma('charge.v.06.charge'), ['charged']), Tree(Lemma('mental.a.02.mental'), ['mental']), Tree(Lemma('cruelty.n.02.cruelty'), ['cruelty']), ['.']]\n"
          ]
        }
      ],
      "source": [
        "# two sample sentence from the semcor corpus\n",
        "# with their corresponding sense-annotated versions\n",
        "for i in [0, 27]:\n",
        "    print(semcor.sents()[i])\n",
        "    print(semcor.tagged_sents(tag=\"sem\")[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xz-BK46f29z"
      },
      "source": [
        "Let's prepare SemCor data for the disambiguation task. Since this is just an educational exercise and we don't aim at replicating the full results, we can use only a subset of SemCor. Take the first $N$ sentences of SemCor, pre-process the data, shuffle the sample in the data **randomly**, and finally split the data into the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJxPaNl0f29z"
      },
      "outputs": [],
      "source": [
        "# Extract a part of the data for experiments\n",
        "N = 10_000\n",
        "semcor_annotated = list(semcor.tagged_sents(tag='sem')[:N])\n",
        "semcor_tokenized = list(semcor.sents()[:N])\n",
        "random.Random(42).shuffle(semcor_annotated)\n",
        "random.Random(42).shuffle(semcor_tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCMYa2O6f29z"
      },
      "source": [
        "## Ex2.1 [8pt] Preprocessing data\n",
        "\n",
        "Create a function that takes as input a collection of sense-annotated sentences from SemCor and extracts the sense annotation. For each token of the sentence get either the corresponding WordNet sense or <code>None</code>.\n",
        "<code>None</code> corresponds to tokens that are: (1) not annotated with a Lemma object sense (e.g. articles); (2) representing a part of a larger phrase that is annotated with a sense. The latter represents a simplification of the task.  \n",
        "More info about NLTK's Lemma and Tree objects can be found here: [Lemma](https://www.nltk.org/api/nltk.corpus.reader.wordnet.html) and [Tree](https://www.nltk.org/api/nltk.tree.tree.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIBT0eNff29z"
      },
      "outputs": [],
      "source": [
        "from nltk.tree import Tree\n",
        "\n",
        "def get_sns_annotations(data):\n",
        "    \"\"\" data - sense tagged data from semcor\n",
        "        return\n",
        "            the sense annotations as a list of lists.\n",
        "            The structure follows to semcor sentences and tokenization\n",
        "            The elements of the list are None or a tuple of strings\n",
        "            representing a synset and a lemma.\n",
        "            None annotation means that a word token has no sense annotation\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    annotations = []\n",
        "\n",
        "    for sentence in data:\n",
        "        sentence_annotations = []\n",
        "\n",
        "        for token in sentence:\n",
        "            if isinstance(token, Tree):\n",
        "                # If multi-word expression or named entity or complex tree structure, assign None to all tokens\n",
        "                if len(token.leaves()) > 1 or isinstance(token.label(), str) or token.height() > 2:\n",
        "                    sentence_annotations.extend([None] * len(token.leaves()))\n",
        "                else:\n",
        "                    # Single-token Tree with a Lemma label: extract annotation\n",
        "                    lemma = token.label()\n",
        "                    sentence_annotations.append((lemma.synset().name(), lemma.name()))\n",
        "            else:\n",
        "                # Plain token (string or list of strings): assign None for each token\n",
        "                sentence_annotations.extend([None] * len(token))\n",
        "\n",
        "        annotations.append(sentence_annotations)\n",
        "\n",
        "    return annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vcRK1QMhHXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddea2c6f-5b15-49fd-c842-40858ec0ee81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample sentence: ['The', 'bronchial', 'artery', ',', 'except', 'for', 'a', 'small', 'number', 'of', 'short', 'branches', 'in', 'the', 'hilum', ',', 'contributes', 'none', 'of', 'the', 'pleural', 'blood', 'supply', '.']\n",
            "sample annotation: [None, None, None, None, None, None, None, ('small.a.01', 'small'), ('number.n.02', 'number'), None, ('short.a.02', 'short'), ('branch.n.03', 'branch'), None, None, ('hilus.n.01', 'hilum'), None, ('contribute.v.02', 'contribute'), None, None, None, ('pleural.a.01', 'pleural'), ('blood.n.01', 'blood'), ('supply.n.01', 'supply'), None]\n",
            "sample sentence: ['It', 'just', 'did', \"n't\", 'occur', 'to', 'Trig', 'that', 'anything', 'serious', 'would', 'happen', 'to', 'him', '.']\n",
            "sample annotation: [None, ('merely.r.01', 'just'), None, None, ('occur.v.02', 'occur'), None, None, None, None, ('dangerous.s.02', 'serious'), None, ('happen.v.02', 'happen'), None, None, None]\n",
            "Total number of senses in the data = 84296\n"
          ]
        }
      ],
      "source": [
        "# TEST Ex2.1\n",
        "semcor_senses = get_sns_annotations(semcor_annotated)\n",
        "\n",
        "print(\"sample sentence:\", semcor_tokenized[0])\n",
        "print(\"sample annotation:\", semcor_senses[0])\n",
        "\n",
        "print(\"sample sentence:\", semcor_tokenized[13])\n",
        "print(\"sample annotation:\", semcor_senses[13])\n",
        "\n",
        "print(\"Total number of senses in the data =\", len([ t for s in semcor_senses for t in s if t ]))\n",
        "\n",
        "# test that for all sentences token number and annotation length are the same\n",
        "for i, (senses, tokenized) in enumerate(zip(semcor_senses, semcor_tokenized, strict=True)):\n",
        "    assert len(senses) == len(tokenized), \\\n",
        "        f\"mismatch for {i}th sentence\\n{senses}\\n{tokenized}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMldhpzYEnXq"
      },
      "source": [
        "Reference output:\n",
        "```\n",
        "sample sentence: ['The', 'bronchial', 'artery', ',', 'except', 'for', 'a', 'small', 'number', 'of', 'short', 'branches', 'in', 'the', 'hilum', ',', 'contributes', 'none', 'of', 'the', 'pleural', 'blood', 'supply', '.']\n",
        "sample annotation: [None, None, None, None, None, None, None, ('small.a.01', 'small'), ('number.n.02', 'number'), None, ('short.a.02', 'short'), ('branch.n.03', 'branch'), None, None, ('hilus.n.01', 'hilum'), None, ('contribute.v.02', 'contribute'), None, None, None, ('pleural.a.01', 'pleural'), ('blood.n.01', 'blood'), ('supply.n.01', 'supply'), None]\n",
        "sample sentence: ['It', 'just', 'did', \"n't\", 'occur', 'to', 'Trig', 'that', 'anything', 'serious', 'would', 'happen', 'to', 'him', '.']\n",
        "sample annotation: [None, ('merely.r.01', 'just'), None, None, ('occur.v.02', 'occur'), None, None, None, None, ('dangerous.s.02', 'serious'), None, ('happen.v.02', 'happen'), None, None, None]\n",
        "Total number of senses in the data = 84296\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL_hd1y1es7z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run the following to get a reference data for comparison\n",
        "# If your data differs from the reference, use the reference data in the subsequent parts\n",
        "# !rm -f semcor_senses.pkl\n",
        "# !wget -nv https://naturallogic.pro/_files_/download/mNLP/semcor_senses.pkl\n",
        "# semcor_senses = read_pickle(\"semcor_senses.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xboZFvxBf290"
      },
      "outputs": [],
      "source": [
        "# create training and test sets\n",
        "train_N = 9_000\n",
        "semcor_X = {'train':semcor_tokenized[:train_N], 'test':semcor_tokenized[train_N:]}\n",
        "semcor_Y = {'train':semcor_senses[:train_N], 'test':semcor_senses[train_N:]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8RjCtWAnkOw"
      },
      "source": [
        "## BERT's contextualized vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JyNoPGWf290"
      },
      "source": [
        "After we have the training and test sets prepared with their gold sense annotations, it is time to get sense vectors for those senses that are occurring in the training set. Note that **contextualized vectors are crucial for the task** as a word (e.g., \"book\", \"plant\", \"figure\") can have different senses in different contexts.\n",
        "\n",
        "We will use BERT transformer model to get contextualized word vectors for the words in the training and test sets. We will use the implementation of BERT in pytorch from the [transformers library](https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "Getting word vectors from BERT is not trivial as it uses a different type of tokenization than the traditional one. For example, the base-uncased version of BERT expects `Jupyter` tokenized as `ju`, `##py`, `##ter` while `Notebook` as `notebook` (note the lower casing of tokens due to the uncased version of BERT). To distinguish these two versions of tokenization and tokens, we will use `tokens` for BERT tokens and words for traditional tokenization. For example, the SemCor sentences use traditional tokenization.\n",
        "\n",
        "If you want to learn more about BERT, [this](http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/) represents a gentle intro to BERT's wordpiece-based tokenizatio and contextualized word vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Aah2bg9sAja"
      },
      "outputs": [],
      "source": [
        "# if this cell errors with \"A UTF-8 locale is required. Got ANSI_X3.4-1968\"\n",
        "# uncomment and run the next two lines\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "# install transformer library\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__NtRqd_f291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5d2de5-f576-48e8-9570-7b88b1e28ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.52.4\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, AutoTokenizer\n",
        "print(transformers.__version__) # 4.41.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I2kwYUXk4Uo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "90207b49155f494c8ef3a48c70212eab",
            "e1f2d7a1fd5740d6b513ecc90e7f9a52",
            "51152b672cc0474fadbbe12fb9b8b6c6",
            "4467aec407d249efa0261b53817242ce",
            "2c8aaace75a546a7b33367296d32c3a8",
            "134fd0f607b24dc5828536be8b1e5f09",
            "a7b61c5fd27f46998a803d0ad5d9f315",
            "56460b15af144944b30429d20c4ae220",
            "4ffe2b4bf0a7447999bbbd3dc44637e0",
            "9806fcac0e7a44dab1e02083136ee5a5",
            "154471849dfe4d73bbf451314d5fb893",
            "026c8964ef2c43abb697f63cb87f8ab0",
            "193c1bd1af954f30bd66ac758978a8c8",
            "e93496d281864e3090530678f6c82589",
            "413b739790a54935ad723fccf23d9ab3",
            "d43079d51f2244b0a69567f3bc7de743",
            "9af1b9935d3a4ec29fcd8cb3188c821d",
            "6c8553da956c437f88b9b254b31954d2",
            "1e48b660802a42b395d3595b278b04c9",
            "bac3a68964ae4c759e0fff152dd39e76",
            "af0f04f01de746a48bf94a2a34f97885",
            "3e98bf487c5649438a681cf2b3636b61",
            "a6623758527142cca3f21d2b3541054a",
            "693c94dff1404bbf8a8b2d91120ac50c",
            "ec43481b65174b258e797b4215ecf66c",
            "aef66578063a4e2aac522b973b1a549b",
            "88133164e7ed4cf6b7527fd9ef3ec2e4",
            "4362fd523a4c435c90d63fead16b1a41",
            "1ba2ea01cc8d442d95c1d80a44433f92",
            "782cfc3ea8984c41bfc589b2676e7d87",
            "65aef184b91c40a480bed5710c262d56",
            "787c9fb95bf249668c003eda3ac83275",
            "764c8a660b5442a6bfce73ea7ed2ec95",
            "8ee38400adb444f1b65a5aece48a4121",
            "b3e57d855f734f3ab9d37d2e9bac0047",
            "d61ee32f13a947159ad2e0e27c7e503e",
            "ea636f49ab89445cb266e5203f36ff9c",
            "a20595c7fcc545de91b20f64850f8efd",
            "dbc20ce0532344e9907c62156ea3918b",
            "2054b00bcfbd4a679bee002d37094ae2",
            "f2f74fe75ea14649b689cb84d478a604",
            "e7e9d60937ba4286942962723e95e32e",
            "df70770e71f74682af5ae17b5600fb1b",
            "cdc323129d754705a7125a06265c1594"
          ]
        },
        "outputId": "7d0c23d6-2a9d-454a-8698-b8a4a4f696e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90207b49155f494c8ef3a48c70212eab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "026c8964ef2c43abb697f63cb87f8ab0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6623758527142cca3f21d2b3541054a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ee38400adb444f1b65a5aece48a4121"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load tokenizer (vocabulary)\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TniSOKjXsSYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59090003-50fd-49fc-dc47-7fabf6939abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the token vocabulary 30522\n",
            "'dog' has index 3899\n",
            "'##tion' has index 3508\n",
            "Reverse mapping: 3899 --> dog\n",
            "Reverse mapping: 3508 --> ##tion\n"
          ]
        }
      ],
      "source": [
        "# As usual, tokens are mapped to indices\n",
        "print(\"The size of the token vocabulary\", len(tokenizer.vocab))\n",
        "for tok in (\"dog\", \"##tion\"):\n",
        "    print(f\"'{tok}' has index {tokenizer.vocab[tok]}\")\n",
        "\n",
        "for i in (3899, 3508):\n",
        "    print(f\"Reverse mapping: {i} --> {tokenizer.convert_ids_to_tokens(i)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL1wil6ctdNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60533925-8262-4433-a6f1-504672c7e250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of a tokenizer:  {'input_ids': [101, 19081, 1999, 18414, 7685, 3334, 14960, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Tokens as word pieces:  ['[CLS]', 'transformers', 'in', 'ju', '##py', '##ter', 'notebook', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "example_input = \"Transformers in Jupyter Notebook\"\n",
        "tok_result = tokenizer(example_input)\n",
        "print(\"Output of a tokenizer: \", tok_result)\n",
        "print(\"Tokens as word pieces: \", tokenizer.convert_ids_to_tokens(tok_result.input_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3sMSQztupXy"
      },
      "source": [
        "`[CLS]` and `[SEP]` are special tokens use by BERT. `[CLS]` gets a vector that models the meaning of the entire input text sequence while `[SEP]` indicates sequence delimiters. Note that one of the tasks BERT was pre-trained on was guessing the next sentence, hence it was trained on sequence modeling, where elements of the sequence are sentences. Note that the output of `tokenizer([S1, S2])` and `tokenizer(S1, S2)` differ as in the first case the input is interpreted as a batch of two independent texts while in the second it is a sequence of texts.\n",
        "\n",
        "The output of the tokenizer provides a sufficient input for BERT to process the input and assign contextualized embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mdwEKBcf291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "c19cd6d5eafb45efa0bb963f0391e51f",
            "f1d82353e809461b90735d0abc10f416",
            "dae99e240d6e47bf8767a0f2d3894d68",
            "79d33a990c59422f9755967c6a400fe7",
            "355a8dda7e1048d3bd69d25c1a1893e7",
            "bce6331ea4f548c3bab41d22d8b42036",
            "4eb650af9d0f478182dda58329fc22c9",
            "104407f70d784931b2567af9e13c7ec6",
            "45a7cf2b57894be2967003efb0cec6ee",
            "e79aa1d425824c8299cd30356c66d2aa",
            "e111e1593a87428295a1890f93ed2771"
          ]
        },
        "outputId": "9e0a9d01-bed5-4a16-a901-37bf1351ede1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c19cd6d5eafb45efa0bb963f0391e51f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.module.Module.parameters</b><br/>def parameters(recurse: bool=True) -&gt; Iterator[Parameter]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py</a>Return an iterator over module parameters.\n",
              "\n",
              "This is typically passed to an optimizer.\n",
              "\n",
              "Args:\n",
              "    recurse (bool): if True, then yields parameters of this module\n",
              "        and all submodules. Otherwise, yields only parameters that\n",
              "        are direct members of this module.\n",
              "\n",
              "Yields:\n",
              "    Parameter: module parameter\n",
              "\n",
              "Example::\n",
              "\n",
              "    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)\n",
              "    &gt;&gt;&gt; for param in model.parameters():\n",
              "    &gt;&gt;&gt;     print(type(param), param.size())\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L,)\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L, 1L, 5L, 5L)</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2608);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Load pre-trained model (weights)\n",
        "bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "#print parameters\n",
        "bert.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AsRE_wvw5aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579f0e82-4119-47b2-dd97-a98d466dc4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the last (12th) hidden states (batch size X token number X vector dim):  torch.Size([1, 8, 768])\n"
          ]
        }
      ],
      "source": [
        "# let bert output hidden states\n",
        "bert.config.output_hidden_states = True\n",
        "# bert expects tensors as an input\n",
        "tok_result = tokenizer(example_input, return_tensors='pt')\n",
        "bert_output = bert(**tok_result)\n",
        "print(\"Dimension of the last (12th) hidden states (batch size X token number X vector dim): \", bert_output.hidden_states[-1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0mDqT17zOTE"
      },
      "source": [
        "Due to non-trivial correspondence between BERT tokens and words, we provide you with a ready function that takes a batch/list of word-tokenized sentences and processes them with the BERT model. In the end, it returns contextualized word vectors for each input word. The vector of the words that consist of several tokens is obtained by collating token vectors (e.g., taking the mean by default). The function allows to indicate from which layer the vectors should be extracted. For more details you can read the function definition [here](https://github.com/kovvalsky/assigntools/blob/main/NLP/deep_learning.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLvl8jTZ0J3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40957887-46a9-434c-86c2-cfe9b1223b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are using cuda\n",
            "'Transformers' tokenized as ['transformers'] with tensor (first 3 components) tensor([-0.2651, -0.0888, -0.1850])\n",
            "'in' tokenized as ['in'] with tensor (first 3 components) tensor([ 0.8255,  0.1081, -0.4694])\n",
            "'Jupyter' tokenized as ['ju', '##py', '##ter'] with tensor (first 3 components) tensor([-0.1719, -0.5191,  0.3761])\n",
            "'Notebook' tokenized as ['notebook'] with tensor (first 3 components) tensor([-0.2273, -0.4334,  0.7509])\n",
            "\n",
            "'Transformers' tokenized as ['transformers'] with tensor (first 3 components) tensor([-0.4967,  0.0918, -0.0243])\n",
            "'visited' tokenized as ['visited'] with tensor (first 3 components) tensor([ 1.2033, -0.1839, -0.5399])\n",
            "'the' tokenized as ['the'] with tensor (first 3 components) tensor([-0.8393,  0.1038,  0.2743])\n",
            "'earth' tokenized as ['earth'] with tensor (first 3 components) tensor([-0.8355, -0.2884, -0.1953])\n",
            "\n",
            "tensor([-0.2651, -0.0888, -0.1850,  0.4485,  0.1538])... != tensor([-0.4967,  0.0918, -0.0243,  0.1993, -0.2419])...\n",
            "vectors cosine similarity = 0.9091211557388306\n"
          ]
        }
      ],
      "source": [
        "# Batches with GPU accelerates the process ~30 times when used T4 GPU of colab compared to CPU\n",
        "# Obviously for this toy example, efficiency doesn't matter\n",
        "# this identifies whether GPU is present\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"we are using\", device)\n",
        "\n",
        "sample_batch = [ \"Transformers in Jupyter Notebook\".split(), \"Transformers visited the earth\".split() ]\n",
        "sample_output = transformer_word2convec(bert, tokenizer, sample_batch, device=device, collate_tok_vec=torch.mean, layer=-1)\n",
        "\n",
        "# illustrating the output\n",
        "for sent in sample_output:\n",
        "    for w in sent:\n",
        "        print(f\"'{w['word']}' tokenized as {w['tokens']} with tensor (first 3 components) {w['pt'][:3]}\")\n",
        "    print()\n",
        "\n",
        "# Comparing vectors of two occurrences of \"Transformers\"\n",
        "tvec1, tvec2 = sample_output[0][0]['pt'], sample_output[1][0]['pt']\n",
        "print(f\"{tvec1[:5]}... != {tvec2[:5]}...\")\n",
        "print(f\"vectors cosine similarity = {F.cosine_similarity(tvec1, tvec2, dim=0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3czfz2Pbf292"
      },
      "source": [
        "## Ex2.2 [10pt] Sense vectors\n",
        "\n",
        "Process the training set with BERT using `transformer_word2convec` with default parameters. After getting word vectors, iterate over all train sentences, and for each sense, collect the word vectors. Note that words without sense annotations will be ignored in this process.\n",
        "\n",
        "Since senses in the same WordNet synset are considered equivalent, we will be using synsets as sense labels. Prepare a dictionary with synset `(synset_str)` as a key and a single tensor as a value. The tensor should be a mean of all the word vectors collected for the sense (this is a default collating method used by `transformer_word2convec`).\n",
        "\n",
        "This process is a time-consuming part of this assignment. It is recommended to use Colab's GPU: max 5min of T4 GPU will suffice to process all sentences with BERT. While processing the sentences, use batches of size 64 (Hint: `chunked` from `more_itertools` can do batching for you). Note that batches make a big difference with GPU. For the purposes of developing and debugging your solution, you may start by using a sample of 100 sentences, but then switch to the full training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TDxnJP8f293"
      },
      "outputs": [],
      "source": [
        "# you can reuse global vars bert and tokenizer\n",
        "def get_sense2vec(data_X, data_Y, batch_size=64, device=device, collate=torch.mean):\n",
        "    \"\"\" data_X and data_Y are a list of tokenized semcor sentences with their corresponding sense annotations.\n",
        "        The last two arguments are the same as in transformer_word2convec\n",
        "        Returns 2 dictionaries:\n",
        "            Sense2VecList - { synset_str -> list of tensors  }\n",
        "            Sense2AvgVec - { synset_str -> a mean tensor  }\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    sense2veclist = defaultdict(list)\n",
        "\n",
        "    # Process data in batches\n",
        "    for batch_X, batch_Y in zip(chunked(data_X, batch_size), chunked(data_Y, batch_size)):\n",
        "        # Get BERT embeddings for the batch\n",
        "        batch_embeddings = transformer_word2convec(bert, tokenizer, batch_X, device=device, collate_tok_vec=collate, layer=-1)\n",
        "\n",
        "        # Process each sentence in the batch\n",
        "        for sent_embeddings, sent_senses in zip(batch_embeddings, batch_Y):\n",
        "            for word_embedding, sense in zip(sent_embeddings, sent_senses):\n",
        "                if sense is not None:  # Only consider words with sense annotations\n",
        "                    synset_str = sense[0]  # Get the synset string\n",
        "                    sense2veclist[synset_str].append(word_embedding['pt'])\n",
        "\n",
        "    sense2avgvec = {}  # Dictionary to store the average vector for each sense\n",
        "\n",
        "    for synset, vectors in sense2veclist.items():\n",
        "        # Stack the list of vectors into a single tensor (shape: [num_vectors, 768])\n",
        "        stacked = torch.stack(vectors)\n",
        "\n",
        "        # Compute the mean vector along the 0th dimension (i.e., average across all vectors)\n",
        "        avg_vector = stacked.mean(dim=0)\n",
        "\n",
        "        # Store the result in the dictionary\n",
        "        sense2avgvec[synset] = avg_vector\n",
        "\n",
        "    return sense2avgvec, sense2veclist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmdAbnmN0XOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc23b5f-c826-460e-ac6f-42b766c5d56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 3s, sys: 357 ms, total: 1min 4s\n",
            "Wall time: 1min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# ~50min with CPU, less than 2min with T4 GPU\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "Sense2AvgVec, Sense2VecList = get_sense2vec(semcor_X['train'], semcor_Y['train'], batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG3cgmUIOxsl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If you want to use reference vectors for next exercises, run the following:\n",
        "# !rm -f Sense2AvgVec.pkl\n",
        "# !wget -nv https://naturallogic.pro/_files_/download/mNLP/Sense2AvgVec.pkl\n",
        "# Sense2AvgVec = read_pickle(\"Sense2AvgVec.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8O6xolyl0_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9761f995-5a63-41ce-a413-51b0cd74c2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mature.v.01 sense has 3 vectors with the mean vector = tensor([ 0.0587,  0.0471, -0.4079, -0.1624,  0.2848,  0.0910,  0.6782,  0.3704]) ...\n",
            "promptly.r.01 sense has 6 vectors with the mean vector = tensor([-0.2618,  0.0485,  0.1117,  0.0635,  0.5795, -0.1821,  0.0408,  1.0724]) ...\n",
            "state.v.01 sense has 410 vectors with the mean vector = tensor([ 0.3054,  0.2383, -0.0089, -0.0291,  0.2214,  0.0783,  0.2360,  0.5706]) ...\n",
            "be.v.01 sense has 2465 vectors with the mean vector = tensor([ 0.0400,  0.0864,  0.0222, -0.0710,  0.2275, -0.0252,  0.2669,  0.5936]) ...\n"
          ]
        }
      ],
      "source": [
        "# TEST Ex2.2\n",
        "for sns in [ 'mature.v.01', 'promptly.r.01', 'state.v.01', 'be.v.01']:\n",
        "    assert isinstance(Sense2VecList[sns], list)\n",
        "    assert isinstance(Sense2VecList[sns][0], torch.Tensor)\n",
        "    assert isinstance(Sense2AvgVec[sns], torch.Tensor)\n",
        "    print(f\"{sns} sense has {len(Sense2VecList[sns])} vectors with the mean vector = {Sense2AvgVec[sns][:8]} ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jldmhkypa0p-"
      },
      "source": [
        "Reference output\n",
        "```\n",
        "mature.v.01 sense has 3 vectors with the mean vector = tensor([ 0.0587,  0.0471, -0.4079, -0.1624,  0.2848,  0.0910,  0.6782,  0.3704]) ...\n",
        "promptly.r.01 sense has 6 vectors with the mean vector = tensor([-0.2618,  0.0485,  0.1117,  0.0635,  0.5795, -0.1821,  0.0408,  1.0724]) ...\n",
        "state.v.01 sense has 410 vectors with the mean vector = tensor([ 0.3054,  0.2383, -0.0089, -0.0291,  0.2214,  0.0783,  0.2360,  0.5706]) ...\n",
        "be.v.01 sense has 2465 vectors with the mean vector = tensor([ 0.0400,  0.0864,  0.0222, -0.0710,  0.2275, -0.0252,  0.2669,  0.5936]) ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeP1NVl6f294"
      },
      "source": [
        "## Ex2.3 [12pt] WSD testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hDY0vO4f294"
      },
      "source": [
        "Now we are going to evaluate the sense embeddings on the test set. Write a function that takes a list of tokenized sentences and a mask that indicates which words are supposed to get senses. The function should return the sense predictions aligned with the sentences. When predicting a sense for a word token, use the strategy outlined above, with 1st WordNet sense as a fallback. Here is the strategy in more detail:\n",
        "\n",
        "- Use the sense vectors that were calculated based on the training set;\n",
        "- For each sense-annotated word token $t$ (e.g. the verb `run`) in the test set, predict the synset $s$ (e.g., `'run.x.xx'`) such that the vector of $s$ is the closest to the contextualized vector of $t$ based on the cosine distance metric. Also make sure that the predicted sense is applicable to a word token using [`wn.synsets()`](https://www.nltk.org/howto/wordnet.html).\n",
        "- There will be word tokens $t$ in the test set for which there won't be a sense vector collected from the training set, i.e., unseen senses. For such word tokens, us a backup strategy and predict the 1st sense of the word from WordNet, which is the most common sense of the word. This can be done using a built-in function from NLTK (e.g. <code>wn.lemmas('run')[0]</code>). For more info about NLTK's WordNet API, check [this](https://www.nltk.org/howto/wordnet.html).\n",
        "\n",
        "Note that the info that a word token has a gold sense unseen in the training set (provided by the mask argument), is not realistic info as it presupposes knowledge about gold annotations.\n",
        "\n",
        "Below you are provided with the sense masking that indicates whether a word token gets a sense and whether its sense was seen in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAUMf_dFHcDO"
      },
      "outputs": [],
      "source": [
        "# masking of annotations: None - has NO sense annotation; True - has sense annotation and the sense\n",
        "# was seen in the training set; False - has sense annotation but the sense was NOT seen in the training set\n",
        "test_sense_mask = [ [ i if i is None else ( True if i[0] in Sense2AvgVec else False ) for i in s ] \\\n",
        "                        for s in semcor_Y['test'] ]\n",
        "\n",
        "def wsd_accuracy(predictions, reference, verbose=False):\n",
        "    \"\"\" Calculates accuracy with respect to the word tokens that get sense annotations.\n",
        "    \"\"\"\n",
        "    true_and_false = []\n",
        "    for preds, refs in zip(predictions, reference, strict=True):\n",
        "        for (p, r) in zip(preds, refs, strict=True):\n",
        "            if r is not None:\n",
        "                true_and_false.append(p == r[0])\n",
        "                if verbose and p != r[0]:\n",
        "                    print(f\"wrong prediction ({p}) for ({r})\")\n",
        "    return sum(true_and_false)/len(true_and_false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGHvYdzbaI1a"
      },
      "outputs": [],
      "source": [
        "def predict_senses(sense2vec, sentences, sense_mask, fallback=False,\n",
        "                   batch_size=BATCH_SIZE, bert=bert, tokenizer=tokenizer, device=device, verbose=False):\n",
        "    \"\"\" sense2vec - a dictioanry from synset strings to torch tensor vectors\n",
        "        sentences - a list of sentences each being a list of word tokens\n",
        "        sense_mask - it is aligned with tokens of sentences and tells if a token gets sense\n",
        "                    and what type sense, seen or unseen in the training set.\n",
        "        fallback - if True it uses first sense as the option for tokens with unseen senses.\n",
        "        batch_size - the number of sentences is a batch\n",
        "        bert, tokenizer - bert model and a tokenizer compatible with it\n",
        "        device - a cpu or a gpu/cuda device that will be used by bert and tensor computations\n",
        "        verbose - Prints whatever you want when it is False\n",
        "        return predictions\n",
        "            a list of list of predictions (None or a synset as a string) where the structure\n",
        "            is aligned with the sentences\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    # Process in batches\n",
        "    for batch_X, batch_mask in zip(chunked(sentences, batch_size), chunked(sense_mask, batch_size)):\n",
        "        # Get contextualized embeddings\n",
        "        batch_embeddings = transformer_word2convec(\n",
        "            bert, tokenizer, batch_X,\n",
        "            device=device, collate_tok_vec=torch.mean, layer=-1\n",
        "        )\n",
        "\n",
        "        for sentence_vecs, mask_row, tokens in zip(batch_embeddings, batch_mask, batch_X):\n",
        "            sentence_preds = []\n",
        "\n",
        "            for token_vec, mask, token in zip(sentence_vecs, mask_row, tokens):\n",
        "                if mask is None:\n",
        "                    sentence_preds.append(None)\n",
        "                    continue\n",
        "\n",
        "                # Get possible senses of the token using WordNet\n",
        "                possible_synsets = wn.synsets(token)\n",
        "\n",
        "                if not possible_synsets:\n",
        "                    sentence_preds.append(None)\n",
        "                    continue\n",
        "\n",
        "                # If the token has a seen sense (True in mask)\n",
        "                if mask is True:\n",
        "                    # Filter to possible synsets present in training\n",
        "                    valid_synsets = [s.name() for s in possible_synsets if s.name() in sense2vec]\n",
        "\n",
        "                    if not valid_synsets:\n",
        "                        sentence_preds.append(None)\n",
        "                        continue\n",
        "\n",
        "                    # Stack all candidate sense vectors\n",
        "                    synset_vecs = torch.stack([sense2vec[syn] for syn in valid_synsets]).to(device)\n",
        "                    token_vec = token_vec['pt'].to(device)\n",
        "\n",
        "                    # Compute cosine similarities\n",
        "                    sims = F.cosine_similarity(token_vec.unsqueeze(0), synset_vecs)\n",
        "                    best_idx = torch.argmax(sims).item()\n",
        "                    sentence_preds.append(valid_synsets[best_idx])\n",
        "\n",
        "                # If the token has an unseen sense (False in mask)\n",
        "                elif fallback and mask is False:\n",
        "                    # Use the most frequent WordNet sense\n",
        "                    first_synset = possible_synsets[0].name()\n",
        "                    sentence_preds.append(first_synset)\n",
        "                else:\n",
        "                    sentence_preds.append(None)\n",
        "\n",
        "            predictions.append(sentence_preds)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfWacHi4QV15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06ca29a-c41f-440f-f701-57687337cb27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy of BERT      = 0.6520353114271702\n",
            "Accuracy of BERT + WN = 0.6972780774889652\n"
          ]
        }
      ],
      "source": [
        "# TEST Ex2.3\n",
        "# DON'T DELETE THE OUTPUT\n",
        "# expected runtime less than a minute\n",
        "predictions = predict_senses(Sense2AvgVec, semcor_X['test'], test_sense_mask)\n",
        "predictions_fb_ssl = predict_senses(Sense2AvgVec, semcor_X['test'], test_sense_mask, fallback=True)\n",
        "\n",
        "print(\"\\nAccuracy of BERT      =\", wsd_accuracy(predictions, semcor_Y['test']))\n",
        "print(\"Accuracy of BERT + WN =\", wsd_accuracy(predictions_fb_ssl, semcor_Y['test']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MfEISf7TSfE"
      },
      "source": [
        "Reference output (where `X<Y`):\n",
        "\n",
        "```\n",
        "Accuracy of BERT      = 0.6X...\n",
        "Accuracy of BERT + WN = 0.6Y...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbnGJ3sBiYac"
      },
      "source": [
        "## Further experiments\n",
        "\n",
        "Congratulations! You have reached the end of lab 4.\n",
        "\n",
        "If you want an additional challenge, you can carry out further experiments on WSD task. Note that in the experiments we used the vectors from the last layer of BERT, but several research papers have shown that the vectors from different layers also encode useful information.\n",
        "\n",
        "1.   You can test whether the vectors from other layers perform better than the last layer vectors.\n",
        "2.   Word (and sense vectors) can be defined in terms of the combinations of the vectors from several layers of BERT. You can verify whether concatenating vectors from different layers (e.g., a concatenation of vectors from the last two layers) performs better than the vectors from the single layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaWMLZiyVln-"
      },
      "source": [
        "## Work description for Part 2\n",
        "\n",
        "YOUR ANSWER HERE [100-200 words]\n",
        "\n",
        "The most challenging part was the `get_sns_annotations` function from Exercise 1.1, specifically getting the total number of senses in the data correct. Exercise 2.2 was pretty straightforward. Exercise 2.3 was more complicated, especially using the mask correctly for the fallback strategy. GenAI was used for understanding the exercises, debugging and refining functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dQpGR5idvL9"
      },
      "source": [
        "# Part 3: Generalization & explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8iGAJ2TzsxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595ce91b-5db7-463d-a56c-58c7ea8abf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        }
      ],
      "source": [
        "# necessary to update datasets module for compatibility\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEmX4622d7xP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d836db9d-9846-4588-dd84-15424f68f94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers=4.52.4\n",
            "torch=2.6.0+cu124\n",
            "datasets=3.6.0\n"
          ]
        }
      ],
      "source": [
        "# @title imports\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "print(f\"transformers={transformers.__version__}\")\n",
        "import torch\n",
        "print(f\"torch={torch.__version__}\")\n",
        "import datasets\n",
        "print(f\"datasets={datasets.__version__}\")\n",
        "from datasets import load_dataset\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQyD78K-dSOo"
      },
      "source": [
        "## Task description\n",
        "\n",
        "In this part, we will test one of the LLMs (which can be run in colab's modest environment) on the generalization and explainability while using chain-of-thought prompting ([Wei et al. 2022](https://arxiv.org/abs/2201.11903)).  \n",
        "We will use an instruct model, a model that needs to be instructed with prompts to make predictions and doesn't need to be trained. So, we will use the model for inference and not for training or fine-tuning. Nonetheless, even Colab's least powerful GPU, such as T4, will be of practical use.  \n",
        "Let's load an instruct model, in particular, `Phi-3-mini-4k-instruct` (see its [model card](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) for details), and make a processing pipeline out of it. We use this model as it is optimal for the Colab environment and has very good results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTTqFsQtdxgg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763,
          "referenced_widgets": [
            "21e63e4c588f484f803156854cff2868",
            "f088843e1d104ba0be277e982fd0b77a",
            "0632574d04524d88be672e8e9e3228b0",
            "e15c2340012f4c54bd465035433757ce",
            "5bc5689c60644299bc8ea229d3ca9879",
            "2a18a548ae6540c2b04ce175b5970937",
            "908def6077b94631939810e63ca66b25",
            "7c0a1e69ced042c49d91cfa5c3a76991",
            "d26a94d351a7455a8d04b65c72c404f2",
            "6e23d3e9ad724bc5b0bdbf4f0bc01cca",
            "68da8e5d207047579ffc24408f70caf2",
            "0af61600bebe4ab28ed5b5139b25da21",
            "3a3f0708605b4834b87c363614127093",
            "b2b839ff14404514989ef54eb8fc6acf",
            "1e70d8128301485b8588f61e8cbf77b1",
            "167445d15cb54fc48a8c93ddefa6c420",
            "93e5bb4da82a45afb4a58b324ce58686",
            "9f194c775df54980a2ab20ef71fc4e99",
            "5b84ee32027a4ec68ab06c74adcad021",
            "4fcfbb3c46354b3f979a1b9d4d0b7b20",
            "e3f6d5ec20cc46df84188c9477eddd51",
            "e8b551cea64949deb5cb84116be8b200",
            "bbcab8ed07c547b1947fa9e5312ec597",
            "f4a9456d00ec4df8b1ca38cc53a49a5e",
            "d56b39710318481d929b140b7f43fd5c",
            "5e17c26e356f445bb9989873fa07c4fd",
            "0ff807a9f6fc4834afcac95210214af0",
            "52ff25fe78ec4c848bd0e1e188e25a39",
            "76acba0103444288a26ec7fd1b1c89c2",
            "1c886dd566554be990c2210de37fcf8d",
            "47085965bd9f4e289a71b41ac2b78c98",
            "78425bd22d974b548191175e3558afe0",
            "4f3a55b12fd745a0a78cc0480d275e53",
            "5d5bc143a4b64210beb63d231570ff49",
            "f7933bf3f20542eca27d58e06b9cedbc",
            "443dcafd2c554e659b85e959c29bd224",
            "41f2516284c345f295461761a0b75b30",
            "d21624ef16fc40cdb933a5553a2f88aa",
            "81d4b212666949958fcfa323c73c5e63",
            "a363abccb6914d199e6811fac9ff30ef",
            "5af221297c5d48ce896afa3521614fb5",
            "674d6a3f786f48179e7a156a2e62f105",
            "4c9fa9d40d984344ad2003021ed5dd8d",
            "269b5648ddac4d5ca57bc39cc6eb941e",
            "db8d2a25d61f4c53a32eaef3a5544041",
            "bc86ffcbba8042319eee9b9a1499ce24",
            "e5afa3fbd45046869710096ee32fa654",
            "ff2dbd72a3dd4383a3478d54dc7a866d",
            "a280b889931d4c4186b4c8d102e175aa",
            "2a28e646c81e46d0b28501c196418efd",
            "230c2c43834e4ffe8c24d7ea8fe08a5a",
            "999ea89a48ac4e49820112465104afef",
            "c7b00b48ccc64edf830e9ad1faa83815",
            "1172d6eaf34840e582012db07ff4ce16",
            "ee1f7076465e4ab78677f13d277e66ce",
            "bb9863d634374ff7a8ba4544a624530c",
            "c1a4e1d4ae7e43fb8fb8d9b2ca68b124",
            "12f14dcb4afb492394368b388f5e83bf",
            "62f01584a6f043688be90a8bebfa4c79",
            "f86b7045a0af44899b650ed6b64a3b41",
            "ed9a911e74d84d1488f708112b47d4a8",
            "13d7ff52691447b6a17f8e663b483be1",
            "c27acd835c04462abb57b00273e413eb",
            "efdc88d420d54ab58e644937a87a6aad",
            "6abbfbee14f24dc19504723ede9876f3",
            "6f7883f91adf47a58e4734abe26b0178",
            "f5ef745a431143c5a14fb3fae2b91cac",
            "272a49d44ef44c6aa4221d42a1bc0cca",
            "1d31c68a07a2478cb2ffb37c12a5afd4",
            "50718078fac843309d74a9f7519bfe0d",
            "3f01e544602a4695a4145f14f58d3ea8",
            "56399dfaa910483b8e4efdc55dc06a30",
            "e0ec4e6ba2f84e509cb007b8050fc134",
            "a9e96228c96e4e009e710c0adaecccfc",
            "4507b3e8276d40448b71530f5a07867d",
            "b6e959dc9f994979af95c41f1df6c44d",
            "b140f9542d134b039b30b60a699c4fde",
            "93c1f3e9218d44439121bcabdd0c3130",
            "15efece47c36428294efcd5baa9d704c",
            "9892848eb12c412297e1a0add60f9a68",
            "60a5ea06f1b04287b78d3899b1654de2",
            "d23c02131c8d4bfcaf84614be7c7a179",
            "be4af64ac03d447580fd7425466ecdd2",
            "426f02c2d2434e4a91d054bc43e0345b",
            "8b59cdad3ac64a558f1cba5ae417f862",
            "32a24644b5aa490c9a91b170766b4490",
            "b824d42b316142b2b30b055509cd4d81",
            "121cf33189bc4d76a172c03158c657a0",
            "e8852e6069934168b5874c6052c63c00",
            "62ce7c17dbf24fc8948be663dd2c9710",
            "d79c447eee03471298d7f6397203b023",
            "fe8f3e79f8b543c18e97197492d14b1c",
            "d4b475f6d85e49aebb6f5d928c2e9f59",
            "a446e4e3900549509bf59284e7a981b6",
            "f41953b1333e4b0390c823560d07f489",
            "2988d41828a84540bdc2f8e084f962f0",
            "14347b14b55f4c988b1d12e09414e92b",
            "d7b1e11e6b744528a82237b693b297c7",
            "f3de15d474c84051977294eee771a06d",
            "d1689b26304548f89fa80eacdc5a34a7",
            "32fd3b0dddb24f9585c83e8675f82395",
            "244a3960f6e54614ad281bda29f43eb2",
            "a89b5e59d6ef4bec885da8d6e483adc6",
            "e80ad492ddef4b35b4d051c9403ede6d",
            "ff6793d3455e4c948af6732669eae529",
            "5f989f11af0a47ea8ae7687c1fc3dd13",
            "8cf639b89b6741d2b902e9d74c6a41bc",
            "68c472a44c2b4e488c482bf3e26ca293",
            "f5961a5f2628451a85e9c6776fef827f",
            "a743d88154614570a1818615d1e000bf",
            "f6a673622273428198c7d8e07e2ce20a",
            "9f4815db954f426db85c9dfe3d548305",
            "1c700236e2fe4146b048af51812d9edc",
            "5806bddadbcb421f9f7695ddf42cdf30",
            "19bfe6c7afdf4f7e81d9ba7bc0f404f0",
            "7b9075e25f2547dab424f99291284999",
            "5f4bd0921d334b208234462f44bb5de8",
            "b61fc63d39fc4d17b1e6f7b913da1505",
            "f850a5fcbe1a40499fe64c25029af71e",
            "a346d22e290a4128b6ae8866356a4b9f",
            "2b4ebe6fdc3547619e9ec5b81856b5b0",
            "5411d8cb4d1644aead6e4de8e2d0d92b",
            "768f7a800d814d93be814af4cd46e4f2",
            "e618f7011427487ca83eb2a34f0e0fe3",
            "79e28d31afe14f8aabd326934b080294",
            "54e21328ff654c62a3c7be8034fbc861",
            "456783ad58684657af24b47b41a0e250",
            "3ab6c5cb8ae94d31be5303d483e52bb0",
            "1887c8af99454076ae964e11ea3f483a",
            "eccbcac4661847cca20540321448750d",
            "306e85aa118d4844b7b1328e9294cfe0",
            "da0a7e5724d849e6b1466969c02429f9",
            "49c726960497469493674cfdc85f6b3d",
            "e946bb0ca38046deabe93f3ba1b07bda",
            "7547ea696a60447882122bc16057e190",
            "a4432537fdea48c784fc1c606528b9af",
            "5d080621d40f4e07a0cd0a3f2fe5c6f3",
            "3c3d07d2344d403498848f5ee0953ef4",
            "2cd3f81f735942f1b77d61162c958dbe",
            "f3ee62b27e9943be8bed63393a48b230",
            "d09e0e10679e4357988bec22e95707e2",
            "45409685b8f748fa95daf401eebb8bd7",
            "1f7fef6d00af437fae79f9639b063c20",
            "9ba681b6b34641659e18f0e7c8411d55",
            "b424214953db48a6b821f450007395ed",
            "48ceeff038dd4783a7968bdbfcdf569b",
            "08b958c04e4441f2896188629c2b9f89",
            "362e7b1d5bd743f3a13a05a4acb16a67",
            "ff0d220d80134aea92177906e7d75c12",
            "ea6bea9795a9496c8ff49ea6acada953",
            "bdcbc8c6ac4e4612b39dec7aa5ba4f8e",
            "3844f511e95c4e2c82edf32e308a8dfc",
            "b5618ba9af514d56960ff5fa0d449649",
            "b24f724a7c794d21b0c3873b5a5a840f"
          ]
        },
        "outputId": "12943374-d5d2-4102-e037-07805d2ba79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e63e4c588f484f803156854cff2868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0af61600bebe4ab28ed5b5139b25da21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
            "- configuration_phi3.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbcab8ed07c547b1947fa9e5312ec597"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
            "- modeling_phi3.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d5bc143a4b64210beb63d231570ff49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db8d2a25d61f4c53a32eaef3a5544041"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb9863d634374ff7a8ba4544a624530c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5ef745a431143c5a14fb3fae2b91cac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93c1f3e9218d44439121bcabdd0c3130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8852e6069934168b5874c6052c63c00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1689b26304548f89fa80eacdc5a34a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a673622273428198c7d8e07e2ce20a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5411d8cb4d1644aead6e4de8e2d0d92b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49c726960497469493674cfdc85f6b3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ba681b6b34641659e18f0e7c8411d55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "# @title model & tokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"auto\", # Automatically place on GPU if available\n",
        "    torch_dtype=torch.float16, # for good/efficient performance\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "\n",
        "# Create a pipeline\n",
        "instruct_pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "    max_new_tokens=512, # tokens to generate, doesn't count the prompt\n",
        "    return_full_text=False, # don't return the input prompt\n",
        "    do_sample=False, # for determinism, generates next token greedily\n",
        "    use_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19kCdpDaofNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff5eeed-3dcf-4b6a-cff9-a122255e03ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "dtype: torch.float16\n",
            "Att-impl: eager\n",
            "Number of parameters: 3821079552\n"
          ]
        }
      ],
      "source": [
        "# get model characteristics\n",
        "def model_info(m):\n",
        "    print(f\"device: {next(m.parameters()).device}\")\n",
        "    print(f\"dtype: {next(m.parameters()).dtype}\")\n",
        "    print(f\"Att-impl: {m.config._attn_implementation}\")\n",
        "    print(f\"Number of parameters: {sum(p.numel() for p in m.parameters())}\")\n",
        "\n",
        "model_info(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9SuJBXfk63v"
      },
      "source": [
        "## Ex3.1 [7pt] Data generation\n",
        "\n",
        "We will use the GSM8K dataset ([Cobbe et al. 2021](https://arxiv.org/pdf/2110.14168)) from OpenAI to access simple arithmetic math problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s58yyVBDw_ZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b3bc5084d0c942cfbf7d3b0ea0a047df",
            "f0a28018925f4761a94d3cfc07370fa3",
            "40f8b9dc0e494c689d1b8e9fc7a37392",
            "6c6b228894404bf2924c15b3b44b0c40",
            "0286fa2891b34c91b4374aca5fc0d9b9",
            "de293cd9005c4638bb1efd3f52c8f58b",
            "b550ed47954d4112b8886a7a51a146a3",
            "e9ee0e502e524a90a4575f973d186996",
            "1a7325967cca41889cc640b515696726",
            "87884afe83d944568365dbbdab7a580b",
            "ac72cf0871b2497f954b28e0bab8bc1b",
            "5e46e3e0cbc54c74b94d0f6d5c060d11",
            "979159f1dbbf4908a0d0e1fd05838e4e",
            "45eec5eae81946d4b16970c9a852f8a1",
            "ebcc064735694c819581d17941c8fd9a",
            "2970a3770da04e189ba8f6e9e91cd305",
            "e29fca6810f84f65b464c700b186bc7d",
            "779f01b7b8f44c7f97e32590a6db8298",
            "0fc33bc9325b4b0ca7189d6ea61af61c",
            "fb5fe576c6114e3d988e41969ade6707",
            "01cd4adeaab843f69cc5bea59a22b507",
            "f56219522b3f4e60bbc3ea83b0c67e2c",
            "25b89a3cf8d64764b2444f79db3bf7f5",
            "0d397ab0a6d14a8180eb92802257733d",
            "cec7fca8e3d44feca565ee47400dcfdd",
            "c452079140ae485f97328a7c0a48b0a4",
            "2d2c2a20cfc1406493cbeaf0ad053081",
            "33075b740b56430abfb783ec46a5c11b",
            "91df871ea39b47af91df97adea755d09",
            "42ace153e7ac48f2971116ad97a66231",
            "43cafe4f5fb44c31ad23b940c481f644",
            "897a4ee408bc430f876425b9e03d0301",
            "77ae2dcca05c46b6a10f4e2828dfd819",
            "cbdd060a9b36438090ab2c60d5fc5814",
            "bc346d36b3cd486cac7cd53a9ed0c0a1",
            "840c34bf544b420dbbcaeb7828071fa9",
            "87878072dc374da5bcb805869d4ff403",
            "302f8a7e3a074684906ee7236b137584",
            "64334673cec447db886f49e6c7f5375e",
            "6fd09391501045bdaf97893d021d10ce",
            "3f81c2af840642c59c11a2b83907af3e",
            "aaf3cf9b785e48d68e255b1b69b8b0da",
            "81381c2ae79342f0886c20fcd7cf2c97",
            "e8abe205a041408697420ef5a855601b",
            "496cad2bf95c481b910684a01effe464",
            "42a6c17b7a224b9eb4d5fe91b07bd464",
            "7832cab58fe541ab905c6c5d9953903c",
            "c26b878d463948a194e8c47137eb0c33",
            "76a52c8e61b54cfbab9f29ea681de0fc",
            "2892b7687fe04a9cad90f4b36ee8d5e7",
            "9be653f8401a496c87cb4f99b78f41ee",
            "1822f5876e0d447bb56f0755e21506cc",
            "3da5ac40a0844bf4a72f2e04ad39c0ee",
            "0c493499526f4aad8d1d7cc10aebbcd3",
            "67a59345317e424695552f92de2e464c"
          ]
        },
        "outputId": "db676d4a-09ff-45a5-dc65-cb5d417ab7c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3bc5084d0c942cfbf7d3b0ea0a047df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e46e3e0cbc54c74b94d0f6d5c060d11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25b89a3cf8d64764b2444f79db3bf7f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbdd060a9b36438090ab2c60d5fc5814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "496cad2bf95c481b910684a01effe464"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title GSM8K\n",
        "GSM8K = load_dataset(\"openai/gsm8k\", 'main')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_W6K60d0t_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f3325688602947c68458892d0c4e92c6",
            "2e80c733857e47579b3d853dac6d880f",
            "e35bbede9dd14336bca30519d76a49cb",
            "74fec002d020404e9513bbc29af3389f",
            "3a4f477377e14356a75418701cf14b7c",
            "17b7e4fa6f14480c910bbfbf937577e5",
            "21dc77847c204daa84464cb9c079f980",
            "de4b99e6dc76482fb5c8b438ab184741",
            "0d12344f27cb4972952a88d36738aca1",
            "180dc3067bc9465c9368e8f2968c49cb",
            "2b9a74fb29404f22b65d825d12b6534a",
            "83a4abb1d90c4f27b11ff8835f217609",
            "0ae3cb813a194ad489b173fbcf0c73bc",
            "18daf9010051466b8f4206124507f72f",
            "e10767e9a1ef468f9276e72a4c7119e6",
            "e894ebbd06f34fafa89a9fe81a4b7659",
            "17eeaa6dcb354bd5b2a8d26aa6bf947e",
            "a0e093c28b12403ea13915e38deb5219",
            "d60fe61785684af8a9a2cc5eeb5d65c5",
            "8885f591faf849babfa148e759e28369",
            "fa4577ea292143d0b6a4a2934d40189d",
            "3652985f1c4a44b9a214e209e1b03f56"
          ]
        },
        "outputId": "81f85094-f897-42a5-fb95-7a1dd005595a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3325688602947c68458892d0c4e92c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83a4abb1d90c4f27b11ff8835f217609"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# we do some preprocessing, to get the short answer easily accessible\n",
        "def preprocess_gsm8k(example):\n",
        "    clean = re.sub('<<.*?>>', '', example['answer'])\n",
        "    example['clean_answer'], example['short_answer'] = re.split('\\s*\\n####\\s*', clean)\n",
        "    return example\n",
        "\n",
        "GSM8K = GSM8K.map(preprocess_gsm8k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsEvYTfk8Jma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440ce862-998c-407a-912e-819d6216df26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question:\n",
            "At a bus station, a bus leaves every half-hour for 12 hours a day. How many buses leave the station for 5 days?\n",
            "\n",
            "answer:\n",
            "If one bus leaves every half-hour, then during one hour, there are 1 + 1 = <<1+1=2>>2 buses that leave the station.\n",
            "During 5 days 2 * 12 * 5 = 120 buses leave the station.\n",
            "#### 120\n",
            "\n",
            "clean_answer:\n",
            "If one bus leaves every half-hour, then during one hour, there are 1 + 1 = 2 buses that leave the station.\n",
            "During 5 days 2 * 12 * 5 = 120 buses leave the station.\n",
            "\n",
            "short_answer:\n",
            "120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's print a sample from the data\n",
        "for k, v in GSM8K['train'][2025].items():\n",
        "    print(f\"{k}:\\n{v}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKjipFwUndj1"
      },
      "source": [
        "We need a prompt to give more elaborate instructions to the model. As the experiments show that the chain-of-thought (CoT) prompting boosts the model predictions, we are going to use it.  \n",
        "\n",
        "Feel free to modify or use any of the two CoT templates given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB8mCBTCe3Ev"
      },
      "outputs": [],
      "source": [
        "# @title Prompt templates\n",
        "# Chain-of-Thought prompt template\n",
        "\n",
        "# Feel free to define you CoT template\n",
        "\n",
        "COT_TEMPLATE = \"\"\"Solve the following problem step by step using chain-of-thought reasoning.\n",
        "\n",
        "Problem: {problem}\n",
        "\n",
        "Let me work through this step by step:\"\"\"\n",
        "\n",
        "COT_TEMPLATE_DIALOG = \"\"\"<|user|>:\n",
        "Solve the following problem step by step using chain-of-thought reasoning:\n",
        "\n",
        "Problem: {problem}\n",
        "<|end|>\n",
        "\n",
        "<|assistant|>: Let me work through this step by step:\"\"\"\n",
        "\n",
        "# No Chain-of-Thought prompt template\n",
        "\n",
        "NO_COT_TEMPLATE_DIALOG = \"\"\"<|user|>:\n",
        "Solve the following problem and provide only the answer:\n",
        "\n",
        "Problem: {problem}\n",
        "<|end|>\n",
        "\n",
        "<|assistant|>: The correct answer is:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cj2f3uWoJV0"
      },
      "source": [
        "Here we are defining the substitution rules. The idea behind the experiment is to check whether concept and number replacements irrelevant from the reasoning perspective will affect the model's predictions.  \n",
        "If the model correctly answers a math question `q`, then it should also correctly answer the math questions that are obtained from `q` with irrelevant concept/number substitutions.\n",
        "Otherwise it will indicate the poor generalization capacity of the model.\n",
        "\n",
        "Below you have an illustration of how to define the concept and number replacement rules for particular QA problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84DwwaHJ6-L-"
      },
      "outputs": [],
      "source": [
        "# @title demo substitutions\n",
        "problem_subs = [\n",
        "    (2024, {'concept': [\n",
        "                {'question': ['red -> pink', 'green -> yellow'],'short_answer': '30'},\n",
        "                {'question': ['party -> event'],                'short_answer': '30'},\n",
        "                {'question': ['balloons -> inflatable toys'],   'short_answer': '30'}\n",
        "            ],\n",
        "            'number': [\n",
        "                {'question': ['20 -> 55', '15 -> 35'],  'short_answer': '85'},\n",
        "                {'question': ['3 -> 15', '2 -> 15'],    'short_answer': '5'},\n",
        "                {'question': ['20 -> 3', '15 -> 2'],    'short_answer': '0'}\n",
        "                ]\n",
        "    }),\n",
        "    (2025, {'concept': [\n",
        "                {'question': ['bus -> train', 'buses -> trains'],                           'short_answer': '120'},\n",
        "                {'question': ['leaves -> arrives', 'leaves the -> arrives in the'],         'short_answer': '120'},\n",
        "                {'question': ['day -> month', 'days -> months', 'half-hour -> half-day', 'hours -> days'],    'short_answer': '120'}\n",
        "                ],\n",
        "            'number': [\n",
        "                {'question': ['12 -> 5'],               'short_answer': '50'},\n",
        "                {'question': ['12 -> 23'],              'short_answer': '230'},\n",
        "                {'question': ['12 -> 3', '5 -> 12'],    'short_answer': '72'}\n",
        "                ]\n",
        "    })\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFSaCwUjCzPS"
      },
      "source": [
        "<font color=\"red\">Pick **any three** QA problems from the test part of GSM8K.  \n",
        "If your selected problems substantially overlap with other group's selected problems, this may be considered as plagarism and will be subject to penalization.</font>\n",
        "\n",
        "For example, the chances of two groups selecting the same two problems are extremely low, taking into account that the test split contains >1300 problems.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO_IxceZrwx7"
      },
      "outputs": [],
      "source": [
        "# @title My substitutions\n",
        "# don't change the variable name!!!\n",
        "MY_SUBS = [\n",
        "    ### YOUR CODE HERE ###\n",
        "    # here should be three(!) problem IDs from the GSM8K['test']\n",
        "    # each with corresponding three(!) concept and three(!) number replacement rules\n",
        "    # So in total, with the mix=True, this should define 3x(3+3+3x3)=45 new QA problems\n",
        "    # make sure that the generated problems have the correct gold standard answers\n",
        "\n",
        "    # Problem ID 23: A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM? Ans: 8\n",
        "    (23, {'concept': [\n",
        "                {'question': ['candle -> wax sculpture', 'melts -> shrinks'],      'short_answer': '8'},\n",
        "                {'question': ['centimeters -> millimeters', 'shorter -> smaller'], 'short_answer': '8'},\n",
        "                {'question': ['burns -> is lit', 'PM -> AM'],                      'short_answer': '8'}\n",
        "            ],\n",
        "            'number': [\n",
        "                {'question': ['2 -> 3', '1:00 -> 2:00', '5:00 -> 7:00'],   'short_answer': '15'}, # 7-2=5 hours. 3 * 5 = 15\n",
        "                {'question': ['2 -> 1.5', '1:00 -> 4:00', '5:00 -> 8:00'], 'short_answer': '6'},  # 13-9=4 hours. 1.5 * 4 = 6\n",
        "                {'question': ['2 -> 4', '1:00 -> 10:00', '5:00 -> 11:00'], 'short_answer': '4'}   # 12-11=1 hours. 4 * 1 = 4\n",
        "                ]\n",
        "    }),\n",
        "\n",
        "    # Problem ID 24: Kyle bought last year's best-selling book for $19.50. This is with a 25% discount from the original price. What was the original price of the book? Ans: 26\n",
        "    (24, {'concept': [\n",
        "                {'question': ['Kyle -> Sarah', 'book -> magazine'],                    'short_answer': '26'},\n",
        "                {'question': ['best-selling -> most popular', 'bought -> purchased'],  'short_answer': '26'},\n",
        "                {'question': ['discount -> price reduction', 'original price -> list price'], 'short_answer': '26'}\n",
        "            ],\n",
        "            'number': [\n",
        "                {'question': ['19.50 -> 24.00', '25 -> 20'],  'short_answer': '30.0'}, # 24.00 / (1 - 0.20) = 24.00 / 0.8 = 30.0\n",
        "                {'question': ['19.50 -> 30.00', '25 -> 40'],  'short_answer': '50.0'}, # 30.00 / (1 - 0.40) = 30.00 / 0.6 = 50.0\n",
        "                {'question': ['19.50 -> 28.00', '25 -> 30'],  'short_answer': '40.0'} # 28.00 / (1 - 0.30) = 28.00 / 0.7 = 40.0\n",
        "                ]\n",
        "    }),\n",
        "\n",
        "    # Problem ID 50: Lloyd has an egg farm. His chickens produce 252 eggs per day and he sells them for $2 per dozen. How much does Lloyd make on eggs per week? Ans: 294\n",
        "    (50, {'concept': [\n",
        "                {'question': ['egg -> apple', 'eggs -> apples', 'chickens -> trees'],                'short_answer': '294'},\n",
        "                {'question': ['egg farm -> dairy farm', 'chickens -> cows', 'eggs -> milk bottles'], 'short_answer': '294'},\n",
        "                {'question': ['produce -> lay', 'sells -> trades'],                                  'short_answer': '294'}\n",
        "            ],\n",
        "            'number': [\n",
        "                {'question': ['252 -> 300', '2 -> 3'],      'short_answer': '525'},  # 300 apples/day * 7 days/week = 2100 apples/week.             2100/12 = 175 dozens. 175 * $3 = $525\n",
        "                {'question': ['252 -> 144', '2 -> 2.50'],   'short_answer': '210'},  # 144 milk bottles/day * 7 days/week = 1008 milk bottles/week. 1008/12 = 84 dozens.  84 * $2.50 = $210\n",
        "                {'question': ['252 -> 120', '2 -> 1.50'],   'short_answer': '105'}   # 120 eggs/day * 7 days/week = 840 eggs/week.                  840/12 = 70 dozens.   70 * $1.50 = $105\n",
        "                ]\n",
        "    })\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NEnbx4bqU8J"
      },
      "outputs": [],
      "source": [
        "# @title generation function\n",
        "\n",
        "def generate_prompted_samples(data, prob_subs, template=None, mix=True):\n",
        "    \"\"\" The function takes data and a list of problem id and substitution rules.\n",
        "        It returns a new list of QA problems that are obtained from the original ones\n",
        "        by applying the substitutions.\n",
        "        template is an optional flag telling the function to wrap new problems\n",
        "        in a pre-defined template.\n",
        "        mix tells the function to generate problems with a mixture of concept and number\n",
        "        replacement rules. This option considers all possible combinations.\n",
        "    \"\"\"\n",
        "    prompted_samples = [] # a lits of (id, mode, new_question, new_short_answer, q_subs)\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    for prob_id, subs_dict in prob_subs:\n",
        "        original_question = data[prob_id]['question']\n",
        "\n",
        "        # 1. Concept substitutions\n",
        "        for c_sub_info in subs_dict['concept']:\n",
        "            new_question = original_question\n",
        "            q_subs_applied = []\n",
        "            for sub_pair in c_sub_info['question']:\n",
        "                old, new = sub_pair.split(' -> ')\n",
        "                # Use regex to replace whole words to avoid partial matches\n",
        "                new_question = re.sub(r'\\b' + re.escape(old) + r'\\b', new, new_question, flags=re.IGNORECASE)\n",
        "                q_subs_applied.append(sub_pair)\n",
        "            final_question = template.format(problem=new_question) if template else new_question\n",
        "            prompted_samples.append((prob_id, 'concept', final_question, c_sub_info['short_answer'], q_subs_applied))\n",
        "\n",
        "        # 2. Number substitutions\n",
        "        for n_sub_info in subs_dict['number']:\n",
        "            new_question = original_question\n",
        "            q_subs_applied = []\n",
        "            for sub_pair in n_sub_info['question']:\n",
        "                old, new = sub_pair.split(' -> ')\n",
        "                # Use regex to replace whole numbers, ensuring they are not part of other numbers\n",
        "                # e.g., '20' should not replace '200'\n",
        "                new_question = re.sub(r'\\b' + re.escape(old) + r'\\b', new, new_question)\n",
        "                q_subs_applied.append(sub_pair)\n",
        "            final_question = template.format(problem=new_question) if template else new_question\n",
        "            prompted_samples.append((prob_id, 'number', final_question, n_sub_info['short_answer'], q_subs_applied))\n",
        "\n",
        "        # 3. Mixed substitutions (if mix is True)\n",
        "        if mix:\n",
        "            for c_sub_info in subs_dict['concept']:\n",
        "                for n_sub_info in subs_dict['number']:\n",
        "                    temp_question = original_question\n",
        "                    q_subs_applied = []\n",
        "\n",
        "                    # Apply concept substitutions first\n",
        "                    for sub_pair in c_sub_info['question']:\n",
        "                        old, new = sub_pair.split(' -> ')\n",
        "                        temp_question = re.sub(r'\\b' + re.escape(old) + r'\\b', new, temp_question, flags=re.IGNORECASE)\n",
        "                        q_subs_applied.append(sub_pair)\n",
        "\n",
        "                    # Then apply number substitutions\n",
        "                    for sub_pair in n_sub_info['question']:\n",
        "                        old, new = sub_pair.split(' -> ')\n",
        "                        temp_question = re.sub(r'\\b' + re.escape(old) + r'\\b', new, temp_question)\n",
        "                        q_subs_applied.append(sub_pair)\n",
        "\n",
        "                    # The short answer for mixed rules comes from the number substitution's calculation\n",
        "                    final_question = template.format(problem=temp_question) if template else temp_question\n",
        "                    prompted_samples.append((prob_id, 'mix', final_question, n_sub_info['short_answer'], q_subs_applied))\n",
        "\n",
        "    return prompted_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJh2ClxPK5J3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a863d06-5a3f-4364-e5a8-d886cabbec68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total samples generated = 30\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "Answer = 72\n"
          ]
        }
      ],
      "source": [
        "# TEST generate_prompted_samples\n",
        "# Let's see how the function should work\n",
        "prompted_samples = generate_prompted_samples(GSM8K['train'], problem_subs, template=COT_TEMPLATE_DIALOG)\n",
        "print(f\"total samples generated = {len(prompted_samples)}\")\n",
        "\n",
        "# print a sample generated problem\n",
        "print(prompted_samples[-1][2])\n",
        "print(f\"Answer = {prompted_samples[-1][-2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWo8_gOct36k"
      },
      "source": [
        "The reference output of the above cell\n",
        "```\n",
        "total samples generated = 30\n",
        "<|user|>:\n",
        "Solve the following problem step by step using chain-of-thought reasoning:\n",
        "\n",
        "Problem: At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?\n",
        "<|end|>\n",
        "\n",
        "<|assistant|>: Let me work through this step by step:\n",
        "Answer = 72\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LyTlgo1uBMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fccd8a5-9939-4928-8b07-2fe40ca57ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total samples generated = 45\n"
          ]
        }
      ],
      "source": [
        "# @title My generated problems\n",
        "# don't change the variable names!!!\n",
        "\n",
        "MY_PROBLEMS = generate_prompted_samples(GSM8K['test'], MY_SUBS, template=COT_TEMPLATE_DIALOG)\n",
        "print(f\"total samples generated = {len(MY_PROBLEMS)}\")\n",
        "\n",
        "# If you cannot generate the problems automatically, define them manually.\n",
        "# Not a great solution (comes with penalties) but it will allow you to proceed with the next step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAQVx8HUuwEx"
      },
      "source": [
        "## Ex3.2 [8pt] Evaluation\n",
        "\n",
        "Now let's see how the model can be fed with an input and get predictions out of it.  \n",
        "We will illustrate the both options, with the CoT template and without it.\n",
        "\n",
        "In the end, you will have to run the instruct model on the generated samples with and without CoT prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uorGHcEpurue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c702091-371c-4ed4-caad-ad7e5389b0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------CoT prompt-----------------------------------\n",
            "\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. First, we need to determine how many buses leave the station in one day. Since a bus leaves every half-day, that means there are 2 buses leaving per day (one for the morning and one for the afternoon).\n",
            "\n",
            "2. Next, we need to find out how many buses leave the station in a month. We know that buses leave for 3 days a month, so we multiply the number of buses per day (2) by the number of days in a month (3):\n",
            "\n",
            "   2 buses/day * 3 days/month = 6 buses/month\n",
            "\n",
            "3. Finally, we need to calculate how many buses leave the station in 12 months. We multiply the number of buses per month (6) by the number of months (12):\n",
            "\n",
            "   6 buses/month * 12 months = 72 buses\n",
            "\n",
            "So, 72 buses leave the station in 12 months.\n",
            "================================================================================\n",
            "---------------------------------No CoT prompt----------------------------------\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "--------------------------------------------------------------------------------\n",
            " 72 buses.\n"
          ]
        }
      ],
      "source": [
        "# @title demo inference\n",
        "\n",
        "CoT_prompt = '''\n",
        "<|user|>:\n",
        "Solve the following problem step by step using chain-of-thought reasoning:\n",
        "\n",
        "Problem: At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?\n",
        "<|end|>\n",
        "\n",
        "<|assistant|>: Let me work through this step by step:\n",
        "'''\n",
        "# note that the correct answer is 72\n",
        "only_question = '''At a bus station, a bus leaves every half-day for 3 days a month. How many buses leave the station for 12 months?'''\n",
        "no_CoT_prompt = NO_COT_TEMPLATE_DIALOG.format(problem=only_question)\n",
        "\n",
        "# @title generate_response\n",
        "def generate_response(pipe_model, prompt, max_length=512):\n",
        "    \"\"\"Generate response using Hugging Face pipeline\"\"\"\n",
        "    # Generate using pipeline\n",
        "    outputs = pipe_model(\n",
        "        prompt,\n",
        "        max_new_tokens=max_length,\n",
        "        pad_token_id=pipe_model.tokenizer.eos_token_id,\n",
        "        eos_token_id=pipe_model.tokenizer.eos_token_id,\n",
        "        return_full_text=False,  # Only return generated text, not the prompt\n",
        "        use_cache=False\n",
        "    )\n",
        "    return outputs[0]['generated_text'].strip()\n",
        "\n",
        "# response = generate_response(instruct_pipe, CoT_prompt, max_length=400)\n",
        "\n",
        "print(f\"{'CoT prompt':-^80}\\n{CoT_prompt}\\n{'':-^80}\")\n",
        "output = instruct_pipe(CoT_prompt, use_cache=False)\n",
        "print(output[0]['generated_text'])\n",
        "print(f'{\"\":=^80}')\n",
        "print(f\"{'No CoT prompt':-^80}\\n{no_CoT_prompt}\\n{'':-^80}\")\n",
        "output = instruct_pipe(no_CoT_prompt)\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LVx8X7Xhjfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d9a47d-1a11-4704-83d8-33feb41ba766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running inference for ORIGINAL problems (CoT) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CoT (ID: 23) done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CoT (ID: 24) done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CoT (ID: 50) done.\n",
            "\n",
            "--- Running inference for ORIGINAL problems (No-CoT) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original No-CoT (ID: 23) done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original No-CoT (ID: 24) done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original No-CoT (ID: 50) done.\n",
            "\n",
            "--- Running inference with CoT prompting on GENERATED problems ---\n",
            "Processing CoT problem 1/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 2/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 3/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 4/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 5/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 6/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 7/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 8/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 9/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 10/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 11/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 12/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 13/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 14/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 15/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 16/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 17/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 18/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 19/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 20/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 21/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 22/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 23/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 24/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 25/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 26/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 27/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 28/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 29/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 30/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 31/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 32/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 33/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 34/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 35/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 36/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 37/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 38/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 39/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 40/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 41/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 42/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 43/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 44/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CoT problem 45/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running inference without CoT prompting on GENERATED problems ---\n",
            "Processing No-CoT problem 1/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 2/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 3/45 (ID: 23, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 4/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 5/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 6/45 (ID: 23, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 7/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 8/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 9/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 10/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 11/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 12/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 13/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 14/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 15/45 (ID: 23, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 16/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 17/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 18/45 (ID: 24, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 19/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 20/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 21/45 (ID: 24, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 22/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 23/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 24/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 25/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 26/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 27/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 28/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 29/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 30/45 (ID: 24, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 31/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 32/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 33/45 (ID: 50, Mode: concept)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 34/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 35/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 36/45 (ID: 50, Mode: number)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 37/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 38/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 39/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 40/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 41/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 42/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 43/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 44/45 (ID: 50, Mode: mix)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing No-CoT problem 45/45 (ID: 50, Mode: mix)...\n",
            "\n",
            "Completed inference for 48 CoT problems and 48 No-CoT problems.\n"
          ]
        }
      ],
      "source": [
        "# @title My inference\n",
        "# Run the model on the generated problems with and without CoT prompting\n",
        "# Feel free to include the problem generation script here too for no CoT prompting\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "def extract_raw_question_from_cot_prompt(modified_prompt):\n",
        "    \"\"\"Extracts the original question from a CoT-formatted prompt\"\"\"\n",
        "    # This pattern matches everything between \"Problem: \" and the next prompt closing tag\n",
        "    pattern = r'Problem:\\s*(.*?)\\s*<\\|end\\|>'\n",
        "    match = re.search(pattern, modified_prompt, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "# Run the model on the generated problems with and without CoT prompting\n",
        "\n",
        "cot_predictions = []\n",
        "no_cot_predictions = []\n",
        "\n",
        "# Define the original problem IDs selected\n",
        "original_problem_ids = [23, 24, 50]\n",
        "\n",
        "# --- Original Problem Inference ---\n",
        "print(\"\\n--- Running inference for ORIGINAL problems (CoT) ---\")\n",
        "for prob_id in original_problem_ids:\n",
        "    original_data = GSM8K['test'][prob_id]\n",
        "    original_question_text = original_data['question']\n",
        "    gold_answer = original_data['short_answer']\n",
        "\n",
        "    cot_orig_prompt = COT_TEMPLATE_DIALOG.format(problem=original_question_text)\n",
        "    orig_cot_response = generate_response(instruct_pipe, cot_orig_prompt, max_length=512)\n",
        "\n",
        "    cot_predictions.append({\n",
        "        'prob_id': prob_id,\n",
        "        'mode': 'original',\n",
        "        'q_subs': [], # No substitutions\n",
        "        'question': original_question_text,\n",
        "        'prompt': cot_orig_prompt,\n",
        "        'gold_answer': gold_answer,\n",
        "        'prompt_type': 'CoT',\n",
        "        'generated_text': orig_cot_response\n",
        "    })\n",
        "    print(f\"Original CoT (ID: {prob_id}) done.\")\n",
        "\n",
        "print(\"\\n--- Running inference for ORIGINAL problems (No-CoT) ---\")\n",
        "for prob_id in original_problem_ids:\n",
        "    original_data = GSM8K['test'][prob_id]\n",
        "    original_question_text = original_data['question']\n",
        "    gold_answer = original_data['short_answer']\n",
        "\n",
        "    no_cot_orig_prompt = NO_COT_TEMPLATE_DIALOG.format(problem=original_question_text)\n",
        "    orig_no_cot_response = generate_response(instruct_pipe, no_cot_orig_prompt, max_length=512)\n",
        "\n",
        "    no_cot_predictions.append({\n",
        "        'prob_id': prob_id,\n",
        "        'mode': 'original',\n",
        "        'q_subs': [], # No substitutions\n",
        "        'question': original_question_text,\n",
        "        'prompt': no_cot_orig_prompt,\n",
        "        'gold_answer': gold_answer,\n",
        "        'prompt_type': 'No-CoT',\n",
        "        'generated_text': orig_no_cot_response\n",
        "    })\n",
        "    print(f\"Original No-CoT (ID: {prob_id}) done.\")\n",
        "\n",
        "# --- Substituted Problem Inference (existing code) ---\n",
        "print(\"\\n--- Running inference with CoT prompting on GENERATED problems ---\")\n",
        "for i, (prob_id, mode, modified_prompt, short_answer_gold, q_subs) in enumerate(MY_PROBLEMS):\n",
        "    print(f\"Processing CoT problem {i+1}/{len(MY_PROBLEMS)} (ID: {prob_id}, Mode: {mode})...\")\n",
        "\n",
        "    # Extract raw question from the CoT-formatted prompt\n",
        "    raw_question = extract_raw_question_from_cot_prompt(modified_prompt)\n",
        "\n",
        "    cot_response = generate_response(instruct_pipe, modified_prompt, max_length=512)\n",
        "\n",
        "    cot_predictions.append({\n",
        "        'prob_id': prob_id,\n",
        "        'mode': mode,\n",
        "        'q_subs': q_subs,\n",
        "        'question': raw_question,\n",
        "        'prompt': modified_prompt,\n",
        "        'gold_answer': short_answer_gold,\n",
        "        'prompt_type': 'CoT',\n",
        "        'generated_text': cot_response\n",
        "    })\n",
        "\n",
        "print(\"\\n--- Running inference without CoT prompting on GENERATED problems ---\")\n",
        "for i, (prob_id, mode, modified_prompt, short_answer_gold, q_subs) in enumerate(MY_PROBLEMS):\n",
        "    print(f\"Processing No-CoT problem {i+1}/{len(MY_PROBLEMS)} (ID: {prob_id}, Mode: {mode})...\")\n",
        "\n",
        "    # Extract raw question from the CoT-formatted prompt\n",
        "    raw_question = extract_raw_question_from_cot_prompt(modified_prompt)\n",
        "\n",
        "    no_cot_prompt = NO_COT_TEMPLATE_DIALOG.format(problem=raw_question)\n",
        "    no_cot_response = generate_response(instruct_pipe, no_cot_prompt, max_length=512)\n",
        "\n",
        "    no_cot_predictions.append({\n",
        "        'prob_id': prob_id,\n",
        "        'mode': mode,\n",
        "        'q_subs': q_subs,\n",
        "        'question': raw_question,\n",
        "        'prompt': no_cot_prompt,\n",
        "        'gold_answer': short_answer_gold,\n",
        "        'prompt_type': 'No-CoT',\n",
        "        'generated_text': no_cot_response\n",
        "    })\n",
        "\n",
        "print(f\"\\nCompleted inference for {len(cot_predictions)} CoT problems and {len(no_cot_predictions)} No-CoT problems.\")\n",
        "\n",
        "# Now, `cot_predictions` and `no_cot_predictions` will contain entries\n",
        "# for both the original problems and the generated (substituted) problems.\n",
        "# The 'mode' field will help distinguish them ('original', 'concept', 'number', 'mix')."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It's helpful to group by original problem ID for assessment\n",
        "grouped_predictions_for_assessment = {}\n",
        "for p in cot_predictions + no_cot_predictions:\n",
        "    if p['prob_id'] not in grouped_predictions_for_assessment:\n",
        "        grouped_predictions_for_assessment[p['prob_id']] = {}\n",
        "    if p['mode'] not in grouped_predictions_for_assessment[p['prob_id']]:\n",
        "        grouped_predictions_for_assessment[p['prob_id']][p['mode']] = {\n",
        "            'CoT': [],\n",
        "            'No-CoT': []\n",
        "        }\n",
        "    grouped_predictions_for_assessment[p['prob_id']][p['mode']][p['prompt_type']].append(p)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"             Manual Evaluation: CoT vs No-CoT Prompting            \")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Sort by problem ID for consistent viewing\n",
        "for prob_id in sorted(grouped_predictions_for_assessment.keys()):\n",
        "    print(f\"\\n{'='*20} Original Problem ID: {prob_id} {'='*20}\\n\")\n",
        "\n",
        "    # Access the 'original' mode first\n",
        "    if 'original' in grouped_predictions_for_assessment[prob_id]:\n",
        "        print(f\"\\n--- Original Problem ({prob_id}) ---\\n\")\n",
        "        # Assuming there's one CoT and one No-CoT for original\n",
        "        original_cot = grouped_predictions_for_assessment[prob_id]['original']['CoT'][0]\n",
        "        original_no_cot = grouped_predictions_for_assessment[prob_id]['original']['No-CoT'][0]\n",
        "\n",
        "        print(f\"  Question: {original_cot['question']}\")\n",
        "        print(f\"  Gold Answer: {original_cot['gold_answer']}\\n\")\n",
        "\n",
        "        print(\"  --- CoT Prompt ---\")\n",
        "        print(original_cot['prompt'])\n",
        "        print(\"\\n  --- CoT Output ---\")\n",
        "        print(original_cot['generated_text'])\n",
        "\n",
        "        print(\"\\n  --- No-CoT Prompt ---\")\n",
        "        print(original_no_cot['prompt'])\n",
        "        print(\"\\n  --- No-CoT Output ---\")\n",
        "        print(original_no_cot['generated_text'])\n",
        "        print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "    # Then iterate through substituted modes\n",
        "    for mode in ['concept', 'number', 'mix']:\n",
        "        if mode in grouped_predictions_for_assessment[prob_id]:\n",
        "            print(f\"\\n--- Mode: {mode.upper()} Substitutions for Problem {prob_id} ({len(grouped_predictions_for_assessment[prob_id][mode]['CoT'])} Samples) ---\")\n",
        "            for j in range(len(grouped_predictions_for_assessment[prob_id][mode]['CoT'])): # Iterate by index as they should be paired\n",
        "                cot_pred = grouped_predictions_for_assessment[prob_id][mode]['CoT'][j]\n",
        "                no_cot_pred = grouped_predictions_for_assessment[prob_id][mode]['No-CoT'][j]\n",
        "\n",
        "                print(f\"\\n  Sample {j+1}:\")\n",
        "                print(f\"    Substitutions Applied: {cot_pred['q_subs']}\")\n",
        "                print(f\"    Question: {cot_pred['question']}\") # Raw question (after subs, before prompt template)\n",
        "                print(f\"    Gold Answer: {cot_pred['gold_answer']}\\n\")\n",
        "\n",
        "                print(\"    --- CoT Prompt ---\")\n",
        "                print(cot_pred['prompt'])\n",
        "                print(\"\\n    --- CoT Output ---\")\n",
        "                print(cot_pred['generated_text'])\n",
        "\n",
        "                print(\"\\n    --- No-CoT Prompt ---\")\n",
        "                print(no_cot_pred['prompt'])\n",
        "                print(\"\\n    --- No-CoT Output ---\")\n",
        "                print(no_cot_pred['generated_text'])\n",
        "\n",
        "                print(\"-\" * 50) # Separator for individual samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeUBfmuW3kQd",
        "outputId": "0bfe9ce8-2b40-4abe-e4f5-065532c9bd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "             Manual Evaluation: CoT vs No-CoT Prompting            \n",
            "================================================================================\n",
            "\n",
            "\n",
            "==================== Original Problem ID: 23 ====================\n",
            "\n",
            "\n",
            "--- Original Problem (23) ---\n",
            "\n",
            "  Question: A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "  Gold Answer: 8\n",
            "\n",
            "  --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "  --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle burns. The candle starts burning at 1:00 PM and ends at 5:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 5:00 PM - 1:00 PM = 4 hours.\n",
            "3. Now that we know the candle burns for 4 hours, we can calculate how much it melts during this time.\n",
            "4. The candle melts by 2 centimeters every hour. So, for 4 hours, it will melt 2 cm/hour * 4 hours = 8 centimeters.\n",
            "5. Therefore, after burning from 1:00 PM to 5:00 PM, the candle will be 8 centimeters shorter.\n",
            "\n",
            "  --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 2 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "  --- No-CoT Output ---\n",
            "8 centimeters.\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "--- Mode: CONCEPT Substitutions for Problem 23 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['candle -> wax sculpture', 'melts -> shrinks']\n",
            "    Question: A wax sculpture shrinks by 2 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 1:00 PM to 5:00 PM?\n",
            "    Gold Answer: 8\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 2 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of the burning process. The sculpture starts burning at 1:00 PM and ends at 5:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 5:00 PM - 1:00 PM = 4 hours.\n",
            "3. Now that we know the sculpture burns for 4 hours, we can calculate how much it shrinks during this time.\n",
            "4. The sculpture shrinks by 2 centimeters every hour. So, for 4 hours, it will shrink by 2 cm/hour * 4 hours = 8 centimeters.\n",
            "5. Therefore, the wax sculpture will be 8 centimeters shorter after burning from 1:00 PM to 5:00 PM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 2 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "8 centimeters\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['centimeters -> millimeters', 'shorter -> smaller']\n",
            "    Question: A candle melts by 2 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "    Gold Answer: 8\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 2 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle burns. The candle starts burning at 1:00 PM and ends at 5:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 5:00 PM - 1:00 PM = 4 hours.\n",
            "3. Now that we know the candle burns for 4 hours, we can calculate how much it melts during this time.\n",
            "4. The candle melts by 2 millimeters every hour. So, for 4 hours, it will melt 2 mm/hour * 4 hours = 8 millimeters.\n",
            "5. Therefore, after burning from 1:00 PM to 5:00 PM, the candle will be 8 millimeters smaller.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 2 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 1:00 PM to 5:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "8 millimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['burns -> is lit', 'PM -> AM']\n",
            "    Question: A candle melts by 2 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 1:00 AM to 5:00 AM?\n",
            "    Gold Answer: 8\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 2 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 1:00 AM to 5:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle was burning. The candle was lit at 1:00 AM and burned until 5:00 AM.\n",
            "2. To find the duration, we subtract the start time from the end time: 5:00 AM - 1:00 AM = 4 hours.\n",
            "3. Now that we know the candle burned for 4 hours, we can calculate how much it melted during this time.\n",
            "4. The candle melts by 2 centimeters every hour. So, for 4 hours, it will melt 2 cm/hour * 4 hours = 8 centimeters.\n",
            "5. Therefore, after burning from 1:00 AM to 5:00 AM, the candle will be 8 centimeters shorter.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 2 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 1:00 AM to 5:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "8 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: NUMBER Substitutions for Problem 23 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['2 -> 3', '1:00 -> 2:00', '5:00 -> 7:00']\n",
            "    Question: A candle melts by 3 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "    Gold Answer: 15\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 3 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of time the candle has been burning. The candle starts burning at 2:00 PM and ends at 7:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 7:00 PM - 2:00 PM = 5 hours.\n",
            "3. Now that we know the candle has been burning for 5 hours, we can calculate how much it has melted.\n",
            "4. The candle melts by 3 centimeters every hour. So, for 5 hours, it will melt 5 hours * 3 centimeters/hour = 15 centimeters.\n",
            "5. Therefore, after burning from 2:00 PM to 7:00 PM, the candle will be 15 centimeters shorter.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 3 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "15 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['2 -> 1.5', '1:00 -> 4:00', '5:00 -> 8:00']\n",
            "    Question: A candle melts by 1.5 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "    Gold Answer: 6\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 1.5 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle burns. The candle starts burning at 4:00 PM and ends at 8:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 8:00 PM - 4:00 PM = 4 hours.\n",
            "3. Now that we know the candle burns for 4 hours, we can calculate how much it melts during this time.\n",
            "4. The candle melts by 1.5 centimeters every hour. So, for 4 hours, it will melt: 1.5 cm/hour * 4 hours = 6 centimeters.\n",
            "5. Therefore, after burning from 4:00 PM to 8:00 PM, the candle will be 6 centimeters shorter.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 1.5 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "6 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['2 -> 4', '1:00 -> 10:00', '5:00 -> 11:00']\n",
            "    Question: A candle melts by 4 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "    Gold Answer: 4\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 4 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that the candle melts by 4 centimeters every hour.\n",
            "2. The candle is burning from 10:00 PM to 11:00 PM, which is a duration of 1 hour.\n",
            "3. To find out how much shorter the candle will be after burning for 1 hour, we need to multiply the melting rate (4 centimeters per hour) by the duration (1 hour).\n",
            "4. So, 4 centimeters/hour * 1 hour = 4 centimeters.\n",
            "\n",
            "After burning from 10:00 PM to 11:00 PM, the candle will be 4 centimeters shorter.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 4 centimeters every hour that it burns. How many centimeters shorter will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "4 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: MIX Substitutions for Problem 23 (9 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['candle -> wax sculpture', 'melts -> shrinks', '2 -> 3', '1:00 -> 2:00', '5:00 -> 7:00']\n",
            "    Question: A wax sculpture shrinks by 3 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 2:00 PM to 7:00 PM?\n",
            "    Gold Answer: 15\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 3 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of the burning process. The sculpture starts burning at 2:00 PM and ends at 7:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 7:00 PM - 2:00 PM = 5 hours.\n",
            "3. Now that we know the sculpture burns for 5 hours, we can calculate how much it shrinks during this time.\n",
            "4. The sculpture shrinks by 3 centimeters every hour. So, for 5 hours, it will shrink by 3 cm/hour * 5 hours = 15 centimeters.\n",
            "5. Therefore, the wax sculpture will be 15 centimeters shorter after burning from 2:00 PM to 7:00 PM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 3 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "15 centimeters\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['candle -> wax sculpture', 'melts -> shrinks', '2 -> 1.5', '1:00 -> 4:00', '5:00 -> 8:00']\n",
            "    Question: A wax sculpture shrinks by 1.5 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 4:00 PM to 8:00 PM?\n",
            "    Gold Answer: 6\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 1.5 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of the burning process. The sculpture burns from 4:00 PM to 8:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 8:00 PM - 4:00 PM = 4 hours.\n",
            "3. Now that we know the sculpture burns for 4 hours, we can calculate how much it shrinks during this time.\n",
            "4. The sculpture shrinks by 1.5 centimeters every hour. To find the total shrinkage, we multiply the shrinkage per hour by the number of hours: 1.5 cm/hour * 4 hours = 6 centimeters.\n",
            "5. Therefore, the wax sculpture will be 6 centimeters shorter after burning from 4:00 PM to 8:00 PM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 1.5 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "6 centimeters\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['candle -> wax sculpture', 'melts -> shrinks', '2 -> 4', '1:00 -> 10:00', '5:00 -> 11:00']\n",
            "    Question: A wax sculpture shrinks by 4 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 10:00 PM to 11:00 PM?\n",
            "    Gold Answer: 4\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 4 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that the wax sculpture shrinks by 4 centimeters every hour.\n",
            "2. The sculpture is burning from 10:00 PM to 11:00 PM, which is a duration of 1 hour.\n",
            "3. Since the sculpture shrinks by 4 centimeters every hour, we can calculate the total shrinkage during this 1-hour period.\n",
            "4. Total shrinkage = Shrinkage per hour * Number of hours\n",
            "5. Total shrinkage = 4 centimeters/hour * 1 hour\n",
            "6. Total shrinkage = 4 centimeters\n",
            "\n",
            "So, the wax sculpture will be 4 centimeters shorter after burning from 10:00 PM to 11:00 PM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A wax sculpture shrinks by 4 centimeters every hour that it burns. How many centimeters shorter will a wax sculpture be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "4 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 4:\n",
            "    Substitutions Applied: ['centimeters -> millimeters', 'shorter -> smaller', '2 -> 3', '1:00 -> 2:00', '5:00 -> 7:00']\n",
            "    Question: A candle melts by 3 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "    Gold Answer: 15\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 3 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of the candle burning. The candle starts burning at 2:00 PM and ends at 7:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 7:00 PM - 2:00 PM = 5 hours.\n",
            "3. Now that we know the candle burns for 5 hours, we can calculate how much it melts during this time.\n",
            "4. The candle melts by 3 millimeters every hour. So, for 5 hours, it will melt 5 hours * 3 millimeters/hour = 15 millimeters.\n",
            "5. Therefore, after burning from 2:00 PM to 7:00 PM, the candle will be 15 millimeters smaller.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 3 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 2:00 PM to 7:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "15 millimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 5:\n",
            "    Substitutions Applied: ['centimeters -> millimeters', 'shorter -> smaller', '2 -> 1.5', '1:00 -> 4:00', '5:00 -> 8:00']\n",
            "    Question: A candle melts by 1.5 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "    Gold Answer: 6\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 1.5 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the duration of the candle burning. The candle burns from 4:00 PM to 8:00 PM.\n",
            "2. To find the duration, we subtract the start time from the end time: 8:00 PM - 4:00 PM = 4 hours.\n",
            "3. Now that we know the candle burns for 4 hours, we can calculate how much it melts during this time.\n",
            "4. The candle melts by 1.5 millimeters every hour. So, for 4 hours, it will melt: 1.5 mm/hour * 4 hours = 6 millimeters.\n",
            "5. Therefore, after burning from 4:00 PM to 8:00 PM, the candle will be 6 millimeters smaller.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 1.5 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 4:00 PM to 8:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "6 millimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 6:\n",
            "    Substitutions Applied: ['centimeters -> millimeters', 'shorter -> smaller', '2 -> 4', '1:00 -> 10:00', '5:00 -> 11:00']\n",
            "    Question: A candle melts by 4 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "    Gold Answer: 4\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 4 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that the candle melts by 4 millimeters every hour.\n",
            "2. The candle is burning from 10:00 PM to 11:00 PM, which is a duration of 1 hour.\n",
            "3. To find out how much the candle will have melted in that hour, we need to multiply the melting rate (4 millimeters per hour) by the duration of burning (1 hour).\n",
            "4. So, 4 millimeters/hour * 1 hour = 4 millimeters.\n",
            "\n",
            "The candle will be 4 millimeters smaller after burning from 10:00 PM to 11:00 PM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 4 millimeters every hour that it burns. How many millimeters smaller will a candle be after burning from 10:00 PM to 11:00 PM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "4 millimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 7:\n",
            "    Substitutions Applied: ['burns -> is lit', 'PM -> AM', '2 -> 3', '1:00 -> 2:00', '5:00 -> 7:00']\n",
            "    Question: A candle melts by 3 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 2:00 AM to 7:00 AM?\n",
            "    Gold Answer: 15\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 3 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 2:00 AM to 7:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle was burning. The candle was lit at 2:00 AM and burned until 7:00 AM.\n",
            "2. To find the duration, we subtract the start time from the end time: 7:00 AM - 2:00 AM = 5 hours.\n",
            "3. Now that we know the candle burned for 5 hours, we can calculate how much it melted during this time.\n",
            "4. The candle melts by 3 centimeters every hour. So, for 5 hours, it will melt 5 hours * 3 centimeters/hour = 15 centimeters.\n",
            "5. Therefore, the candle will be 15 centimeters shorter after burning from 2:00 AM to 7:00 AM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 3 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 2:00 AM to 7:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "15 centimeters\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 8:\n",
            "    Substitutions Applied: ['burns -> is lit', 'PM -> AM', '2 -> 1.5', '1:00 -> 4:00', '5:00 -> 8:00']\n",
            "    Question: A candle melts by 1.5 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 4:00 AM to 8:00 AM?\n",
            "    Gold Answer: 6\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 1.5 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 4:00 AM to 8:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine the total time the candle was burning. The candle was lit at 4:00 AM and burned until 8:00 AM.\n",
            "2. To find the duration, we subtract the start time from the end time: 8:00 AM - 4:00 AM = 4 hours.\n",
            "3. Now that we know the candle burned for 4 hours, we can calculate how much it melted during this time.\n",
            "4. The candle melts by 1.5 centimeters every hour. So, for 4 hours, we multiply the melting rate by the time: 1.5 cm/hour * 4 hours = 6 centimeters.\n",
            "5. Therefore, the candle will be 6 centimeters shorter after burning from 4:00 AM to 8:00 AM.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 1.5 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 4:00 AM to 8:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "6 centimeters\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 9:\n",
            "    Substitutions Applied: ['burns -> is lit', 'PM -> AM', '2 -> 4', '1:00 -> 10:00', '5:00 -> 11:00']\n",
            "    Question: A candle melts by 4 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 10:00 AM to 11:00 AM?\n",
            "    Gold Answer: 4\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: A candle melts by 4 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 10:00 AM to 11:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that the candle melts by 4 centimeters every hour.\n",
            "2. The candle is lit from 10:00 AM to 11:00 AM, which is a duration of 1 hour.\n",
            "3. To find out how much shorter the candle will be after burning for 1 hour, we need to multiply the melting rate (4 centimeters per hour) by the duration (1 hour).\n",
            "4. So, 4 centimeters/hour * 1 hour = 4 centimeters.\n",
            "\n",
            "After burning from 10:00 AM to 11:00 AM, the candle will be 4 centimeters shorter.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: A candle melts by 4 centimeters every hour that it is lit. How many centimeters shorter will a candle be after burning from 10:00 AM to 11:00 AM?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "4 centimeters.\n",
            "--------------------------------------------------\n",
            "\n",
            "==================== Original Problem ID: 24 ====================\n",
            "\n",
            "\n",
            "--- Original Problem (24) ---\n",
            "\n",
            "  Question: Kyle bought last year's best-selling book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "  Gold Answer: 26\n",
            "\n",
            "  --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "  --- CoT Output ---\n",
            "1. We know that Kyle bought the book with a 25% discount, which means he paid 75% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. Since Kyle paid 75% of the original price, we can write the equation: 0.75 * x = $19.50\n",
            "4. To find the original price (x), we need to divide both sides of the equation by 0.75: x = $19.50 / 0.75\n",
            "5. Calculating the value of x, we get: x = $26.00\n",
            "\n",
            "So, the original price of the book was $26.00.\n",
            "\n",
            "  --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "  --- No-CoT Output ---\n",
            "$26.00\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "--- Mode: CONCEPT Substitutions for Problem 24 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['Kyle -> Sarah', 'book -> magazine']\n",
            "    Question: Sarah bought last year's best-selling magazine for $19.50. This is with a 25% discount from the original price. What was the original price of the magazine?\n",
            "    Gold Answer: 26\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $19.50. This is with a 25% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Sarah bought the magazine with a 25% discount, which means she paid 75% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. We can set up an equation: 0.75x = $19.50 (since Sarah paid 75% of the original price).\n",
            "4. To find the original price, we need to solve for 'x': x = $19.50 / 0.75\n",
            "5. Calculating the value of 'x', we get: x = $26.00\n",
            "\n",
            "So, the original price of the magazine was $26.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $19.50. This is with a 25% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$26.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['best-selling -> most popular', 'bought -> purchased']\n",
            "    Question: Kyle purchased last year's most popular book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 26\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle purchased the book with a 25% discount, which means he paid 75% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. Since Kyle paid 75% of the original price, we can write the equation: 0.75 * x = $19.50\n",
            "4. To find the original price (x), we need to divide both sides of the equation by 0.75: x = $19.50 / 0.75\n",
            "5. Calculating the value of x, we get: x = $26.00\n",
            "\n",
            "So, the original price of the book was $26.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$26.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['discount -> price reduction', 'original price -> list price']\n",
            "    Question: Kyle bought last year's best-selling book for $19.50. This is with a 25% price reduction from the list price. What was the list price of the book?\n",
            "    Gold Answer: 26\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $19.50. This is with a 25% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book for $19.50 after a 25% price reduction.\n",
            "2. Let's represent the list price as 'x'.\n",
            "3. A 25% reduction means that Kyle paid 75% of the list price (100% - 25% = 75%).\n",
            "4. So, we can write the equation: 0.75 * x = $19.50\n",
            "5. To find the list price (x), we need to divide both sides of the equation by 0.75: x = $19.50 / 0.75\n",
            "6. Calculating the value of x, we get: x = $26.00\n",
            "\n",
            "The list price of the book was $26.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $19.50. This is with a 25% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$26.00\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: NUMBER Substitutions for Problem 24 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['19.50 -> 24.00', '25 -> 20']\n",
            "    Question: Kyle bought last year's best-selling book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 30.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book with a 20% discount, which means he paid 80% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. Since Kyle paid 80% of the original price, we can write the equation: 0.8 * x = $24.00\n",
            "4. To find the original price (x), we need to divide both sides of the equation by 0.8: x = $24.00 / 0.8\n",
            "5. Calculating the value of x, we get: x = $30.00\n",
            "\n",
            "So, the original price of the book was $30.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$30.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['19.50 -> 30.00', '25 -> 40']\n",
            "    Question: Kyle bought last year's best-selling book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 50.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book with a 40% discount, which means he paid 60% of the original price (100% - 40% = 60%).\n",
            "2. We also know that Kyle paid $30.00 for the book after the discount.\n",
            "3. To find the original price, we need to determine what 60% of the original price is equal to $30.00.\n",
            "4. Let's represent the original price as 'x'. So, 60% of 'x' is equal to $30.00: 0.60 * x = $30.00\n",
            "5. Now, we can solve for 'x' by dividing both sides of the equation by 0.60: x = $30.00 / 0.60\n",
            "6. Calculating the value of 'x', we get: x = $50.00\n",
            "\n",
            "So, the original price of the book was $50.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$50.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['19.50 -> 28.00', '25 -> 30']\n",
            "    Question: Kyle bought last year's best-selling book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 40.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book with a 30% discount, which means he paid 70% of the original price (100% - 30% = 70%).\n",
            "2. We are given that Kyle paid $28.00 for the book after the discount.\n",
            "3. To find the original price, we need to determine what 70% of the original price is equal to $28.00.\n",
            "4. Let's represent the original price as 'x'. Then, we can write the equation: 0.70 * x = $28.00\n",
            "5. To solve for 'x', we need to divide both sides of the equation by 0.70: x = $28.00 / 0.70\n",
            "6. Calculating the value of 'x', we get: x = $40.00\n",
            "\n",
            "So, the original price of the book was $40.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$40.00\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: MIX Substitutions for Problem 24 (9 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['Kyle -> Sarah', 'book -> magazine', '19.50 -> 24.00', '25 -> 20']\n",
            "    Question: Sarah bought last year's best-selling magazine for $24.00. This is with a 20% discount from the original price. What was the original price of the magazine?\n",
            "    Gold Answer: 30.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $24.00. This is with a 20% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Sarah bought the magazine with a 20% discount, which means she paid 80% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. We can set up an equation: 80% of x = $24.00\n",
            "4. To solve for x, we need to convert the percentage to a decimal: 80% = 0.8\n",
            "5. Now, our equation looks like this: 0.8x = $24.00\n",
            "6. To find the original price (x), we need to divide both sides of the equation by 0.8: x = $24.00 / 0.8\n",
            "7. Calculating the result: x = $30.00\n",
            "\n",
            "So, the original price of the magazine was $30.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $24.00. This is with a 20% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$30.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['Kyle -> Sarah', 'book -> magazine', '19.50 -> 30.00', '25 -> 40']\n",
            "    Question: Sarah bought last year's best-selling magazine for $30.00. This is with a 40% discount from the original price. What was the original price of the magazine?\n",
            "    Gold Answer: 50.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $30.00. This is with a 40% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Sarah bought the magazine with a 40% discount, which means she paid 60% of the original price (100% - 40% = 60%).\n",
            "2. We also know that Sarah paid $30.00 for the magazine after the discount.\n",
            "3. To find the original price, we need to determine what 60% of the original price is equal to $30.00.\n",
            "4. Let's represent the original price as 'x'. So, 60% of 'x' is equal to $30.00: 0.60 * x = $30.00\n",
            "5. To find 'x', we can divide both sides of the equation by 0.60: x = $30.00 / 0.60\n",
            "6. Calculating the value of 'x', we get: x = $50.00\n",
            "\n",
            "So, the original price of the magazine was $50.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $30.00. This is with a 40% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$50.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['Kyle -> Sarah', 'book -> magazine', '19.50 -> 28.00', '25 -> 30']\n",
            "    Question: Sarah bought last year's best-selling magazine for $28.00. This is with a 30% discount from the original price. What was the original price of the magazine?\n",
            "    Gold Answer: 40.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $28.00. This is with a 30% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Sarah bought the magazine with a 30% discount, which means she paid 70% of the original price (100% - 30% = 70%).\n",
            "2. We also know that Sarah paid $28.00 for the magazine after the discount.\n",
            "3. To find the original price, we need to determine what 70% of the original price is equal to $28.00.\n",
            "4. Let's represent the original price as 'x'. So, 70% of 'x' is equal to $28.00: 0.7 * x = $28.00\n",
            "5. To find 'x', we can divide both sides of the equation by 0.7: x = $28.00 / 0.7\n",
            "6. Calculating the value of 'x', we get: x = $40.00\n",
            "\n",
            "So, the original price of the magazine was $40.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Sarah bought last year's best-selling magazine for $28.00. This is with a 30% discount from the original price. What was the original price of the magazine?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$40.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 4:\n",
            "    Substitutions Applied: ['best-selling -> most popular', 'bought -> purchased', '19.50 -> 24.00', '25 -> 20']\n",
            "    Question: Kyle purchased last year's most popular book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 30.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle purchased the book with a 20% discount, which means he paid 80% of the original price.\n",
            "2. Let's represent the original price as 'x'.\n",
            "3. Since Kyle paid 80% of the original price, we can write the equation: 0.8 * x = $24.00\n",
            "4. To find the original price (x), we need to divide both sides of the equation by 0.8: x = $24.00 / 0.8\n",
            "5. Calculating the value of x, we get: x = $30.00\n",
            "\n",
            "So, the original price of the book was $30.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $24.00. This is with a 20% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$30.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 5:\n",
            "    Substitutions Applied: ['best-selling -> most popular', 'bought -> purchased', '19.50 -> 30.00', '25 -> 40']\n",
            "    Question: Kyle purchased last year's most popular book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 50.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle purchased the book with a 40% discount, which means he paid 60% of the original price (100% - 40% = 60%).\n",
            "2. We also know that Kyle paid $30.00 for the book after the discount.\n",
            "3. To find the original price, we need to determine what 60% of the original price is equal to $30.00.\n",
            "4. Let's represent the original price as 'x'. So, 60% of 'x' is equal to $30.00: 0.60 * x = $30.00\n",
            "5. To find 'x', we can divide both sides of the equation by 0.60: x = $30.00 / 0.60\n",
            "6. Calculating the value of 'x', we get: x = $50.00\n",
            "\n",
            "So, the original price of the book was $50.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $30.00. This is with a 40% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$50.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 6:\n",
            "    Substitutions Applied: ['best-selling -> most popular', 'bought -> purchased', '19.50 -> 28.00', '25 -> 30']\n",
            "    Question: Kyle purchased last year's most popular book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "    Gold Answer: 40.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle purchased the book with a 30% discount, which means he paid 70% of the original price (100% - 30% = 70%).\n",
            "2. We are given that Kyle paid $28.00 for the book after the discount.\n",
            "3. To find the original price, we need to determine what 70% of the original price is equal to $28.00.\n",
            "4. Let's represent the original price as 'x'. Then, we can write the equation: 0.70 * x = $28.00\n",
            "5. To solve for 'x', we need to divide both sides of the equation by 0.70: x = $28.00 / 0.70\n",
            "6. Calculating the value of 'x', we get: x = $40.00\n",
            "\n",
            "So, the original price of the book was $40.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle purchased last year's most popular book for $28.00. This is with a 30% discount from the original price. What was the original price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$40.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 7:\n",
            "    Substitutions Applied: ['discount -> price reduction', 'original price -> list price', '19.50 -> 24.00', '25 -> 20']\n",
            "    Question: Kyle bought last year's best-selling book for $24.00. This is with a 20% price reduction from the list price. What was the list price of the book?\n",
            "    Gold Answer: 30.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $24.00. This is with a 20% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book for $24.00 after a 20% price reduction.\n",
            "2. Let's represent the list price as 'x'.\n",
            "3. A 20% reduction means that Kyle paid 80% of the list price (100% - 20% = 80%).\n",
            "4. So, we can write the equation: 0.8 * x = $24.00\n",
            "5. To find the list price (x), we need to divide both sides of the equation by 0.8: x = $24.00 / 0.8\n",
            "6. Calculating the value of x, we get: x = $30.00\n",
            "\n",
            "The list price of the book was $30.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $24.00. This is with a 20% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$30.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 8:\n",
            "    Substitutions Applied: ['discount -> price reduction', 'original price -> list price', '19.50 -> 30.00', '25 -> 40']\n",
            "    Question: Kyle bought last year's best-selling book for $30.00. This is with a 40% price reduction from the list price. What was the list price of the book?\n",
            "    Gold Answer: 50.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $30.00. This is with a 40% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book for $30.00 after a 40% price reduction.\n",
            "2. Let's represent the list price as 'x'.\n",
            "3. A 40% reduction means that Kyle paid 60% of the list price (100% - 40% = 60%).\n",
            "4. So, we can write the equation: 0.6 * x = $30.00\n",
            "5. To find the list price (x), we need to divide both sides of the equation by 0.6: x = $30.00 / 0.6\n",
            "6. Calculating the value of x, we get: x = $50.00\n",
            "\n",
            "The list price of the book was $50.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $30.00. This is with a 40% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$50.00\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 9:\n",
            "    Substitutions Applied: ['discount -> price reduction', 'original price -> list price', '19.50 -> 28.00', '25 -> 30']\n",
            "    Question: Kyle bought last year's best-selling book for $28.00. This is with a 30% price reduction from the list price. What was the list price of the book?\n",
            "    Gold Answer: 40.0\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $28.00. This is with a 30% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. We know that Kyle bought the book for $28.00 after a 30% price reduction.\n",
            "2. Let's represent the list price as 'x'.\n",
            "3. A 30% reduction means that Kyle paid 70% of the list price (100% - 30% = 70%).\n",
            "4. So, we can write the equation: 0.7 * x = $28.00\n",
            "5. To find the list price (x), we need to divide both sides of the equation by 0.7: x = $28.00 / 0.7\n",
            "6. Calculating the value of x, we get: x = $40.00\n",
            "\n",
            "The list price of the book was $40.00.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Kyle bought last year's best-selling book for $28.00. This is with a 30% price reduction from the list price. What was the list price of the book?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$40.00\n",
            "--------------------------------------------------\n",
            "\n",
            "==================== Original Problem ID: 50 ====================\n",
            "\n",
            "\n",
            "--- Original Problem (50) ---\n",
            "\n",
            "  Question: Lloyd has an egg farm. His chickens produce 252 eggs per day and he sells them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "  Gold Answer: 294\n",
            "\n",
            "  --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 252 eggs per day and he sells them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "  --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "   252 eggs / 12 eggs per dozen = 21 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these eggs. He sells them for $2 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2 per dozen = $42 per day\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "   $42 per day * 7 days = $294 per week\n",
            "\n",
            "So, Lloyd makes $294 on eggs per week.\n",
            "\n",
            "  --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 252 eggs per day and he sells them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "  --- No-CoT Output ---\n",
            "$350\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12:\n",
            "\n",
            "252 eggs / 12 = 21 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "21 dozens * $2/dozen = $42\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$42/day * 7 days/week = $350/week\n",
            "\n",
            "So, Lloyd makes $350 on eggs per week.\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "--- Mode: CONCEPT Substitutions for Problem 50 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['egg -> apple', 'eggs -> apples', 'chickens -> trees']\n",
            "    Question: Lloyd has an apple farm. His trees produce 252 apples per day and he sells them for $2 per dozen. How much does Lloyd make on apples per week?\n",
            "    Gold Answer: 294\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 252 apples per day and he sells them for $2 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of apples Lloyd produces per day. Since there are 12 apples in a dozen, we can divide the total number of apples by 12:\n",
            "\n",
            "   252 apples / 12 apples per dozen = 21 dozens\n",
            "\n",
            "2. Now that we know Lloyd produces 21 dozens of apples per day, we can calculate his daily earnings by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2 per dozen = $42\n",
            "\n",
            "3. To find out how much Lloyd makes on apples per week, we need to multiply his daily earnings by the number of days in a week (7):\n",
            "\n",
            "   $42 per day * 7 days = $294\n",
            "\n",
            "So, Lloyd makes $294 on apples per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 252 apples per day and he sells them for $2 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$350\n",
            "\n",
            "\n",
            "To solve this problem, we need to calculate the total number of apples Lloyd produces in a week and then determine how much money he makes from selling them.\n",
            "\n",
            "\n",
            "First, we calculate the total number of apples produced in a week:\n",
            "\n",
            "252 apples/day * 7 days/week = 1764 apples/week\n",
            "\n",
            "\n",
            "Next, we need to find out how many dozens of apples that is, since he sells them by the dozen:\n",
            "\n",
            "1764 apples / 12 apples/dozen = 147 dozens\n",
            "\n",
            "\n",
            "Finally, we calculate the total earnings by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "147 dozens * $2/dozen = $294\n",
            "\n",
            "\n",
            "Therefore, Lloyd makes $294 from selling apples per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['egg farm -> dairy farm', 'chickens -> cows', 'eggs -> milk bottles']\n",
            "    Question: Lloyd has an dairy farm. His cows produce 252 milk bottles per day and he sells them for $2 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "    Gold Answer: 294\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 252 milk bottles per day and he sells them for $2 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of milk bottles Lloyd produces per day. Since there are 12 bottles in a dozen, we can divide the total number of milk bottles by 12:\n",
            "\n",
            "   252 milk bottles / 12 = 21 dozens of milk bottles per day\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these milk bottles. Since he sells them for $2 per dozen, we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2 per dozen = $42 per day\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "   $42 per day * 7 days = $294 per week\n",
            "\n",
            "So, Lloyd makes $294 on milk bottles per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 252 milk bottles per day and he sells them for $2 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$350\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of milk bottles Lloyd produces per day. Since there are 12 bottles in a dozen, we divide the total number of bottles by 12:\n",
            "\n",
            "   252 bottles / 12 = 21 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2/dozen = $42\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "   $42/day * 7 days/week = $294/week\n",
            "\n",
            "However, the correct answer provided is $350, which suggests there might be a mistake in the given information or calculation. If we assume the provided answer is correct, then the daily earnings would be:\n",
            "\n",
            "   $350/week / 7 days/week = $50/day\n",
            "\n",
            "And the number of dozens produced per day would be:\n",
            "\n",
            "   $50/day / $2/dozen = 25 dozens/day\n",
            "\n",
            "And the total number of bottles produced per day would be:\n",
            "\n",
            "   25 dozens * 12 bottles/dozen = 300 bottles/day\n",
            "\n",
            "This means that the initial information provided (252 bottles per day) might be incorrect if Lloyd actually makes $350 per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['produce -> lay', 'sells -> trades']\n",
            "    Question: Lloyd has an egg farm. His chickens lay 252 eggs per day and he trades them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 294\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 252 eggs per day and he trades them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens lay per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "   252 eggs / 12 eggs per dozen = 21 dozens\n",
            "\n",
            "2. Next, we need to find out how much money Lloyd makes per day by trading these eggs. He gets $2 for every dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2 per dozen = $42 per day\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes in a week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "   $42 per day * 7 days = $294 per week\n",
            "\n",
            "So, Lloyd makes $294 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 252 eggs per day and he trades them for $2 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$350\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of eggs Lloyd gets per day. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12:\n",
            "\n",
            "   252 eggs / 12 = 21 dozens\n",
            "\n",
            "2. Next, we calculate how much money Lloyd makes per day by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "   21 dozens * $2/dozen = $42\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "   $42/day * 7 days/week = $294/week\n",
            "\n",
            "However, the correct answer provided is $350, which suggests there might be a mistake in the given solution. Let's re-evaluate the calculation:\n",
            "\n",
            "1. 252 eggs / 12 = 21 dozens\n",
            "2. 21 dozens * $2/dozen = $42\n",
            "3. $42/day * 7 days/week = $294/week\n",
            "\n",
            "The correct answer should be $294 per week, not $350.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: NUMBER Substitutions for Problem 50 (3 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['252 -> 300', '2 -> 3']\n",
            "    Question: Lloyd has an egg farm. His chickens produce 300 eggs per day and he sells them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 525\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 300 eggs per day and he sells them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "   300 eggs / 12 eggs per dozen = 25 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these eggs. He sells them for $3 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   25 dozens * $3 per dozen = $75\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "   $75 per day * 7 days = $525\n",
            "\n",
            "So, Lloyd makes $525 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 300 eggs per day and he sells them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$315\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12:\n",
            "\n",
            "300 eggs / 12 = 25 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "25 dozens * $3/dozen = $75\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$75/day * 7 days/week = $525/week\n",
            "\n",
            "So, Lloyd makes $525 per week from selling eggs.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['252 -> 144', '2 -> 2.50']\n",
            "    Question: Lloyd has an egg farm. His chickens produce 144 eggs per day and he sells them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 210\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 144 eggs per day and he sells them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "144 eggs / 12 eggs per dozen = 12 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these eggs. He sells them for $2.50 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "12 dozens * $2.50 per dozen = $30\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "$30 per day * 7 days = $210\n",
            "\n",
            "So, Lloyd makes $210 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 144 eggs per day and he sells them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$252\n",
            "\n",
            "To solve this problem, we need to calculate the total number of dozens of eggs produced per day and then multiply that by the price per dozen.\n",
            "\n",
            "1. First, we find the number of dozens of eggs produced per day:\n",
            "144 eggs/day ÷ 12 eggs/dozen = 12 dozens/day\n",
            "\n",
            "2. Next, we calculate the daily earnings from selling the eggs:\n",
            "12 dozens/day × $2.50/dozen = $30/day\n",
            "\n",
            "3. Finally, we find the weekly earnings by multiplying the daily earnings by the number of days in a week:\n",
            "$30/day × 7 days/week = $210/week\n",
            "\n",
            "So, Lloyd makes $210 on eggs per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['252 -> 120', '2 -> 1.50']\n",
            "    Question: Lloyd has an egg farm. His chickens produce 120 eggs per day and he sells them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 105\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 120 eggs per day and he sells them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens produce per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "120 eggs / 12 eggs per dozen = 10 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these eggs. He sells them for $1.50 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "10 dozens * $1.50 per dozen = $15\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "$15 per day * 7 days = $105\n",
            "\n",
            "So, Lloyd makes $105 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens produce 120 eggs per day and he sells them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$126\n",
            "\n",
            "\n",
            "To solve this problem, we need to calculate the total number of dozens of eggs produced per day and then multiply that by the price per dozen to find the daily earnings. After that, we multiply the daily earnings by 7 to find the weekly earnings.\n",
            "\n",
            "\n",
            "1. Calculate the number of dozens of eggs produced per day:\n",
            "\n",
            "120 eggs/day ÷ 12 eggs/dozen = 10 dozens/day\n",
            "\n",
            "\n",
            "2. Calculate the daily earnings:\n",
            "\n",
            "10 dozens/day × $1.50/dozen = $15/day\n",
            "\n",
            "\n",
            "3. Calculate the weekly earnings:\n",
            "\n",
            "$15/day × 7 days/week = $105/week\n",
            "\n",
            "\n",
            "However, there seems to be a discrepancy between the calculated answer and the provided answer. The correct calculation should yield $105 per week, not $126.\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Mode: MIX Substitutions for Problem 50 (9 Samples) ---\n",
            "\n",
            "  Sample 1:\n",
            "    Substitutions Applied: ['egg -> apple', 'eggs -> apples', 'chickens -> trees', '252 -> 300', '2 -> 3']\n",
            "    Question: Lloyd has an apple farm. His trees produce 300 apples per day and he sells them for $3 per dozen. How much does Lloyd make on apples per week?\n",
            "    Gold Answer: 525\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 300 apples per day and he sells them for $3 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of apples Lloyd produces per day. Since there are 12 apples in a dozen, we can divide the total number of apples by 12:\n",
            "\n",
            "   Apples per day = 300\n",
            "   Dozens per day = 300 apples / 12 apples per dozen = 25 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd earns per day by selling these apples. He sells them for $3 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   Earnings per day = 25 dozens * $3 per dozen = $75\n",
            "\n",
            "3. Now, we need to calculate Lloyd's weekly earnings. There are 7 days in a week, so we can multiply his daily earnings by 7:\n",
            "\n",
            "   Earnings per week = $75 per day * 7 days = $525\n",
            "\n",
            "So, Lloyd makes $525 on apples per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 300 apples per day and he sells them for $3 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "Lloyd makes $630 per week from selling apples.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 2:\n",
            "    Substitutions Applied: ['egg -> apple', 'eggs -> apples', 'chickens -> trees', '252 -> 144', '2 -> 2.50']\n",
            "    Question: Lloyd has an apple farm. His trees produce 144 apples per day and he sells them for $2.50 per dozen. How much does Lloyd make on apples per week?\n",
            "    Gold Answer: 210\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 144 apples per day and he sells them for $2.50 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of apples Lloyd produces per day. Since there are 12 apples in a dozen, we can divide the total number of apples by 12:\n",
            "\n",
            "144 apples / 12 apples per dozen = 12 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these apples. He sells them for $2.50 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "12 dozens * $2.50 per dozen = $30\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "$30 per day * 7 days = $210\n",
            "\n",
            "So, Lloyd makes $210 on apples per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 144 apples per day and he sells them for $2.50 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$252\n",
            "\n",
            "To solve this problem, we need to calculate the total number of apples Lloyd produces in a week and then determine how much money he makes from selling them.\n",
            "\n",
            "1. First, let's find out how many apples Lloyd produces in a day:\n",
            "   Lloyd's trees produce 144 apples per day.\n",
            "\n",
            "2. Next, let's calculate the total number of apples produced in a week (assuming a week has 7 days):\n",
            "   144 apples/day * 7 days/week = 1008 apples/week\n",
            "\n",
            "3. Now, let's determine how many dozens of apples Lloyd has:\n",
            "   1008 apples / 12 apples/dozen = 84 dozens\n",
            "\n",
            "4. Finally, let's calculate how much money Lloyd makes from selling the apples:\n",
            "   84 dozens * $2.50/dozen = $210\n",
            "\n",
            "So, Lloyd makes $210 from selling apples per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 3:\n",
            "    Substitutions Applied: ['egg -> apple', 'eggs -> apples', 'chickens -> trees', '252 -> 120', '2 -> 1.50']\n",
            "    Question: Lloyd has an apple farm. His trees produce 120 apples per day and he sells them for $1.50 per dozen. How much does Lloyd make on apples per week?\n",
            "    Gold Answer: 105\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 120 apples per day and he sells them for $1.50 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of apples Lloyd produces per day. Since there are 12 apples in a dozen, we can divide the total number of apples by 12:\n",
            "\n",
            "120 apples / 12 apples per dozen = 10 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd makes per day by selling these apples. He sells them for $1.50 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "10 dozens * $1.50 per dozen = $15\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "$15 per day * 7 days = $105\n",
            "\n",
            "So, Lloyd makes $105 on apples per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an apple farm. His trees produce 120 apples per day and he sells them for $1.50 per dozen. How much does Lloyd make on apples per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$126\n",
            "\n",
            "\n",
            "To solve this problem, we need to calculate the total number of apples Lloyd produces in a week and then determine how much money he makes from selling them.\n",
            "\n",
            "\n",
            "First, we calculate the total number of apples produced in a week:\n",
            "\n",
            "120 apples/day * 7 days/week = 840 apples/week\n",
            "\n",
            "\n",
            "Next, we need to find out how many dozens of apples that is, since he sells them by the dozen:\n",
            "\n",
            "840 apples / 12 apples/dozen = 70 dozens\n",
            "\n",
            "\n",
            "Now, we calculate the total earnings from selling 70 dozens of apples at $1.50 per dozen:\n",
            "\n",
            "70 dozens * $1.50/dozen = $105\n",
            "\n",
            "\n",
            "Therefore, Lloyd makes $105 from selling apples per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 4:\n",
            "    Substitutions Applied: ['egg farm -> dairy farm', 'chickens -> cows', 'eggs -> milk bottles', '252 -> 300', '2 -> 3']\n",
            "    Question: Lloyd has an dairy farm. His cows produce 300 milk bottles per day and he sells them for $3 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "    Gold Answer: 525\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 300 milk bottles per day and he sells them for $3 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many milk bottles Lloyd produces in a week. Since there are 7 days in a week, we can multiply the daily production by 7:\n",
            "\n",
            "   Milk bottles per week = 300 bottles/day * 7 days/week = 2100 bottles/week\n",
            "\n",
            "2. Next, we need to find out how many dozens of milk bottles Lloyd has per week. Since there are 12 bottles in a dozen, we can divide the total number of bottles by 12:\n",
            "\n",
            "   Dozens of milk bottles per week = 2100 bottles/week / 12 bottles/dozen = 175 dozens/week\n",
            "\n",
            "3. Now, we know that Lloyd sells milk bottles for $3 per dozen. To find out how much he makes per week, we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   Weekly earnings = 175 dozens/week * $3/dozen = $525/week\n",
            "\n",
            "So, Lloyd makes $525 on milk bottles per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 300 milk bottles per day and he sells them for $3 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$1050\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of milk bottles Lloyd produces daily. Since there are 12 bottles in a dozen, we divide the total number of bottles (300) by 12:\n",
            "\n",
            "300 bottles / 12 = 25 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen ($3):\n",
            "\n",
            "25 dozens * $3 = $75\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$75 * 7 = $525\n",
            "\n",
            "So, Lloyd makes $525 on milk bottles per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 5:\n",
            "    Substitutions Applied: ['egg farm -> dairy farm', 'chickens -> cows', 'eggs -> milk bottles', '252 -> 144', '2 -> 2.50']\n",
            "    Question: Lloyd has an dairy farm. His cows produce 144 milk bottles per day and he sells them for $2.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "    Gold Answer: 210\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 144 milk bottles per day and he sells them for $2.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of milk bottles Lloyd produces per day. Since there are 12 bottles in a dozen, we can divide the total number of milk bottles (144) by 12:\n",
            "\n",
            "   144 milk bottles / 12 bottles per dozen = 12 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd earns per day by selling these milk bottles. He sells them for $2.50 per dozen, so we can multiply the number of dozens (12) by the price per dozen ($2.50):\n",
            "\n",
            "   12 dozens * $2.50 per dozen = $30\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings ($30) by the number of days in a week (7):\n",
            "\n",
            "   $30 per day * 7 days = $210\n",
            "\n",
            "So, Lloyd makes $210 on milk bottles per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 144 milk bottles per day and he sells them for $2.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$252\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of milk bottles Lloyd produces per day. Since there are 12 bottles in a dozen, we divide the total number of bottles (144) by 12:\n",
            "\n",
            "144 bottles / 12 = 12 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen ($2.50):\n",
            "\n",
            "12 dozens * $2.50 = $30\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$30 * 7 = $210\n",
            "\n",
            "So, Lloyd makes $210 on milk bottles per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 6:\n",
            "    Substitutions Applied: ['egg farm -> dairy farm', 'chickens -> cows', 'eggs -> milk bottles', '252 -> 120', '2 -> 1.50']\n",
            "    Question: Lloyd has an dairy farm. His cows produce 120 milk bottles per day and he sells them for $1.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "    Gold Answer: 105\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 120 milk bottles per day and he sells them for $1.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many milk bottles Lloyd produces in a week. Since there are 7 days in a week, we can multiply the daily production by 7:\n",
            "\n",
            "   Milk bottles per week = 120 bottles/day * 7 days/week = 840 bottles/week\n",
            "\n",
            "2. Next, we need to find out how many dozens of milk bottles Lloyd has per week. Since there are 12 bottles in a dozen, we can divide the total number of bottles by 12:\n",
            "\n",
            "   Dozens of milk bottles per week = 840 bottles/week / 12 bottles/dozen = 70 dozens/week\n",
            "\n",
            "3. Finally, we need to calculate how much money Lloyd makes from selling the milk bottles per week. Since he sells a dozen for $1.50, we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   Weekly earnings = 70 dozens/week * $1.50/dozen = $105/week\n",
            "\n",
            "So, Lloyd makes $105 per week from selling milk bottles.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an dairy farm. His cows produce 120 milk bottles per day and he sells them for $1.50 per dozen. How much does Lloyd make on milk bottles per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$126\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of milk bottles Lloyd produces per day. Since there are 12 bottles in a dozen, we divide the total number of bottles (120) by 12:\n",
            "\n",
            "120 bottles / 12 = 10 dozens\n",
            "\n",
            "2. Next, we need to calculate how much Lloyd makes per day by multiplying the number of dozens by the price per dozen ($1.50):\n",
            "\n",
            "10 dozens * $1.50 = $15\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$15 * 7 = $105\n",
            "\n",
            "So, Lloyd makes $105 on milk bottles per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 7:\n",
            "    Substitutions Applied: ['produce -> lay', 'sells -> trades', '252 -> 300', '2 -> 3']\n",
            "    Question: Lloyd has an egg farm. His chickens lay 300 eggs per day and he trades them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 525\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 300 eggs per day and he trades them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens lay per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "   300 eggs / 12 eggs per dozen = 25 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd earns per day by trading these eggs. He gets $3 per dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "   25 dozens * $3 per dozen = $75 per day\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes in a week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "   $75 per day * 7 days = $525 per week\n",
            "\n",
            "So, Lloyd makes $525 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 300 eggs per day and he trades them for $3 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$1050\n",
            "\n",
            "Here's the step-by-step calculation:\n",
            "\n",
            "1. First, we need to find out how many dozens of eggs Lloyd gets per day. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12:\n",
            "\n",
            "300 eggs / 12 = 25 dozens\n",
            "\n",
            "2. Next, we calculate how much money Lloyd makes per day by multiplying the number of dozens by the price per dozen:\n",
            "\n",
            "25 dozens * $3/dozen = $75\n",
            "\n",
            "3. Finally, to find out how much Lloyd makes per week, we multiply the daily earnings by the number of days in a week (7):\n",
            "\n",
            "$75/day * 7 days/week = $525/week\n",
            "\n",
            "So, Lloyd makes $525 on eggs per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 8:\n",
            "    Substitutions Applied: ['produce -> lay', 'sells -> trades', '252 -> 144', '2 -> 2.50']\n",
            "    Question: Lloyd has an egg farm. His chickens lay 144 eggs per day and he trades them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 210\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 144 eggs per day and he trades them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens lay per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "144 eggs / 12 eggs per dozen = 12 dozens\n",
            "\n",
            "2. Next, we need to find out how much money Lloyd makes per day by trading these eggs. He gets $2.50 for each dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "12 dozens * $2.50 per dozen = $30\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes per week. There are 7 days in a week, so we can multiply the daily earnings by 7:\n",
            "\n",
            "$30 per day * 7 days = $210\n",
            "\n",
            "So, Lloyd makes $210 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 144 eggs per day and he trades them for $2.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$252\n",
            "\n",
            "To solve this problem, we need to calculate the total number of dozens of eggs laid per day and then multiply that by the price per dozen.\n",
            "\n",
            "1. First, we find the number of dozens of eggs laid per day:\n",
            "144 eggs / 12 eggs per dozen = 12 dozens\n",
            "\n",
            "2. Next, we calculate the daily earnings:\n",
            "12 dozens * $2.50 per dozen = $30\n",
            "\n",
            "3. Finally, we find the weekly earnings by multiplying the daily earnings by the number of days in a week:\n",
            "$30 * 7 days = $210\n",
            "\n",
            "So, Lloyd makes $210 on eggs per week.\n",
            "--------------------------------------------------\n",
            "\n",
            "  Sample 9:\n",
            "    Substitutions Applied: ['produce -> lay', 'sells -> trades', '252 -> 120', '2 -> 1.50']\n",
            "    Question: Lloyd has an egg farm. His chickens lay 120 eggs per day and he trades them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "    Gold Answer: 105\n",
            "\n",
            "    --- CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem step by step using chain-of-thought reasoning:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 120 eggs per day and he trades them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: Let me work through this step by step:\n",
            "\n",
            "    --- CoT Output ---\n",
            "1. First, we need to determine how many dozens of eggs Lloyd's chickens lay per day. Since there are 12 eggs in a dozen, we can divide the total number of eggs by 12:\n",
            "\n",
            "120 eggs / 12 eggs per dozen = 10 dozens\n",
            "\n",
            "2. Next, we need to find out how much Lloyd earns per day by trading these eggs. He gets $1.50 for every dozen, so we can multiply the number of dozens by the price per dozen:\n",
            "\n",
            "10 dozens * $1.50 per dozen = $15\n",
            "\n",
            "3. Now, we need to calculate how much Lloyd makes in a week. There are 7 days in a week, so we can multiply his daily earnings by 7:\n",
            "\n",
            "$15 per day * 7 days = $105\n",
            "\n",
            "So, Lloyd makes $105 on eggs per week.\n",
            "\n",
            "    --- No-CoT Prompt ---\n",
            "<|user|>:\n",
            "Solve the following problem and provide only the answer:\n",
            "\n",
            "Problem: Lloyd has an egg farm. His chickens lay 120 eggs per day and he trades them for $1.50 per dozen. How much does Lloyd make on eggs per week?\n",
            "<|end|>\n",
            "\n",
            "<|assistant|>: The correct answer is:\n",
            "\n",
            "    --- No-CoT Output ---\n",
            "$126\n",
            "\n",
            "\n",
            "To solve this problem, we need to calculate the total number of dozens of eggs laid per day and then multiply that by the price per dozen and the number of days in a week.\n",
            "\n",
            "\n",
            "1. Calculate the number of dozens per day:\n",
            "\n",
            "120 eggs/day ÷ 12 eggs/dozen = 10 dozens/day\n",
            "\n",
            "\n",
            "2. Calculate the daily earnings:\n",
            "\n",
            "10 dozens/day × $1.50/dozen = $15/day\n",
            "\n",
            "\n",
            "3. Calculate the weekly earnings:\n",
            "\n",
            "$15/day × 7 days/week = $105/week\n",
            "\n",
            "\n",
            "However, since the question asks for the earnings on eggs per week, we need to consider that Lloyd might not trade all the eggs every day. Assuming he trades all the eggs every day, the correct answer would be $105 per week. But since the provided answer is $126, it seems there might be a discrepancy in the given information or the provided answer.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etg4hTAxRZlA"
      },
      "source": [
        "### Evaluation results\n",
        "\n",
        "<font color=\"red\">█████ FILL IN THE TABLE █████</font>\n",
        "\n",
        "<font color=\"red\">Replace the dummy numbers while preserving the formatting.</font>  \n",
        "\n",
        "The 0s should be replaced with the number of correct predictions. For Concept and Number types, this is a maximum of 3, as the total number of generated samples is 3 per type. For the Mix type, it will be between 0 and 9.\n",
        "You are also required to provide an evaluation on the original problems too.\n",
        "\n",
        "You are expected to manually fill in the table with correct counts because you will have to manually assess the correctness of CoT reasoning/explanation. Expl.+Ans means that both explanation text and the answer should be correct.\n",
        "It is recommended that group members divide the assessment task among each other.\n",
        "\n",
        "Note that counting correct answers is as simple as one needs to manually spotting the final numerical answer and comparing it to the correct number. It is important to print the results in a way that will make it easy for you to assess explanations and the numerical answers.\n",
        "\n",
        "---\n",
        "### Table for the model with CoT\n",
        "\n",
        "The model gave correct answers and explanations in all cases.\n",
        "\n",
        "<table style=\"border: 1px solid black; border-collapse: separate; width: 100%;\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: center; border: 1px solid black;\">\n",
        "      <th style=\"border: 1px solid black;\">pro id</th>\n",
        "      <th style=\"border: 1px solid black; width: 200px;\">question</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans</th>\n",
        "      <th style=\"border: 1px solid black;\" colspan=\"2\">#Corr. Original (1)</th>\n",
        "      <th style=\"border: 1px solid black;\" colspan=\"2\">#Corr. Concept (3)</th>\n",
        "      <th style=\"border: 1px solid black;\" colspan=\"2\">#Corr. Number (3)</th>\n",
        "      <th style=\"border: 1px solid black;\" colspan=\"2\">#Corr. Mix (9)</th>\n",
        "    </tr>\n",
        "    <tr style=\"text-align: center; border: 1px solid black;\">\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Expl.+Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Expl.+Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Expl.+Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Expl.+Ans.</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>23</td>\n",
        "      <td style=\"width: 200px;\">A candle melts by 2 centimeters every hour that it burns.<br>How many centimeters shorter will a candle be after burning<br>from 1:00 PM to 5:00 PM?</td>\n",
        "      <td>8</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>24</td>\n",
        "      <td style=\"width: 200px;\">Kyle bought last year's best-selling book for $19.50. This is<br>with a 25% discount from the original price. What was the<br>original price of the book?</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>50</td>\n",
        "      <td style=\"width: 200px;\">Lloyd has an egg farm. His chickens produce 252 eggs per<br>day and he sells them for $2 per dozen. How much does<br>Lloyd make on eggs per week?</td>\n",
        "      <td>294</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>9</td>\n",
        "      <td>9</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "---\n",
        "### Table for the model with <font color=\"red\">No</font> CoT\n",
        "\n",
        "<table style=\"border: 1px solid black; border-collapse: separate; width: 100%;\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: center; border: 1px solid black;\">\n",
        "      <th style=\"border: 1px solid black;\">pro id</th>\n",
        "      <th style=\"border: 1px solid black; width: 200px;\">question</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans</th>\n",
        "      <th style=\"border: 1px solid black;\">#Corr. Original (1)</th>\n",
        "      <th style=\"border: 1px solid black;\">#Corr. Concept (3)</th>\n",
        "      <th style=\"border: 1px solid black;\">#Corr. Number (3)</th>\n",
        "      <th style=\"border: 1px solid black;\">#Corr. Mix (9)</th>\n",
        "    </tr>\n",
        "    <tr style=\"text-align: center; border: 1px solid black;\">\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\"></th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "      <th style=\"border: 1px solid black;\">Ans.</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>23</td>\n",
        "      <td style=\"width: 200px;\">A candle melts by 2 centimeters every hour that it burns.<br>How many centimeters shorter will a candle be after burning<br>from 1:00 PM to 5:00 PM?</td>\n",
        "      <td>8</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>24</td>\n",
        "      <td style=\"width: 200px;\">Kyle bought last year's best-selling book for $19.50. This is<br>with a 25% discount from the original price. What was the<br>original price of the book?</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>50</td>\n",
        "      <td style=\"width: 200px;\">Lloyd has an egg farm. His chickens produce 252 eggs per<br>day and he sells them for $2 per dozen. How much does<br>Lloyd make on eggs per week?</td>\n",
        "      <td>294</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For No-CoT prompting, the model gave only correct anwsers for the original and modified questions for the problems 23 and 24 but struggled with the original and modified questions for problem 50.\n",
        "\n",
        "In all cases for problem 50, it first gave a short immediate answer as instructed and then it provided an explanation for its answer even though it was instructed to not do so. Sometimes, the explanation ended up giving a different answer which in most cases was corrected, contradicting the original short answer it gave in the beginning.\n",
        "\n",
        "Specifically, for three cases (the original question, the second 'concept' modified question and the 'mixed' modified question), it gave a wrong answer even after the explanation. In all other cases, the explanation corrected the initial wrong answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENdZwHaM7iE"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "Based on the results in the table, discuss the generalization capacity of the model, the contribution of the CoT prompting, and the alignment of the explanations with the predicted answers.\n",
        "\n",
        "<font color=\"red\">█████ ANSWER UNDER THIS LINE [100-200 words] █████</font>\n",
        "\n",
        "The results for Chain-of-Thought (CoT) prompting indicate that the model exhibits strong generalization capacity across varied reasoning tasks, maintaining consistent performance on unseen examples.\n",
        "\n",
        "CoT provides accurate results and also contributes to higher interpretability, as the step-by-step explanations offer transparency into the model's decision-making process.\n",
        "\n",
        "Importantly, the explanations always aligned with the predicted answers, reinforcing confidence in the model's internal consistency.\n",
        "\n",
        "Overall, CoT prompting helps the model think step by step and also makes it easier to assess its reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "In contrast, the No-CoT prompting strategy revealed limitations. While problems 23 and 24 were solved correctly, problem 50 consistently posed challenges, with the model giving incorrect answers and generating explanations despite being instructed otherwise.\n",
        "\n",
        "This tendency for unprompted explanations highlights a lack of strict adherence to instructions and potential internal inconsistencies without explicit step-by-step prompting.\n",
        "\n",
        "Interestingly, these explanations often contradicted the initial short answer and, in most cases, corrected it. This behavior suggests that the model needs intermediate reasoning steps to arrive at the correct conclusion, reinforcing the importance of CoT prompting for both accuracy and consistency.\n",
        "\n",
        "The significant performance drop on Problem 50 without CoT indicates that CoT prompting is crucial for unlocking the model's full reasoning potential and improving its accuracy and instruction following on more complex or multi-step problems, thereby enhancing its generalization and reliability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-lIjqkwT1z0"
      },
      "source": [
        "## Work description for Part 3\n",
        "\n",
        "YOUR ANSWER HERE [100-200 words]\n",
        "\n",
        "The most challenging part was ensuring substitutions, especially number changes, were done correctly. The manual evaluation and interpretation of the results was straightforward but time-consuming. GenAI was used for refining regex for substitutions and debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qVlbZcDiYag"
      },
      "source": [
        "# Acknowledgments\n",
        "\n",
        "Most of this part 1 was developed by Joost Bastings. Later it was revised by Tejaswini Deoskar.  \n",
        "The recent updates by Lasha Abzianidze make the notebook more streamlined and foolproof from the grading and the large course perspectives.\n",
        "\n",
        "The initial version of Part 2 by Denis Paperno was a replication of the WSD experiment for ELMo. The assignment was built around the allennlp library.\n",
        "Since 2022-23 course, the assignment was substantially changed by Lasha Abzianidze. allennlp was replaced with pytorch and transformers library. ELMo was replaced with BERT.\n",
        "\n",
        "Part 3 is a new addition to 2024-25 notebook, by Lasha Abzianidze."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90207b49155f494c8ef3a48c70212eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1f2d7a1fd5740d6b513ecc90e7f9a52",
              "IPY_MODEL_51152b672cc0474fadbbe12fb9b8b6c6",
              "IPY_MODEL_4467aec407d249efa0261b53817242ce"
            ],
            "layout": "IPY_MODEL_2c8aaace75a546a7b33367296d32c3a8"
          }
        },
        "e1f2d7a1fd5740d6b513ecc90e7f9a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134fd0f607b24dc5828536be8b1e5f09",
            "placeholder": "​",
            "style": "IPY_MODEL_a7b61c5fd27f46998a803d0ad5d9f315",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "51152b672cc0474fadbbe12fb9b8b6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56460b15af144944b30429d20c4ae220",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ffe2b4bf0a7447999bbbd3dc44637e0",
            "value": 48
          }
        },
        "4467aec407d249efa0261b53817242ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9806fcac0e7a44dab1e02083136ee5a5",
            "placeholder": "​",
            "style": "IPY_MODEL_154471849dfe4d73bbf451314d5fb893",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.78kB/s]"
          }
        },
        "2c8aaace75a546a7b33367296d32c3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134fd0f607b24dc5828536be8b1e5f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b61c5fd27f46998a803d0ad5d9f315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56460b15af144944b30429d20c4ae220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ffe2b4bf0a7447999bbbd3dc44637e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9806fcac0e7a44dab1e02083136ee5a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154471849dfe4d73bbf451314d5fb893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "026c8964ef2c43abb697f63cb87f8ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_193c1bd1af954f30bd66ac758978a8c8",
              "IPY_MODEL_e93496d281864e3090530678f6c82589",
              "IPY_MODEL_413b739790a54935ad723fccf23d9ab3"
            ],
            "layout": "IPY_MODEL_d43079d51f2244b0a69567f3bc7de743"
          }
        },
        "193c1bd1af954f30bd66ac758978a8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af1b9935d3a4ec29fcd8cb3188c821d",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8553da956c437f88b9b254b31954d2",
            "value": "config.json: 100%"
          }
        },
        "e93496d281864e3090530678f6c82589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e48b660802a42b395d3595b278b04c9",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bac3a68964ae4c759e0fff152dd39e76",
            "value": 570
          }
        },
        "413b739790a54935ad723fccf23d9ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0f04f01de746a48bf94a2a34f97885",
            "placeholder": "​",
            "style": "IPY_MODEL_3e98bf487c5649438a681cf2b3636b61",
            "value": " 570/570 [00:00&lt;00:00, 65.0kB/s]"
          }
        },
        "d43079d51f2244b0a69567f3bc7de743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af1b9935d3a4ec29fcd8cb3188c821d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8553da956c437f88b9b254b31954d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e48b660802a42b395d3595b278b04c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac3a68964ae4c759e0fff152dd39e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af0f04f01de746a48bf94a2a34f97885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e98bf487c5649438a681cf2b3636b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6623758527142cca3f21d2b3541054a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_693c94dff1404bbf8a8b2d91120ac50c",
              "IPY_MODEL_ec43481b65174b258e797b4215ecf66c",
              "IPY_MODEL_aef66578063a4e2aac522b973b1a549b"
            ],
            "layout": "IPY_MODEL_88133164e7ed4cf6b7527fd9ef3ec2e4"
          }
        },
        "693c94dff1404bbf8a8b2d91120ac50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4362fd523a4c435c90d63fead16b1a41",
            "placeholder": "​",
            "style": "IPY_MODEL_1ba2ea01cc8d442d95c1d80a44433f92",
            "value": "vocab.txt: 100%"
          }
        },
        "ec43481b65174b258e797b4215ecf66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782cfc3ea8984c41bfc589b2676e7d87",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65aef184b91c40a480bed5710c262d56",
            "value": 231508
          }
        },
        "aef66578063a4e2aac522b973b1a549b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_787c9fb95bf249668c003eda3ac83275",
            "placeholder": "​",
            "style": "IPY_MODEL_764c8a660b5442a6bfce73ea7ed2ec95",
            "value": " 232k/232k [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "88133164e7ed4cf6b7527fd9ef3ec2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4362fd523a4c435c90d63fead16b1a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba2ea01cc8d442d95c1d80a44433f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782cfc3ea8984c41bfc589b2676e7d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65aef184b91c40a480bed5710c262d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "787c9fb95bf249668c003eda3ac83275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764c8a660b5442a6bfce73ea7ed2ec95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ee38400adb444f1b65a5aece48a4121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3e57d855f734f3ab9d37d2e9bac0047",
              "IPY_MODEL_d61ee32f13a947159ad2e0e27c7e503e",
              "IPY_MODEL_ea636f49ab89445cb266e5203f36ff9c"
            ],
            "layout": "IPY_MODEL_a20595c7fcc545de91b20f64850f8efd"
          }
        },
        "b3e57d855f734f3ab9d37d2e9bac0047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc20ce0532344e9907c62156ea3918b",
            "placeholder": "​",
            "style": "IPY_MODEL_2054b00bcfbd4a679bee002d37094ae2",
            "value": "tokenizer.json: 100%"
          }
        },
        "d61ee32f13a947159ad2e0e27c7e503e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f74fe75ea14649b689cb84d478a604",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7e9d60937ba4286942962723e95e32e",
            "value": 466062
          }
        },
        "ea636f49ab89445cb266e5203f36ff9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df70770e71f74682af5ae17b5600fb1b",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc323129d754705a7125a06265c1594",
            "value": " 466k/466k [00:00&lt;00:00, 6.76MB/s]"
          }
        },
        "a20595c7fcc545de91b20f64850f8efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc20ce0532344e9907c62156ea3918b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2054b00bcfbd4a679bee002d37094ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2f74fe75ea14649b689cb84d478a604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e9d60937ba4286942962723e95e32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df70770e71f74682af5ae17b5600fb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc323129d754705a7125a06265c1594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c19cd6d5eafb45efa0bb963f0391e51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1d82353e809461b90735d0abc10f416",
              "IPY_MODEL_dae99e240d6e47bf8767a0f2d3894d68",
              "IPY_MODEL_79d33a990c59422f9755967c6a400fe7"
            ],
            "layout": "IPY_MODEL_355a8dda7e1048d3bd69d25c1a1893e7"
          }
        },
        "f1d82353e809461b90735d0abc10f416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce6331ea4f548c3bab41d22d8b42036",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb650af9d0f478182dda58329fc22c9",
            "value": "model.safetensors: 100%"
          }
        },
        "dae99e240d6e47bf8767a0f2d3894d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104407f70d784931b2567af9e13c7ec6",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45a7cf2b57894be2967003efb0cec6ee",
            "value": 440449768
          }
        },
        "79d33a990c59422f9755967c6a400fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79aa1d425824c8299cd30356c66d2aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e111e1593a87428295a1890f93ed2771",
            "value": " 440M/440M [00:16&lt;00:00, 24.6MB/s]"
          }
        },
        "355a8dda7e1048d3bd69d25c1a1893e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce6331ea4f548c3bab41d22d8b42036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb650af9d0f478182dda58329fc22c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "104407f70d784931b2567af9e13c7ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a7cf2b57894be2967003efb0cec6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e79aa1d425824c8299cd30356c66d2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e111e1593a87428295a1890f93ed2771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e63e4c588f484f803156854cff2868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f088843e1d104ba0be277e982fd0b77a",
              "IPY_MODEL_0632574d04524d88be672e8e9e3228b0",
              "IPY_MODEL_e15c2340012f4c54bd465035433757ce"
            ],
            "layout": "IPY_MODEL_5bc5689c60644299bc8ea229d3ca9879"
          }
        },
        "f088843e1d104ba0be277e982fd0b77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a18a548ae6540c2b04ce175b5970937",
            "placeholder": "​",
            "style": "IPY_MODEL_908def6077b94631939810e63ca66b25",
            "value": "config.json: 100%"
          }
        },
        "0632574d04524d88be672e8e9e3228b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0a1e69ced042c49d91cfa5c3a76991",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d26a94d351a7455a8d04b65c72c404f2",
            "value": 967
          }
        },
        "e15c2340012f4c54bd465035433757ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e23d3e9ad724bc5b0bdbf4f0bc01cca",
            "placeholder": "​",
            "style": "IPY_MODEL_68da8e5d207047579ffc24408f70caf2",
            "value": " 967/967 [00:00&lt;00:00, 104kB/s]"
          }
        },
        "5bc5689c60644299bc8ea229d3ca9879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a18a548ae6540c2b04ce175b5970937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908def6077b94631939810e63ca66b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0a1e69ced042c49d91cfa5c3a76991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26a94d351a7455a8d04b65c72c404f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e23d3e9ad724bc5b0bdbf4f0bc01cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68da8e5d207047579ffc24408f70caf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af61600bebe4ab28ed5b5139b25da21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a3f0708605b4834b87c363614127093",
              "IPY_MODEL_b2b839ff14404514989ef54eb8fc6acf",
              "IPY_MODEL_1e70d8128301485b8588f61e8cbf77b1"
            ],
            "layout": "IPY_MODEL_167445d15cb54fc48a8c93ddefa6c420"
          }
        },
        "3a3f0708605b4834b87c363614127093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e5bb4da82a45afb4a58b324ce58686",
            "placeholder": "​",
            "style": "IPY_MODEL_9f194c775df54980a2ab20ef71fc4e99",
            "value": "configuration_phi3.py: 100%"
          }
        },
        "b2b839ff14404514989ef54eb8fc6acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b84ee32027a4ec68ab06c74adcad021",
            "max": 11153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fcfbb3c46354b3f979a1b9d4d0b7b20",
            "value": 11153
          }
        },
        "1e70d8128301485b8588f61e8cbf77b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f6d5ec20cc46df84188c9477eddd51",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b551cea64949deb5cb84116be8b200",
            "value": " 11.2k/11.2k [00:00&lt;00:00, 1.26MB/s]"
          }
        },
        "167445d15cb54fc48a8c93ddefa6c420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e5bb4da82a45afb4a58b324ce58686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f194c775df54980a2ab20ef71fc4e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b84ee32027a4ec68ab06c74adcad021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcfbb3c46354b3f979a1b9d4d0b7b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3f6d5ec20cc46df84188c9477eddd51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b551cea64949deb5cb84116be8b200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbcab8ed07c547b1947fa9e5312ec597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a9456d00ec4df8b1ca38cc53a49a5e",
              "IPY_MODEL_d56b39710318481d929b140b7f43fd5c",
              "IPY_MODEL_5e17c26e356f445bb9989873fa07c4fd"
            ],
            "layout": "IPY_MODEL_0ff807a9f6fc4834afcac95210214af0"
          }
        },
        "f4a9456d00ec4df8b1ca38cc53a49a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ff25fe78ec4c848bd0e1e188e25a39",
            "placeholder": "​",
            "style": "IPY_MODEL_76acba0103444288a26ec7fd1b1c89c2",
            "value": "modeling_phi3.py: 100%"
          }
        },
        "d56b39710318481d929b140b7f43fd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c886dd566554be990c2210de37fcf8d",
            "max": 73193,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47085965bd9f4e289a71b41ac2b78c98",
            "value": 73193
          }
        },
        "5e17c26e356f445bb9989873fa07c4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78425bd22d974b548191175e3558afe0",
            "placeholder": "​",
            "style": "IPY_MODEL_4f3a55b12fd745a0a78cc0480d275e53",
            "value": " 73.2k/73.2k [00:00&lt;00:00, 4.00MB/s]"
          }
        },
        "0ff807a9f6fc4834afcac95210214af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ff25fe78ec4c848bd0e1e188e25a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76acba0103444288a26ec7fd1b1c89c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c886dd566554be990c2210de37fcf8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47085965bd9f4e289a71b41ac2b78c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78425bd22d974b548191175e3558afe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f3a55b12fd745a0a78cc0480d275e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5bc143a4b64210beb63d231570ff49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7933bf3f20542eca27d58e06b9cedbc",
              "IPY_MODEL_443dcafd2c554e659b85e959c29bd224",
              "IPY_MODEL_41f2516284c345f295461761a0b75b30"
            ],
            "layout": "IPY_MODEL_d21624ef16fc40cdb933a5553a2f88aa"
          }
        },
        "f7933bf3f20542eca27d58e06b9cedbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d4b212666949958fcfa323c73c5e63",
            "placeholder": "​",
            "style": "IPY_MODEL_a363abccb6914d199e6811fac9ff30ef",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "443dcafd2c554e659b85e959c29bd224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af221297c5d48ce896afa3521614fb5",
            "max": 16533,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_674d6a3f786f48179e7a156a2e62f105",
            "value": 16533
          }
        },
        "41f2516284c345f295461761a0b75b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c9fa9d40d984344ad2003021ed5dd8d",
            "placeholder": "​",
            "style": "IPY_MODEL_269b5648ddac4d5ca57bc39cc6eb941e",
            "value": " 16.5k/16.5k [00:00&lt;00:00, 639kB/s]"
          }
        },
        "d21624ef16fc40cdb933a5553a2f88aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d4b212666949958fcfa323c73c5e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a363abccb6914d199e6811fac9ff30ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5af221297c5d48ce896afa3521614fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674d6a3f786f48179e7a156a2e62f105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c9fa9d40d984344ad2003021ed5dd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269b5648ddac4d5ca57bc39cc6eb941e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db8d2a25d61f4c53a32eaef3a5544041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc86ffcbba8042319eee9b9a1499ce24",
              "IPY_MODEL_e5afa3fbd45046869710096ee32fa654",
              "IPY_MODEL_ff2dbd72a3dd4383a3478d54dc7a866d"
            ],
            "layout": "IPY_MODEL_a280b889931d4c4186b4c8d102e175aa"
          }
        },
        "bc86ffcbba8042319eee9b9a1499ce24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a28e646c81e46d0b28501c196418efd",
            "placeholder": "​",
            "style": "IPY_MODEL_230c2c43834e4ffe8c24d7ea8fe08a5a",
            "value": "Fetching 2 files: 100%"
          }
        },
        "e5afa3fbd45046869710096ee32fa654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999ea89a48ac4e49820112465104afef",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7b00b48ccc64edf830e9ad1faa83815",
            "value": 2
          }
        },
        "ff2dbd72a3dd4383a3478d54dc7a866d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1172d6eaf34840e582012db07ff4ce16",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1f7076465e4ab78677f13d277e66ce",
            "value": " 2/2 [00:52&lt;00:00, 52.45s/it]"
          }
        },
        "a280b889931d4c4186b4c8d102e175aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a28e646c81e46d0b28501c196418efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230c2c43834e4ffe8c24d7ea8fe08a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "999ea89a48ac4e49820112465104afef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b00b48ccc64edf830e9ad1faa83815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1172d6eaf34840e582012db07ff4ce16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1f7076465e4ab78677f13d277e66ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb9863d634374ff7a8ba4544a624530c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1a4e1d4ae7e43fb8fb8d9b2ca68b124",
              "IPY_MODEL_12f14dcb4afb492394368b388f5e83bf",
              "IPY_MODEL_62f01584a6f043688be90a8bebfa4c79"
            ],
            "layout": "IPY_MODEL_f86b7045a0af44899b650ed6b64a3b41"
          }
        },
        "c1a4e1d4ae7e43fb8fb8d9b2ca68b124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9a911e74d84d1488f708112b47d4a8",
            "placeholder": "​",
            "style": "IPY_MODEL_13d7ff52691447b6a17f8e663b483be1",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "12f14dcb4afb492394368b388f5e83bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27acd835c04462abb57b00273e413eb",
            "max": 2669692552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efdc88d420d54ab58e644937a87a6aad",
            "value": 2669692552
          }
        },
        "62f01584a6f043688be90a8bebfa4c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6abbfbee14f24dc19504723ede9876f3",
            "placeholder": "​",
            "style": "IPY_MODEL_6f7883f91adf47a58e4734abe26b0178",
            "value": " 2.67G/2.67G [00:35&lt;00:00, 113MB/s]"
          }
        },
        "f86b7045a0af44899b650ed6b64a3b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9a911e74d84d1488f708112b47d4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d7ff52691447b6a17f8e663b483be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c27acd835c04462abb57b00273e413eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efdc88d420d54ab58e644937a87a6aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6abbfbee14f24dc19504723ede9876f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7883f91adf47a58e4734abe26b0178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ef745a431143c5a14fb3fae2b91cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_272a49d44ef44c6aa4221d42a1bc0cca",
              "IPY_MODEL_1d31c68a07a2478cb2ffb37c12a5afd4",
              "IPY_MODEL_50718078fac843309d74a9f7519bfe0d"
            ],
            "layout": "IPY_MODEL_3f01e544602a4695a4145f14f58d3ea8"
          }
        },
        "272a49d44ef44c6aa4221d42a1bc0cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56399dfaa910483b8e4efdc55dc06a30",
            "placeholder": "​",
            "style": "IPY_MODEL_e0ec4e6ba2f84e509cb007b8050fc134",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "1d31c68a07a2478cb2ffb37c12a5afd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e96228c96e4e009e710c0adaecccfc",
            "max": 4972489328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4507b3e8276d40448b71530f5a07867d",
            "value": 4972489328
          }
        },
        "50718078fac843309d74a9f7519bfe0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6e959dc9f994979af95c41f1df6c44d",
            "placeholder": "​",
            "style": "IPY_MODEL_b140f9542d134b039b30b60a699c4fde",
            "value": " 4.97G/4.97G [00:52&lt;00:00, 216MB/s]"
          }
        },
        "3f01e544602a4695a4145f14f58d3ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56399dfaa910483b8e4efdc55dc06a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ec4e6ba2f84e509cb007b8050fc134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e96228c96e4e009e710c0adaecccfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4507b3e8276d40448b71530f5a07867d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6e959dc9f994979af95c41f1df6c44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b140f9542d134b039b30b60a699c4fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c1f3e9218d44439121bcabdd0c3130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15efece47c36428294efcd5baa9d704c",
              "IPY_MODEL_9892848eb12c412297e1a0add60f9a68",
              "IPY_MODEL_60a5ea06f1b04287b78d3899b1654de2"
            ],
            "layout": "IPY_MODEL_d23c02131c8d4bfcaf84614be7c7a179"
          }
        },
        "15efece47c36428294efcd5baa9d704c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4af64ac03d447580fd7425466ecdd2",
            "placeholder": "​",
            "style": "IPY_MODEL_426f02c2d2434e4a91d054bc43e0345b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9892848eb12c412297e1a0add60f9a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b59cdad3ac64a558f1cba5ae417f862",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a24644b5aa490c9a91b170766b4490",
            "value": 2
          }
        },
        "60a5ea06f1b04287b78d3899b1654de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b824d42b316142b2b30b055509cd4d81",
            "placeholder": "​",
            "style": "IPY_MODEL_121cf33189bc4d76a172c03158c657a0",
            "value": " 2/2 [00:31&lt;00:00, 14.97s/it]"
          }
        },
        "d23c02131c8d4bfcaf84614be7c7a179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4af64ac03d447580fd7425466ecdd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "426f02c2d2434e4a91d054bc43e0345b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b59cdad3ac64a558f1cba5ae417f862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a24644b5aa490c9a91b170766b4490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b824d42b316142b2b30b055509cd4d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121cf33189bc4d76a172c03158c657a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8852e6069934168b5874c6052c63c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ce7c17dbf24fc8948be663dd2c9710",
              "IPY_MODEL_d79c447eee03471298d7f6397203b023",
              "IPY_MODEL_fe8f3e79f8b543c18e97197492d14b1c"
            ],
            "layout": "IPY_MODEL_d4b475f6d85e49aebb6f5d928c2e9f59"
          }
        },
        "62ce7c17dbf24fc8948be663dd2c9710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a446e4e3900549509bf59284e7a981b6",
            "placeholder": "​",
            "style": "IPY_MODEL_f41953b1333e4b0390c823560d07f489",
            "value": "generation_config.json: 100%"
          }
        },
        "d79c447eee03471298d7f6397203b023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2988d41828a84540bdc2f8e084f962f0",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14347b14b55f4c988b1d12e09414e92b",
            "value": 181
          }
        },
        "fe8f3e79f8b543c18e97197492d14b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7b1e11e6b744528a82237b693b297c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f3de15d474c84051977294eee771a06d",
            "value": " 181/181 [00:00&lt;00:00, 21.2kB/s]"
          }
        },
        "d4b475f6d85e49aebb6f5d928c2e9f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a446e4e3900549509bf59284e7a981b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41953b1333e4b0390c823560d07f489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2988d41828a84540bdc2f8e084f962f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14347b14b55f4c988b1d12e09414e92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7b1e11e6b744528a82237b693b297c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3de15d474c84051977294eee771a06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1689b26304548f89fa80eacdc5a34a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32fd3b0dddb24f9585c83e8675f82395",
              "IPY_MODEL_244a3960f6e54614ad281bda29f43eb2",
              "IPY_MODEL_a89b5e59d6ef4bec885da8d6e483adc6"
            ],
            "layout": "IPY_MODEL_e80ad492ddef4b35b4d051c9403ede6d"
          }
        },
        "32fd3b0dddb24f9585c83e8675f82395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6793d3455e4c948af6732669eae529",
            "placeholder": "​",
            "style": "IPY_MODEL_5f989f11af0a47ea8ae7687c1fc3dd13",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "244a3960f6e54614ad281bda29f43eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf639b89b6741d2b902e9d74c6a41bc",
            "max": 3441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68c472a44c2b4e488c482bf3e26ca293",
            "value": 3441
          }
        },
        "a89b5e59d6ef4bec885da8d6e483adc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5961a5f2628451a85e9c6776fef827f",
            "placeholder": "​",
            "style": "IPY_MODEL_a743d88154614570a1818615d1e000bf",
            "value": " 3.44k/3.44k [00:00&lt;00:00, 407kB/s]"
          }
        },
        "e80ad492ddef4b35b4d051c9403ede6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6793d3455e4c948af6732669eae529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f989f11af0a47ea8ae7687c1fc3dd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cf639b89b6741d2b902e9d74c6a41bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c472a44c2b4e488c482bf3e26ca293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5961a5f2628451a85e9c6776fef827f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a743d88154614570a1818615d1e000bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6a673622273428198c7d8e07e2ce20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f4815db954f426db85c9dfe3d548305",
              "IPY_MODEL_1c700236e2fe4146b048af51812d9edc",
              "IPY_MODEL_5806bddadbcb421f9f7695ddf42cdf30"
            ],
            "layout": "IPY_MODEL_19bfe6c7afdf4f7e81d9ba7bc0f404f0"
          }
        },
        "9f4815db954f426db85c9dfe3d548305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9075e25f2547dab424f99291284999",
            "placeholder": "​",
            "style": "IPY_MODEL_5f4bd0921d334b208234462f44bb5de8",
            "value": "tokenizer.model: 100%"
          }
        },
        "1c700236e2fe4146b048af51812d9edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61fc63d39fc4d17b1e6f7b913da1505",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f850a5fcbe1a40499fe64c25029af71e",
            "value": 499723
          }
        },
        "5806bddadbcb421f9f7695ddf42cdf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a346d22e290a4128b6ae8866356a4b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b4ebe6fdc3547619e9ec5b81856b5b0",
            "value": " 500k/500k [00:00&lt;00:00, 9.46MB/s]"
          }
        },
        "19bfe6c7afdf4f7e81d9ba7bc0f404f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9075e25f2547dab424f99291284999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4bd0921d334b208234462f44bb5de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61fc63d39fc4d17b1e6f7b913da1505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f850a5fcbe1a40499fe64c25029af71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a346d22e290a4128b6ae8866356a4b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4ebe6fdc3547619e9ec5b81856b5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5411d8cb4d1644aead6e4de8e2d0d92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_768f7a800d814d93be814af4cd46e4f2",
              "IPY_MODEL_e618f7011427487ca83eb2a34f0e0fe3",
              "IPY_MODEL_79e28d31afe14f8aabd326934b080294"
            ],
            "layout": "IPY_MODEL_54e21328ff654c62a3c7be8034fbc861"
          }
        },
        "768f7a800d814d93be814af4cd46e4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456783ad58684657af24b47b41a0e250",
            "placeholder": "​",
            "style": "IPY_MODEL_3ab6c5cb8ae94d31be5303d483e52bb0",
            "value": "tokenizer.json: 100%"
          }
        },
        "e618f7011427487ca83eb2a34f0e0fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1887c8af99454076ae964e11ea3f483a",
            "max": 1937869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eccbcac4661847cca20540321448750d",
            "value": 1937869
          }
        },
        "79e28d31afe14f8aabd326934b080294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306e85aa118d4844b7b1328e9294cfe0",
            "placeholder": "​",
            "style": "IPY_MODEL_da0a7e5724d849e6b1466969c02429f9",
            "value": " 1.94M/1.94M [00:00&lt;00:00, 12.3MB/s]"
          }
        },
        "54e21328ff654c62a3c7be8034fbc861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456783ad58684657af24b47b41a0e250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab6c5cb8ae94d31be5303d483e52bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1887c8af99454076ae964e11ea3f483a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccbcac4661847cca20540321448750d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "306e85aa118d4844b7b1328e9294cfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0a7e5724d849e6b1466969c02429f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c726960497469493674cfdc85f6b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e946bb0ca38046deabe93f3ba1b07bda",
              "IPY_MODEL_7547ea696a60447882122bc16057e190",
              "IPY_MODEL_a4432537fdea48c784fc1c606528b9af"
            ],
            "layout": "IPY_MODEL_5d080621d40f4e07a0cd0a3f2fe5c6f3"
          }
        },
        "e946bb0ca38046deabe93f3ba1b07bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c3d07d2344d403498848f5ee0953ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd3f81f735942f1b77d61162c958dbe",
            "value": "added_tokens.json: 100%"
          }
        },
        "7547ea696a60447882122bc16057e190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ee62b27e9943be8bed63393a48b230",
            "max": 306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d09e0e10679e4357988bec22e95707e2",
            "value": 306
          }
        },
        "a4432537fdea48c784fc1c606528b9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45409685b8f748fa95daf401eebb8bd7",
            "placeholder": "​",
            "style": "IPY_MODEL_1f7fef6d00af437fae79f9639b063c20",
            "value": " 306/306 [00:00&lt;00:00, 8.64kB/s]"
          }
        },
        "5d080621d40f4e07a0cd0a3f2fe5c6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3d07d2344d403498848f5ee0953ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd3f81f735942f1b77d61162c958dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ee62b27e9943be8bed63393a48b230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09e0e10679e4357988bec22e95707e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45409685b8f748fa95daf401eebb8bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7fef6d00af437fae79f9639b063c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba681b6b34641659e18f0e7c8411d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b424214953db48a6b821f450007395ed",
              "IPY_MODEL_48ceeff038dd4783a7968bdbfcdf569b",
              "IPY_MODEL_08b958c04e4441f2896188629c2b9f89"
            ],
            "layout": "IPY_MODEL_362e7b1d5bd743f3a13a05a4acb16a67"
          }
        },
        "b424214953db48a6b821f450007395ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0d220d80134aea92177906e7d75c12",
            "placeholder": "​",
            "style": "IPY_MODEL_ea6bea9795a9496c8ff49ea6acada953",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "48ceeff038dd4783a7968bdbfcdf569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdcbc8c6ac4e4612b39dec7aa5ba4f8e",
            "max": 599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3844f511e95c4e2c82edf32e308a8dfc",
            "value": 599
          }
        },
        "08b958c04e4441f2896188629c2b9f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5618ba9af514d56960ff5fa0d449649",
            "placeholder": "​",
            "style": "IPY_MODEL_b24f724a7c794d21b0c3873b5a5a840f",
            "value": " 599/599 [00:00&lt;00:00, 53.4kB/s]"
          }
        },
        "362e7b1d5bd743f3a13a05a4acb16a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0d220d80134aea92177906e7d75c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea6bea9795a9496c8ff49ea6acada953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdcbc8c6ac4e4612b39dec7aa5ba4f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3844f511e95c4e2c82edf32e308a8dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5618ba9af514d56960ff5fa0d449649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24f724a7c794d21b0c3873b5a5a840f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bc5084d0c942cfbf7d3b0ea0a047df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0a28018925f4761a94d3cfc07370fa3",
              "IPY_MODEL_40f8b9dc0e494c689d1b8e9fc7a37392",
              "IPY_MODEL_6c6b228894404bf2924c15b3b44b0c40"
            ],
            "layout": "IPY_MODEL_0286fa2891b34c91b4374aca5fc0d9b9"
          }
        },
        "f0a28018925f4761a94d3cfc07370fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de293cd9005c4638bb1efd3f52c8f58b",
            "placeholder": "​",
            "style": "IPY_MODEL_b550ed47954d4112b8886a7a51a146a3",
            "value": "README.md: 100%"
          }
        },
        "40f8b9dc0e494c689d1b8e9fc7a37392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ee0e502e524a90a4575f973d186996",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7325967cca41889cc640b515696726",
            "value": 7940
          }
        },
        "6c6b228894404bf2924c15b3b44b0c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87884afe83d944568365dbbdab7a580b",
            "placeholder": "​",
            "style": "IPY_MODEL_ac72cf0871b2497f954b28e0bab8bc1b",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 632kB/s]"
          }
        },
        "0286fa2891b34c91b4374aca5fc0d9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de293cd9005c4638bb1efd3f52c8f58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b550ed47954d4112b8886a7a51a146a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9ee0e502e524a90a4575f973d186996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7325967cca41889cc640b515696726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87884afe83d944568365dbbdab7a580b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac72cf0871b2497f954b28e0bab8bc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e46e3e0cbc54c74b94d0f6d5c060d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_979159f1dbbf4908a0d0e1fd05838e4e",
              "IPY_MODEL_45eec5eae81946d4b16970c9a852f8a1",
              "IPY_MODEL_ebcc064735694c819581d17941c8fd9a"
            ],
            "layout": "IPY_MODEL_2970a3770da04e189ba8f6e9e91cd305"
          }
        },
        "979159f1dbbf4908a0d0e1fd05838e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e29fca6810f84f65b464c700b186bc7d",
            "placeholder": "​",
            "style": "IPY_MODEL_779f01b7b8f44c7f97e32590a6db8298",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "45eec5eae81946d4b16970c9a852f8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fc33bc9325b4b0ca7189d6ea61af61c",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb5fe576c6114e3d988e41969ade6707",
            "value": 2306545
          }
        },
        "ebcc064735694c819581d17941c8fd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01cd4adeaab843f69cc5bea59a22b507",
            "placeholder": "​",
            "style": "IPY_MODEL_f56219522b3f4e60bbc3ea83b0c67e2c",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 32.8MB/s]"
          }
        },
        "2970a3770da04e189ba8f6e9e91cd305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29fca6810f84f65b464c700b186bc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779f01b7b8f44c7f97e32590a6db8298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fc33bc9325b4b0ca7189d6ea61af61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5fe576c6114e3d988e41969ade6707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01cd4adeaab843f69cc5bea59a22b507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56219522b3f4e60bbc3ea83b0c67e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b89a3cf8d64764b2444f79db3bf7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d397ab0a6d14a8180eb92802257733d",
              "IPY_MODEL_cec7fca8e3d44feca565ee47400dcfdd",
              "IPY_MODEL_c452079140ae485f97328a7c0a48b0a4"
            ],
            "layout": "IPY_MODEL_2d2c2a20cfc1406493cbeaf0ad053081"
          }
        },
        "0d397ab0a6d14a8180eb92802257733d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33075b740b56430abfb783ec46a5c11b",
            "placeholder": "​",
            "style": "IPY_MODEL_91df871ea39b47af91df97adea755d09",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "cec7fca8e3d44feca565ee47400dcfdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42ace153e7ac48f2971116ad97a66231",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43cafe4f5fb44c31ad23b940c481f644",
            "value": 419088
          }
        },
        "c452079140ae485f97328a7c0a48b0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_897a4ee408bc430f876425b9e03d0301",
            "placeholder": "​",
            "style": "IPY_MODEL_77ae2dcca05c46b6a10f4e2828dfd819",
            "value": " 419k/419k [00:00&lt;00:00, 34.6MB/s]"
          }
        },
        "2d2c2a20cfc1406493cbeaf0ad053081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33075b740b56430abfb783ec46a5c11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91df871ea39b47af91df97adea755d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42ace153e7ac48f2971116ad97a66231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43cafe4f5fb44c31ad23b940c481f644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "897a4ee408bc430f876425b9e03d0301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ae2dcca05c46b6a10f4e2828dfd819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbdd060a9b36438090ab2c60d5fc5814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc346d36b3cd486cac7cd53a9ed0c0a1",
              "IPY_MODEL_840c34bf544b420dbbcaeb7828071fa9",
              "IPY_MODEL_87878072dc374da5bcb805869d4ff403"
            ],
            "layout": "IPY_MODEL_302f8a7e3a074684906ee7236b137584"
          }
        },
        "bc346d36b3cd486cac7cd53a9ed0c0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64334673cec447db886f49e6c7f5375e",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd09391501045bdaf97893d021d10ce",
            "value": "Generating train split: 100%"
          }
        },
        "840c34bf544b420dbbcaeb7828071fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f81c2af840642c59c11a2b83907af3e",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf3cf9b785e48d68e255b1b69b8b0da",
            "value": 7473
          }
        },
        "87878072dc374da5bcb805869d4ff403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81381c2ae79342f0886c20fcd7cf2c97",
            "placeholder": "​",
            "style": "IPY_MODEL_e8abe205a041408697420ef5a855601b",
            "value": " 7473/7473 [00:00&lt;00:00, 7148.56 examples/s]"
          }
        },
        "302f8a7e3a074684906ee7236b137584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64334673cec447db886f49e6c7f5375e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd09391501045bdaf97893d021d10ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f81c2af840642c59c11a2b83907af3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf3cf9b785e48d68e255b1b69b8b0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81381c2ae79342f0886c20fcd7cf2c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8abe205a041408697420ef5a855601b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "496cad2bf95c481b910684a01effe464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42a6c17b7a224b9eb4d5fe91b07bd464",
              "IPY_MODEL_7832cab58fe541ab905c6c5d9953903c",
              "IPY_MODEL_c26b878d463948a194e8c47137eb0c33"
            ],
            "layout": "IPY_MODEL_76a52c8e61b54cfbab9f29ea681de0fc"
          }
        },
        "42a6c17b7a224b9eb4d5fe91b07bd464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2892b7687fe04a9cad90f4b36ee8d5e7",
            "placeholder": "​",
            "style": "IPY_MODEL_9be653f8401a496c87cb4f99b78f41ee",
            "value": "Generating test split: 100%"
          }
        },
        "7832cab58fe541ab905c6c5d9953903c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1822f5876e0d447bb56f0755e21506cc",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3da5ac40a0844bf4a72f2e04ad39c0ee",
            "value": 1319
          }
        },
        "c26b878d463948a194e8c47137eb0c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c493499526f4aad8d1d7cc10aebbcd3",
            "placeholder": "​",
            "style": "IPY_MODEL_67a59345317e424695552f92de2e464c",
            "value": " 1319/1319 [00:00&lt;00:00, 47096.92 examples/s]"
          }
        },
        "76a52c8e61b54cfbab9f29ea681de0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2892b7687fe04a9cad90f4b36ee8d5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be653f8401a496c87cb4f99b78f41ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1822f5876e0d447bb56f0755e21506cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da5ac40a0844bf4a72f2e04ad39c0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c493499526f4aad8d1d7cc10aebbcd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67a59345317e424695552f92de2e464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3325688602947c68458892d0c4e92c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e80c733857e47579b3d853dac6d880f",
              "IPY_MODEL_e35bbede9dd14336bca30519d76a49cb",
              "IPY_MODEL_74fec002d020404e9513bbc29af3389f"
            ],
            "layout": "IPY_MODEL_3a4f477377e14356a75418701cf14b7c"
          }
        },
        "2e80c733857e47579b3d853dac6d880f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17b7e4fa6f14480c910bbfbf937577e5",
            "placeholder": "​",
            "style": "IPY_MODEL_21dc77847c204daa84464cb9c079f980",
            "value": "Map: 100%"
          }
        },
        "e35bbede9dd14336bca30519d76a49cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4b99e6dc76482fb5c8b438ab184741",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d12344f27cb4972952a88d36738aca1",
            "value": 7473
          }
        },
        "74fec002d020404e9513bbc29af3389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_180dc3067bc9465c9368e8f2968c49cb",
            "placeholder": "​",
            "style": "IPY_MODEL_2b9a74fb29404f22b65d825d12b6534a",
            "value": " 7473/7473 [00:00&lt;00:00, 16236.89 examples/s]"
          }
        },
        "3a4f477377e14356a75418701cf14b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17b7e4fa6f14480c910bbfbf937577e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21dc77847c204daa84464cb9c079f980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4b99e6dc76482fb5c8b438ab184741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d12344f27cb4972952a88d36738aca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "180dc3067bc9465c9368e8f2968c49cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9a74fb29404f22b65d825d12b6534a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a4abb1d90c4f27b11ff8835f217609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ae3cb813a194ad489b173fbcf0c73bc",
              "IPY_MODEL_18daf9010051466b8f4206124507f72f",
              "IPY_MODEL_e10767e9a1ef468f9276e72a4c7119e6"
            ],
            "layout": "IPY_MODEL_e894ebbd06f34fafa89a9fe81a4b7659"
          }
        },
        "0ae3cb813a194ad489b173fbcf0c73bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17eeaa6dcb354bd5b2a8d26aa6bf947e",
            "placeholder": "​",
            "style": "IPY_MODEL_a0e093c28b12403ea13915e38deb5219",
            "value": "Map: 100%"
          }
        },
        "18daf9010051466b8f4206124507f72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60fe61785684af8a9a2cc5eeb5d65c5",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8885f591faf849babfa148e759e28369",
            "value": 1319
          }
        },
        "e10767e9a1ef468f9276e72a4c7119e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4577ea292143d0b6a4a2934d40189d",
            "placeholder": "​",
            "style": "IPY_MODEL_3652985f1c4a44b9a214e209e1b03f56",
            "value": " 1319/1319 [00:00&lt;00:00, 14422.06 examples/s]"
          }
        },
        "e894ebbd06f34fafa89a9fe81a4b7659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17eeaa6dcb354bd5b2a8d26aa6bf947e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e093c28b12403ea13915e38deb5219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60fe61785684af8a9a2cc5eeb5d65c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8885f591faf849babfa148e759e28369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa4577ea292143d0b6a4a2934d40189d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3652985f1c4a44b9a214e209e1b03f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}